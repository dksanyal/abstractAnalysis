

# 16
### http://arxiv.org/abs/cs/0504073v1
## Rendezvous Regions: A Scalable Architecture for Resource Discovery and Service Location in Large-Scale Mobile Networks

0	In large-scale wireless networks such as mobile ad hoc and sensor networks, efficient and robust service discovery and data-access mechanisms are both essential and challenging.
0 	Rendezvous-based mechanisms provide a valuable solution for provisioning a wide range of services.
1 	In this paper, we describe Rendezvous Regions (RRs) - a novel scalable rendezvous-based architecture for wireless networks.
0 	RR is a general architecture proposed for service location and bootstrapping in ad hoc networks, in addition to data-centric storage, configuration, and task assignment in sensor networks.
0 	In RR the network topology is divided into geographical regions, where each region is responsible for a set of keys representing the services or data of interest.
0 	Each key is mapped to a region based on a hash-table-like mapping scheme.
0 	A few elected nodes inside each region are responsible for maintaining the mapped information.
0 	The service or data provider stores the information in the corresponding region and the seekers retrieve it from there.
1 	We run extensive detailed simulations, and high-level simulations and analysis, to investigate the design space, and study the architecture in various environments including node mobility and failures.
1 	We evaluate it against other approaches to identify its merits and limitations.
2 	The results show high success rate and low overhead even with dynamics.
2 	RR scales to large number of nodes and is highly robust and efficient to node failures.
2 	It is also robust to node mobility and location inaccuracy with a significant advantage over point-based rendezvous mechanisms.


# 17
### http://arxiv.org/abs/cs/0604017v3
## AS Relationships: Inference and Validation

0 	Research on performance, robustness, and evolution of the global Internet is fundamentally handicapped without accurate and thorough knowledge of the nature and structure of the contractual relationships between Autonomous Systems (ASs).
1 	In this work we introduce novel heuristics for inferring AS relationships.
1 	Our heuristics improve upon previous works in several technical aspects, which we outline in detail and demonstrate with several examples.
1 	Seeking to increase the value and reliability of our inference results, we then focus on validation of inferred AS relationships.
1 	We perform a survey with ASs' network administrators to collect information on the actual connectivity and policies of the surveyed ASs.
1 	Based on the survey results, we find that our new AS relationship inference techniques achieve high levels of accuracy: we correctly infer 96.5% customer to provider (c2p), 82.8% peer to peer (p2p), and 90.3% sibling to sibling (s2s) relationships.
1 	We then cross-compare the reported AS connectivity with the AS connectivity data contained in BGP tables.
1 	We find that BGP tables miss up to 86.2% of the true adjacencies of the surveyed ASs.
2 	The majority of the missing links are of the p2p type, which highlights the limitations of present measuring techniques to capture links of this type.
1 	Finally, to make our results easily accessible and practically useful for the community, we open an AS relationship repository where we archive, on a weekly basis, and make publicly available the complete Internet AS-level topology annotated with AS relationship information for every pair of AS neighbors.


# 18
### http://arxiv.org/abs/cs/0609026v1
## Rarest First and Choke Algorithms Are Enough

0 	The performance of peer-to-peer file replication comes from its piece and peer selection strategies.
0 	Two such strategies have been introduced by the BitTorrent protocol: the rarest first and choke algorithms.
0 	Whereas it is commonly admitted that BitTorrent performs well, recent studies have proposed the replacement of the rarest first and choke algorithms in order to improve efficiency and fairness.
1 	In this paper, we use results from real experiments to advocate that the replacement of the rarest first and choke algorithms cannot be justified in the context of peer-to-peer file replication in the Internet.
1 	We instrumented a BitTorrent client and ran experiments on real torrents with different characteristics.
0 	Our experimental evaluation is peer oriented, instead of tracker oriented, which allows us to get detailed information on all exchanged messages and protocol events.
1 	We go beyond the mere observation of the good efficiency of both algorithms.
1 	We show that the rarest first algorithm guarantees close to ideal diversity of the pieces among peers.
2 	In particular, on our experiments, replacing the rarest first algorithm with source or network coding solutions cannot be justified.
1 	We also show that the choke algorithm in its latest version fosters reciprocation and is robust to free riders.
2 	In particular, the choke algorithm is fair and its replacement with a bit level tit-for-tat solution is not appropriate.
1 	Finally, we identify new areas of improvements for efficient peer-to-peer file replication protocols.


# 19
### http://arxiv.org/abs/cs/0609069v1
## Coverage and Connectivity in Three-Dimensional Networks

0 	Most wireless terrestrial networks are designed based on the assumption that the nodes are deployed on a two-dimensional (2D) plane.
0 	However, this 2D assumption is not valid in underwater, atmospheric, or space communications.
0 	In fact, recent interest in underwater acoustic ad hoc and sensor networks hints at the need to understand how to design networks in 3D.
0 	Unfortunately, the design of 3D networks is surprisingly more difficult than the design of 2D networks.
0 	For example, proofs of Kelvin's conjecture and Kepler's conjecture required centuries of research to achieve breakthroughs, whereas their 2D counterparts are trivial to solve.
1 	In this paper, we consider the coverage and connectivity issues of 3D networks, where the goal is to find a node placement strategy with 100% sensing coverage of a 3D space, while minimizing the number of nodes required for surveillance.
2 	Our results indicate that the use of the Voronoi tessellation of 3D space to create truncated octahedral cells results in the best strategy.
2 	In this truncated octahedron placement strategy, the transmission range must be at least 1.7889 times the sensing range in order to maintain connectivity among nodes.
2 	If the transmission range is between 1.4142 and 1.7889 times the sensing range, then a hexagonal prism placement strategy or a rhombic dodecahedron placement strategy should be used.
2 	Although the required number of nodes in the hexagonal prism and the rhombic dodecahedron placement strategies is the same, this number is 43.25% higher than the number of nodes required by the truncated octahedron placement strategy.
1 	We verify by simulation that our placement strategies indeed guarantee ubiquitous coverage.
2 	We believe that our approach and our results presented in this paper could be used for extending the processes of 2D network design to 3D networks.


# 20
### http://arxiv.org/abs/cs/0609086v1
## About the Capacity of Flat and Self-Organized Ad Hoc and Hybrid Networks

0 	Ad hoc networking specific challenges foster a strong research effort on efficient protocols design.
0 	Routing protocols based on a self-organized structure have been studied principally for the robustness and the scalability they provide.
0 	On the other hand, self-organization schemes may decrease the network capacity since they concentrate the traffic on privileged links.
0 	This paper presents four models for evaluating the capacity of a routing schemes on 802.11 like networks.
0 	Our approach consists in modeling the radio resource sharing principles of 802.11 like MAC protocols as a set of linear constraints.
1 	We have implemented two models of fairness.
0 	The first one assumes that nodes have a fair access to the channel, while the second one assumes that on the radio links.
1 	We then develop a pessimistic and an optimistic scenario of spatial re-utilization of the medium, yielding a lower bound and an upper bound on the network capacity for each fairness case.
0 	Our models are independent of the routing protocols and provide therefore a relevant framework for their comparison.
1 	We apply our models to a comparative analysis of the well-known shortest path base flat routing protocol OLSR against two main self-organized structure approaches, VSR, and Wu & Li's protocols.
2 	This study concludes on the relevance of self-organized approaches from the network capacity point of view.


# 21
### http://arxiv.org/abs/cs/0609098v1
## Reducing the Makespan in Hierarchical Reliable Multicast Tree

0 	In hierarchical reliable multicast environment, makespan is the time that is required to fully and successfully transmit a packet from the sender to all receivers.
0 	Low makespan is vital for achieving high throughput with a TCP-like window based sending scheme.
0 	In hierarchical reliable multicast methods, the number of repair servers and their locations influence the makespan.
1 	In this paper we propose a new method to decide the locations of repair servers that can reduce the makespan in hierarchical reliable multicast networks.
0 	Our method has a formulation based on mixed integer programming to analyze the makespan minimization problem.
0 	A notable aspect of the formulation is that heterogeneous links and packet losses are taken into account in the formulation.
1 	Three different heuristics are presented to find the locations of repair servers in reasonable time in the formulation.
0 	Through simulations, three heuristics are carefully analyzed and compared on networks with different sizes.
1 	We also evaluate our proposals on PGM (Pragmatic General Multicast) reliable multicast protocol using ns-2 simulation.
2 	The results show that the our best heuristic is close to the lower bound by a factor of 2.3 in terms of makespan and by a factor of 5.5 in terms of the number of repair servers.


# 22
### http://arxiv.org/abs/0712.2083v1
## VoIP over Multiple IEEE 802.11 Wireless LANs

0 	Prior work indicates that 802.11 is extremely inefficient for VoIP transport.
0 	Only 12 and 60 VoIP sessions can be supported in an 802.11b and an 802.11g WLAN, respectively.
0 	This paper shows that the bad news does not stop there.
0 	When there are multiple WLANs in the vicinity of each other, the already-low VoIP capacity can be further eroded in a significant manner.
0 	For example, in a 5-by-5, 25-cell multi-WLAN network, the VoIP capacities for 802.11b and 802.11g are only 1.63 and 10.34 sessions per AP, respectively.
0 	This paper investigates several solutions to improve the VoIP capacity.
1 	Based on a conflict graph model, we propose a clique-analytical call-admission scheme, which increases the VoIP capacity by 52% and 37% in 802.11b and 802.11g respectively.
2 	If all the three orthogonal frequency channels available in 11b and 11g are used, the capacity can be nearly tripled by the call-admission scheme.
1 	This paper also proposes for the first time the use of coarse-grained time-division multiple access (CoTDMA) in conjunction with the basic 802.11 CSMA to eliminate the performance-degrading exposed-node and hidden-node problems.
2 	We find that CoTDMA can further increase the VoIP capacity in the multi-WLAN scenario by an additional 35%.


# 23
### http://arxiv.org/abs/0712.2274v1
## Distributed MAC Strategy for Exploiting Multi-user Diversity in Multi-rate IEEE 802.11 Wireless LANs

0 	Fast rate adaptation has been established as an effective way to improve the PHY-layer raw date rate of wireless networks.
0 	However, within the current IEEE 802.11 legacy, MAC-layer throughput is dominated by users with the lowest data rates, resulting in underutilization of bandwidth.
1 	In this paper, we propose and analyze a novel distributed MAC strategy, referred to as Rate-aware DCF (R-DCF), to leverage the potential of rate adaptation in IEEE 802.11 WLANs.
0 	The key feature of R-DCF is that by introducing different mini slots according to the instantaneous channel conditions, only contending stations with the highest data rate can access the channel.
0 	In this way, the R-DCF protocol not only exploits multi-user diversity in a fully distributed manner but also reduces the loss of throughput due to collisions.
1 	Through analysis, we develop an analytical model to derive the throughput of R-DCF in general multi-rate WLANs.
1 	Using the analytical model we investigate the performance of R-DCF protocol in various network settings with different rate adaptation strategies and channel variations.
1 	Based on the analysis, we further derive the maximal throughput achievable by R-DCF.
1 	For practical implementation, an offline adaptive backoff method is developed to achieve a close-to-optimal performance at low runtime complexity.
2 	The superiority of R-DCF is proven via extensive analyses and simulations.


# 24
### http://arxiv.org/abs/0807.1153v1
## CSI: A Paradigm for Behavior-oriented Delivery Services in Mobile Human Networks

0 	We propose behavior-oriented services as a new paradigm of communication in mobile human networks.
0 	Our study is motivated by the tight user-network coupling in future mobile societies.
0 	In such a paradigm, messages are sent to inferred behavioral profiles, instead of explicit IDs.
0 	Our paper provides a systematic framework in providing such services.
0 	First, user behavioral profiles are constructed based on traces collected from two large wireless networks, and their spatio-temporal stability is analyzed.
0 	The implicit relationship discovered between mobile users could be utilized to provide a service for message delivery and discovery in various network environments.
1 	As an example application, we provide a detailed design of such a service in challenged opportunistic network architecture, named CSI.
1 	We provide a fully distributed solution using behavioral profile space gradients and small world structures.
2 	Our analysis shows that user behavioral profiles are surprisingly stable, i.e., the similarity of the behavioral profile of a user to its future behavioral profile is above 0.8 for two days and 0.75 for one week, and remains above 0.6 for five weeks.
2 	The correlation coefficient of the similarity metrics between a user pair at different time instants is above 0.7 for four days, 0.62 for a week, and remains above 0.5 for two weeks.
2 	Leveraging such a stability in user behaviors, the CSI service achieves delivery rate very close to the delay-optimal strategy (above 94%), with minimal overhead (less than 84% of the optimal).
2 	We believe that this new paradigm will act as an enabler of multiple new services in mobile societies, and is potentially applicable in server-based, heterogeneous or infrastructure-less wireless environments.


# 25
### http://arxiv.org/abs/0812.4744v1
## On Wireless Link Scheduling and Flow Control

0 	This thesis focuses on link scheduling in wireless mesh networks by taking into account physical layer characteristics.
0 	The assumption made throughout is that a packet is received successfully only if the Signal to Interference and Noise Ratio (SINR) at the receiver exceeds the communication threshold.
0 	The thesis also discusses the complementary problem of flow control. 
1 	(1) We consider various problems on centralized link scheduling in Spatial Time Division Multiple Access (STDMA) wireless mesh networks.
1 	We motivate the use of spatial reuse as performance metric and provide an explicit characterization of spatial reuse.
1 	We propose link scheduling algorithms based on certain graph models (communication graph, SINR graph) of the network.
2 	Our algorithms achieve higher spatial reuse than that of existing algorithms, with only a slight increase in computational complexity. 
1 	(2) We investigate random access algorithms in wireless networks.
1 	We assume that the receiver is capable of power-based capture and propose a splitting algorithm that varies transmission powers of users on the basis of quaternary channel feedback.
1 	We model the algorithm dynamics by a Discrete Time Markov Chain and consequently show that its maximum stable throughput is 0.5518.
2 	Our algorithm achieves higher maximum stable throughput and significantly lower delay than the First Come First Serve (FCFS) splitting algorithm with uniform transmission power. 
1 	(3) We consider the problem of flow control in packet networks from an information-theoretic perspective.
1 	We derive the maximum entropy of a flow which conforms to traffic constraints imposed by a generalized token bucket regulator (GTBR), by taking into account the covert information present in randomness of packet lengths.


# 26
### http://arxiv.org/abs/0906.3038v1
## A measurement driven, 802.11 anti-jamming system

0 	Dense, unmanaged 802.11 deployments tempt saboteurs into launching jamming attacks by injecting malicious interference.
0 	Nowadays, jammers can be portable devices that transmit intermittently at low power in order to conserve energy.
1 	In this paper, we first conduct extensive experiments on an indoor 802.11 network to assess the ability of two physical layer functions, rate adaptation and power control, in mitigating jamming.
1 	In the presence of a jammer we find that: (a) the use of popular rate adaptation algorithms can significantly degrade network performance and, (b) appropriate tuning of the carrier sensing threshold allows a transmitter to send packets even when being jammed and enables a receiver capture the desired signal.
1 	Based on our findings, we build ARES, an Anti-jamming REinforcement System, which tunes the parameters of rate adaptation and power control to improve the performance in the presence of jammers.
0 	ARES ensures that operations under benign conditions are unaffected.
1 	To demonstrate the effectiveness and generality of ARES, we evaluate it in three wireless testbeds: (a) an 802.11n WLAN with MIMO nodes, (b) an 802.11a/g mesh network with mobile jammers and (c) an 802.11a WLAN.
2 	We observe that ARES improves the network throughput across all testbeds by up to 150%.


# 27
### http://arxiv.org/abs/0907.5489v2
## On Delay Constrained Multicast Capacity of Large-Scale Mobile Ad-Hoc Networks

0 	This paper studies the delay constrained multicast capacity of large scale mobile ad hoc networks (MANETs).
1 	We consider a MANET consists of $n_s$ multicast sessions.
0 	Each multicast session has one source and $p$ destinations.
0 	The wireless mobiles move according to a two-dimensional i.i.d. mobility model.
0 	Each source sends identical information to the $p$ destinations in its multicast session, and the information is required to be delivered to all the $p$ destinations within $D$ time-slots.
1 	Given the delay constraint $D,$ we first prove that the capacity per multicast session is $O(\min\{1, (\log p)(\log (n_sp)) \sqrt{\frac{D}{n_s}}\}).
0 	$ Given non-negative functions $f(n)$ and $g(n)$: $f(n)=O(g(n))$ means there exist positive constants $c$ and $m$ such that $f(n) \leq cg(n)$ for all $ n\geq m;$ $f(n)=\Omega(g(n))$ means there exist positive constants $c$ and $m$ such that $f(n)\geq cg(n)$ for all $n\geq m;$ $f(n)=\Theta(g(n))$ means that both $f(n)=\Omega(g(n))$ and $f(n)=O(g(n))$ hold; $f(n)=o(g(n))$ means that $\lim_{n\to \infty} f(n)/g(n)=0;$ and $f(n)=\omega(g(n))$ means that $\lim_{n\to \infty} g(n)/f(n)=0.
1 	$ We then propose a joint coding/scheduling algorithm achieving a throughput of $\Theta(\min\{1,\sqrt{\frac{D}{n_s}}\}).
2 	$ Our simulations show that the joint coding/scheduling algorithm achieves a throughput of the same order ($\Theta(\min\{1, \sqrt{\frac{D}{n_s}}\})$) under random walk model and random waypoint model.


# 28
### http://arxiv.org/abs/0908.0711v3
## Passive network tomography for erroneous networks: A network coding approach

0 	Passive network tomography uses end-to-end observations of network communication to characterize the network, for instance to estimate the network topology and to localize random or adversarial glitches.
0 	Under the setting of linear network coding this work provides a comprehensive study of passive network tomography in the presence of network (random or adversarial) glitches.
0 	To be concrete, this work is developed along two directions: 
0 	1.Tomographic upper and lower bounds (i.e., the most adverse conditions in each problem setting under which network tomography is possible, and corresponding schemes (computationally efficient, if possible) that achieve this performance) are presented for random linear network coding (RLNC).
1 	We consider RLNC designed with common randomness, i.e., the receiver knows the random code-books all nodes. 
1 	(To justify this, we show an upper bound for the problem of topology estimation in networks using RLNC without common randomness.)
1 	In this setting we present the first set of algorithms that characterize the network topology exactly.
2 	Our algorithm for topology estimation with random network errors has time complexity that is polynomial in network parameters.
1 	For the problem of network error localization given the topology information, we present the first computationally tractable algorithm to localize random errors, and prove it is computationally intractable to localize adversarial errors.
1 	2.New network coding schemes are designed that improve the tomographic performance of RLNC while maintaining the desirable low-complexity, throughput-optimal, distributed linear network coding properties of RLNC.
1 	In particular, we design network codes based on Reed-Solomon codes so that a maximal number of adversarial errors can be localized in a computationally efficient manner even without the information of network topology.


# 29
### http://arxiv.org/abs/0911.3528v1
## Estimating Network Link Characteristics using Packet-Pair Dispersion: A Discrete Time Queueing Theoretic View

0 	Packet-dispersion based measurement tools insert pairs of probe packets with a known separation into the network for transmission over a unicast path or a multicast tree.
0 	Samples of the separation between the probe pairs at the destination(s) are observed.
0 	Heuristic techniques are then used by these tools to estimate the path characteristics from the observations.
1 	In this paper we present a queueing theoretic setting for packet-dispersion based probing.
1 	Analogous to network tomography, we develop techniques to estimate the parameters of the arrival process to the individual links from the samples of the output separations, i.e., from the end-to-end measurements.
0 	The links are modeled as independent discrete time queues with i.i.d. arrivals.
1 	We first obtain an algorithm to obtain the (joint) distribution of the separation between the probes at the destination(s) for a given distribution of the spacing at the input.
0 	The parameter estimates of the arrival process are obtained as the minimizer of a cost function between the empirical and calculated distributions.
1 	We also carry out extensive simulations and numerical experiments to study the performance of the estimation algorithm under the fairly `harsh' conditions of non stationarity of the arrival process.
2 	We find that the estimations work fairly well for two queues in series and for multicast.


# 30
### http://arxiv.org/abs/0911.4357v1
## Splitting Algorithms for Fast Relay Selection: Generalizations, Analysis, and a Unified View

0 	Relay selection for cooperative communications promises significant performance improvements, and is, therefore, attracting considerable attention.
0 	While several criteria have been proposed for selecting one or more relays, distributed mechanisms that perform the selection have received relatively less attention.
1 	In this paper, we develop a novel, yet simple, asymptotic analysis of a splitting-based multiple access selection algorithm to find the single best relay.
0 	The analysis leads to simpler and alternate expressions for the average number of slots required to find the best user.
0 	By introducing a new `contention load' parameter, the analysis shows that the parameter settings used in the existing literature can be improved upon.
0 	New and simple bounds are also derived.
1 	Furthermore, we propose a new algorithm that addresses the general problem of selecting the best $Q \ge 1$ relays, and analyze and optimize it.
2 	Even for a large number of relays, the algorithm selects the best two relays within 4.406 slots and the best three within 6.491 slots, on average.
1 	We also propose a new and simple scheme for the practically relevant case of discrete metrics.
2 	Altogether, our results develop a unifying perspective about the general problem of distributed selection in cooperative systems and several other multi-node systems.


# 31
### http://arxiv.org/abs/0912.4115v2
## On Channel-Discontinuity-Constraint Routing in Wireless Networks

0	Multi-channel wireless networks are increasingly being employed as infrastructure networks, e.g. in metro areas.
0 	Nodes in these networks frequently employ directional antennas to improve spatial throughput.
0 	In such networks, given a source and destination, it is of interest to compute an optimal path and channel assignment on every link in the path such that the path bandwidth is the same as that of the link bandwidth and such a path satisfies the constraint that no two consecutive links on the path are assigned the same channel, referred to as "Channel Discontinuity Constraint" (CDC).
0 	CDC-paths are also quite useful for TDMA system, where preferably every consecutive links along a path are assigned different time slots.
0 	This paper contains several contributions.
1 	We first present an $O(N^{2})$ distributed algorithm for discovering the shortest CDC-path between given source and destination.
2	This improves the running time of the $O(N^{3})$ centralized algorithm of Ahuja et al. for finding the minimum-weight CDC-path.
1 	Our second result is a generalized $t$-spanner for CDC-path; For any $\theta>0$ we show how to construct a sub-network containing only $O(\frac{N}{\theta})$ edges, such that that length of shortest CDC-paths between arbitrary sources and destinations increases by only a factor of at most $(1-2\sin{\tfrac{\theta}{2}})^{-2}$.
1 	We propose a novel algorithm to compute the spanner in a distributed manner using only $O(n\log{n})$ messages.
2 	An important conclusion of this scheme is in the case of directional antennas are used.
2	In this case, it is enough to consider only the two closest nodes in each cone.


# 32
### http://arxiv.org/abs/1003.1479v1
## Analysis, Modification, and Implementation (AMI) of Scheduling Algorithm for the IEEE 802.116e (Mobile WiMAX)

0 	Mobile WiMAX (Worldwide Interoperability for Microwave Access) is being touted as the most promising and potential broadband wireless technology.
0 	And the popularity rate has been surging to newer heights as the knowledge-backed service era unfolds steadily.
0	Especially Mobile WiMAX is being projected as a real and strategic boon for developing counties such as India due to its wireless coverage acreage is phenomenally high.
0	Mobile WiMAX has spurred tremendous interest from operators seeking to deploy high-performance yet cost-effective broadband wireless networks.
1	The IEEE 802.16e standard based Mobile WiMAX system will be investigated for the purpose of Quality of Service provisioning.
1	As a technical challenge, radio resource management will be primarily considered and main is the costly spectrum and the increasingly more demanding applications with ever growing number of subscribers.
0 	It is necessary to provide Quality of Service (QoS) guaranteed with different characteristics.
1 	As a possible solution the scheduling algorithms will be taken into main consideration and the present well known algorithms will be described.
2 	In this paper, we have highlighted the following critical issues for Mobile WiMAX technologies.
2 	This paper specifically discussed about the below mentioned in detail. -
2 	QoS Requirements For IEEE 802.16 Service Classes, Achieving efficient radio resource management. -
2	Deficit Round Robin (DRR) Scheduling algorithm. -
2	Modified Deficit Round Robin (MDRR) scheduling algorithm's attributes, properties and architecture.
2	System Model And Scenarios Using OPNET Modeler Software. -
2 	Simulation Limitations And Constraints.


# 33
### http://arxiv.org/abs/1003.3568v1
## Key distribution in PKC through Quantas

0 	Cryptography literally means "The art & science of secret writing & sending a message between two parties in such a way that its contents cannot be understood by someone other than the intended recipient".and Quantum word is related with "Light".
0	Thus, Quantum Cryptography is a way of descripting any information in the form of quantum particles.
0	There are no classical cryptographic systems which are perfectly secure.
0 	In contrast to Classical cryptography which depends upon Mathematics, Quantum Cryptography utilizes the concepts of Quantum Physics which provides us the security against the cleverest marauders of the present age.
0	In the view of increasing need of Network and Information Security, we do require methods to overcome the Molecular Computing technologies (A future technology) and other techniques of the various codebrakers.
1 	Both the parts i.e. Quantum Key distribution and Information transference from Sender to Receiver are much efficient and secure.
1 	It is based upon BB84 protocol.
0	It can be of great use for Govt agencies such as Banks, Insurance, Brokerages firms, financial institutions, e-commerce and most important is the Defense & security of any country.
2 	It is a Cryptographic communication system in which the original users can detect unauthorized eavesdropper and in addition it gives a guarantee of no eavesdropping.
2	It proves to be the ultra secure mode of communication b/w two intended parties.


# 34
### http://arxiv.org/abs/1003.5104v1
## Resilient networking in wireless sensor networks

0	This report deals with security in wireless sensor networks (WSNs), especially in network layer.
0	Multiple secure routing protocols have been proposed in the literature.
0 	However, they often use the cryptography to secure routing functionalities.
0 	The cryptography alone is not enough to defend against multiple attacks due to the node compromise.
0	Therefore, we need more algorithmic solutions.
0	In this report, we focus on the behavior of routing protocols to determine which properties make them more resilient to attacks.
0 	Our aim is to find some answers to the following questions.
0 	Are there any existing protocols, not designed initially for security, but which already contain some inherently resilient properties against attacks under which some portion of the network nodes is compromised?
0 	If yes, which specific behaviors are making these protocols more resilient?
1 	We propose in this report an overview of security strategies for WSNs in general, including existing attacks and defensive measures.
2	In this report we focus at the network layer in particular, and an analysis of the behavior of four particular routing protocols is provided to determine their inherent resiliency to insider attacks.
2 	The protocols considered are: Dynamic Source Routing (DSR), Gradient-Based Routing (GBR), Greedy Forwarding (GF) and Random Walk Routing (RWR).


# 35
### http://arxiv.org/abs/1003.5432v1
## Computer Network Topology Design in Limelight of Pascal Graph Property

0 	Constantly growing demands of high productivity and security of computer systems and computer networks call the interest of specialists in the environment of construction of optimum topologies of computer mediums.
0	In earliest phases of design, the study of the topological influence of the processes that happen in computer systems and computer networks allows to obtain useful information which possesses a significant value in the subsequent design.
0	It has always been tried to represent the different computer network topologies using appropriate graph models.
0 	Graphs have huge contributions towards the performance improvement factor of a network.
0 	Some major contributors are de-Bruijn, Hypercube, Mesh and Pascal.
0	They had been studied a lot and different new features were always a part of research outcome.
0 	As per the definition of interconnection network it is equivalent that a suitable graph can represent the physical and logical layout very efficiently.
1 	In this present study Pascal graph is researched again and a new characteristics has been discovered.
0	From the perspective of network topologies Pascal graph and its properties were first studied more than two decades back.
0	Since then, a numerous graph models have emerged with potentials to be used as network topologies.
2	This new property is guaranteed to make an everlasting mark towards the reliability of this graph to be used as a substantial contributor as a computer network topology.
2	This shows its credentials over so many other topologies.
2	This study reviews the characteristics of the Pascal graph and the new property is established using appropriate algorithm and the results.


# 36
### http://arxiv.org/abs/1004.0596v1
## Effect of Inter Packet Delay in performance analysis of coexistence heterogeneous Wireless Packet Networks

0 	As the explosive growth of the ISM band usage continues, there are many scenarios where different systems operate in the same place at the same time.
0	One of growing concerns is the coexistence of heterogeneous wireless network systems.
0	For the successful deployment of mission-critical systems such as wireless sensor networks, it is required to provide a solution for the coexistence.
1	In this paper, we propose a new scheme using inter packet delay for the coexistence of IEEE 802.15.4 LRWPAN and IEEE 802.11b WLAN.
1 	To evaluate the effectiveness of the proposed scheme, measurement and simulation study are conducted using Qualnet 4.5 simulation software.
2 	The simulation results show that the proposed scheme is effective in performance improvement for coexistence network of IEEE 802.15.4 for various topologies.


# 37
### http://arxiv.org/abs/1004.1678v1
## Node Sensing & Dynamic Discovering Routes for Wireless Sensor Networks

0	The applications of Wireless Sensor Networks (WSN) contain a wide variety of scenarios.
0	In most of them, the network is composed of a significant number of nodes deployed in an extensive area in which not all nodes are directly connected.
0 	Then, the data exchange is supported by multihop communications.
0 	Routing protocols are in charge of discovering and maintaining the routes in the network.
0 	However, the correctness of a particular routing protocol mainly depends on the capabilities of the nodes and on the application requirements.
1 	This paper presents a dynamic discover routing method for communication between sensor nodes and a base station in WSN.
1 	This method tolerates failures of arbitrary individual nodes in the network (node failure) or a small part of the network (area failure).
1 	Each node in the network does only local routing preservation, needs to record only its neighbor nodes' information, and incurs no extra routing overhead during failure free periods.
1 	It dynamically discovers new routes when an intermediate node or a small part of the network in the path from a sensor node to a base station fails.
1 	In our planned method, every node decides its path based only on local information, such as its parent node and neighbor nodes' routing information.
1 	So, it is possible to form a loop in the routing path.
1 	We believe that the loop problem in sensor network routing is not as serious as that in the Internet routing or traditional mobile ad-hoc routing.
1 	We are trying to find all possible loops and eliminate the loops as far as possible in WSN.


# 38
### http://arxiv.org/abs/1004.4465v1
## Mobile Zigbee Sensor Networks

0 	OPNET Modeler accelerates network R&D and improves product quality through high-fidelity modeling and scalable simulation.
0	It provides a virtual environment for designing protocols and devices, and for testing and demonstrating designs in realistic scenarios prior to production.
1	OPNET Modeler supports 802.15.4 standard and has been used to make a model of PAN.
1	Iterations have been performed by changing the Power of the transmitter and the throughput will has been analyzed to arrive at optimal values.
1	An energy-efficient wireless home network based on IEEE 802.15.4, a novel architecture has been proposed.
1 	In this architecture, all nodes are classified into stationary nodes and mobile nodes according to the functionality of each node.
0	Mobile nodes are usually battery-powered, and therefore need low-power operation.
1	In order to improve power consumption of mobile nodes, effective handover sequence based on MAC broadcast and transmission power control based on LQ (link quality) are employed.
2	Experimental results demonstrate that by using the proposed architecture, communication time and power consumption of mobile nodes can be reduced by 1.2 seconds and 42.8%, respectively.


# 39
### http://arxiv.org/abs/1004.4759v1
## Indoor Positioning with Radio Location Fingerprinting

0 	An increasingly important requirement for many novel applications is sensing the positions of people, equipment, etc.
0	GPS technology has proven itself as a successfull technology for positioning in outdoor environments but indoor no technology has yet gained a similar wide-scale adoption.
0 	A promising indoor positioning technique is radio-based location fingerprinting, having the major advantage of exploiting already existing radio infrastructures, like IEEE 802.11, which avoids extra deployment costs and effort.
1 	The research goal of this thesis is to address the limitations of current indoor location fingerprinting systems.
1 	In particular the aim is to advance location fingerprinting techniques for the challenges of handling heterogeneous clients, scalability to many clients, and interference between communication and positioning.
2 	The wireless clients used for location fingerprinting are heterogeneous even when only considering clients for the same technology.
2	Heterogeneity is a challenge for location fingerprinting because it severely decreases the precision of location fingerprinting.
2 	To support many clients location fingerprinting has to address how to scale estimate calculation, measurement distribution, and distribution of position estimates.
2 	This is a challenge because of the number of calculations involved and the frequency of measurements and position updates.
2 	Positioning using location fingerprinting requires the measurement of, for instance, signal strength for nearby base stations.
2 	However, many wireless communication technologies block communication while collecting such measurements.
2	This interference is a challenge because it is not desirable that positioning disables communication.
1	An additional goal is to improve the conceptual foundation of location fingerprinting.
2 	A better foundation will aid researchers to better survey and design location fingerprinting systems.


# 40
### http://arxiv.org/abs/1004.4821v1
## Optimum Design of a 4x4 Planar Butler Matrix Array for WLAN Application

0 	In recent years, high-speed wireless communication is in vogue.
0 	In wireless communication systems, multipath fading, delay and interference occurres by reflection or diffraction.
0 	In a high-speed wireless communication, it becomes a necessary to separate desired signal from delay or interference signal.
0	Thus to overcome these problems Smart antenna systems have been developed.
0	Basically there are two types of smart antenna systems, one is Switched beam system and another Adaptive array system.
0	This paper presents the optimum design of a 4x4 plannar Butler matrix array as a key component of a switched beam smart antenna system, operating at 5.2 GHz for WLAN with a dielectric substrate, FR4 of er =4.9 and h=1.6mm.
0 	Conception details, simulation results and measurements are also given for the components (microstrip antenna, hybrid couplers, cross-coupler, phase shifter) used to implement the matrix.
1	In this dissertation, mathematical calculations for all the components using MATLAB is done and then every individual component is designed using the commercial software SONNET.
1 	Then these entire components have been combined on a single substrate and simulated using SONNET.


# 41
### http://arxiv.org/abs/1005.0952v1
## Effective Bandwidth Utilization in IEEE802.11 for VOIP

0	Voice over Internet protocol (VoIP) is one of the most important applications for the IEEE 802.11 wireless local area networks (WLANs).
0	For network planners who are deploying VoIP over WLANs, one of the important issues is the VoIP capacity.
0 	VoIP bandwidth consumption over a WAN is one of the most important factors to consider when building a VoIP infrastructure.
0	Failure to account for VoIP bandwidth requirements will severely limit the reliability of a VoIP system and place a huge burden on the WAN infrastructure.
0 	Less bandwidth utilization is the key reasons for reduced number of channel accesses in VOIP.
0 	But in the QoS point of view the free bandwidth of atleast 1-5% will improve the voice quality.
1	This proposal utilizes the maximum bandwidth by leaving 1-5% free bandwidth.
1	A Bandwidth Data rate Moderation (BDM) algorithm has been proposed which correlates the data rate specified in IEEE802.11b with the free bandwidth.
1 	At each time BDM will calculate the bandwidth utilization before sending the packet to improve performance and voice quality of VoIP.
1	The bandwidth calculation in BDM can be done by using Erlang and VOIP bandwidth calculator.
2	Finally, ns2 experimental study shows the relationship between bandwidth utilization, free bandwidth and data rate.
2	The paper concludes that marginal VoIP call rate has been increased by BDM algorithm.


# 42
### http://arxiv.org/abs/1005.4268v1
## An Adaptive Power Efficient Packet Scheduling Algorithm for Wimax Networks

0 	Admission control schemes and scheduling algorithms are designed to offer QoS services in 802.16/802.16e networks and a number of studies have investigated these issues.
0 	But the channel condition and priority of traffic classes are very rarely considered in the existing scheduling algorithms.
0	Although a number of energy saving mechanisms have been proposed for the IEEE 802.16e, to minimize the power consumption of IEEE 802.16e mobile stations with multiple real-time connections has not yet been investigated.
0	Moreover, they mainly consider non real- time connections in IEEE 802.16e networks.
1 	In this paper, we propose to design an adaptive power efficient packet scheduling algorithm that provides a minimum fair allocation of the channel bandwidth for each packet flow and additionally minimizes the power consumption.
1 	In the adaptive scheduling algorithm, packets are transmitted as per allotted slots from different priority of traffic classes adaptively, depending on the channel condition.
1 	Suppose if the buffer size of the high priority traffic queues with bad channel condition exceeds a threshold, then the priority of those flows will be increased by adjusting the sleep duty cycle of existing low priority traffic, to prevent the starvation.
2 	By simulation results, we show that our proposed scheduler achieves better channel utilization while minimizing the delay and power consumption.


# 43
### http://arxiv.org/abs/1006.2048v1
## Stochastic Approximation Algorithm for Optimal Throughput Performance of Wireless LANs

0 	Throughput improvement of the Wireless LANs has been a constant area of research.
0 	Most of the work in this area, focuses on designing throughput optimal schemes for fully connected networks (no hidden nodes).
0	But, we demonstrate that the proposed schemes, though perform optimally in fully connected network, achieve significantly lesser throughput even than that of standard IEEE 802.11 in a network with hidden nodes.
0	This motivates the need for designing schemes that provide near optimal performance even when hidden nodes are present.
0	The primary reason for the failure of existing protocols in the presence of hidden nodes is that these protocols are based on the model developed by Bianchi.
0	However this model does not hold when hidden nodes exist.
0 	Moreover, analyzing networks with hidden nodes is still an open problem.
0	Thus, designing throughput optimal schemes in networks with hidden nodes is particularly challenging.
0 	The novelty of our approach is that it is not based on any underlying mathematical model, rather it directly tunes the control variables so as to maximize the throughput.
1	We demonstrate that this model independent approach achieves maximum throughput in networks with hidden terminals as well.
1 	Apart from this major contribution, we present stochastic approximation based algorithms for achieving weighted fairness in a connected networks.
1	We also present a throughput optimal exponential backoff based random access algorithm.
1	We demonstrate that the exponential backoff based scheme may outperform an optimal p-persistent scheme in networks with hidden terminals.
2 	This demonstrates the merit of exponential backoff based random access schemes which was deemed unnecessary by results shown by Bianchi.


# 44
### http://arxiv.org/abs/1006.2552v1
## Similarity Analysis and Modeling in Mobile Societies: The Missing Link

0 	A new generation of "behavior-aware" delay tolerant networks is emerging in what may define future mobile social networks.
0 	With the introduction of novel behavior-aware protocols, services and architectures, there is a pressing need to understand and realistically model mobile users behavioral characteristics, their similarity and clustering.
0	Such models are essential for the analysis, performance evaluation, and simulation of future DTNs.
0 	This paper addresses issues related to mobile user similarity, its definition, analysis and modeling.
1	To define similarity, we adopt a behavioral-profile based on users location preferences using their on-line association matrix and its SVD, then calculate the behavioral distance to capture user similarity.
2	This measures the difference of the major spatio-temporal behavioral trends and can be used to cluster users into similarity groups or communities.
1	We then analyze and contrast similarity distributions of mobile user populations in two settings: (i) based on real measurements from four major campuses with over ten thousand users for a month, and (ii) based on existing mobility models, including random direction and time-varying community models.
2	Our results show a rich set of similar communities in real mobile societies with distinct behavioral clusters of users.
2	This is true for all the traces studied, with the trend being consistent over time.
2	Surprisingly, however, we find that the existing mobility models do not explicitly capture similarity and result in homogeneous users that are all similar to each other.
2 	Thus the richness and diversity of user behavioral patterns is not captured to any degree in the existing models.
2 	These findings strongly suggest that similarity should be explicitly captured in future mobility models, which motivates the need to re-visit mobility modeling in the future.


# 45
### http://arxiv.org/abs/1006.2684v1
## Enhancing the Authentication of Bank Cheque Signatures by Implementing Automated System Using Recurrent Neural Network

0 	The associatie memory feature of the Hopfield type recurrent neural network is used for the pattern storage and pattern authentication.
0	This paper outlines an optimization relaxation approach for signature verification based on the Hopfield neural network (HNN)which is a recurrent network.
1 	The standard sample signature of the customer is cross matched with the one supplied on the Cheque.
1 	The difference percentage is obtained by calculating the different pixels in both the images.
1 	The network topology is built so that each pixel in the difference image is a neuron in the network.
1	Each neuron is categorized by its states,which in turn signifies that if the particular pixel is changed.
2 	The network converges to unwavering condition based on the energy function which is derived in experiments.
0 	The Hopfield's model allows each node to take on two binary state values (changed/unchanged)for each pixel.
2	The performance of the proposed technique is evaluated by applying it in various binary and gray scale images.
2	This paper contributes in finding an automated scheme for verification of authentic signature on bank Cheques.
2 	The derived energy function allows a trade off between the influence of its neighborhood and its own criterion.
2 	This device is able to recall as well as complete partially specified inputs.
1	The network is trained via a storage prescription that forces stable states to correspond to (local)minima of a network "energy" function.



# 76
### http://arxiv.org/abs/1203.2167v1
## Design and Implementation of IEEE 802.15.4 Mac Protocol on FPGA

0 	The IEEE 802.15.4 is a wireless standard introduced for low power, low cost wireless communication with moderate data rates.
0 	In the next few years, it is expected that Low Rate Wireless Personal Area Networks (LR-WPAN) will be used in a wide variety of embedded applications, including home automation, industrial sensing and control, environmental monitoring and sensing.
1 	In these applications, numerous embedded devices running on batteries are distributed in an area communicating via wireless radios.
0 	This work presents a method which can be used for comparing current consumption of wireless data transfer embedded systems.
0 	This paper implements a small subset of the IEEE 802.15.4 protocol to achieve a point to point communication.
1 	The implemented protocol uses 802.15.4 MAC compliant data and acknowledgment packets.
1 	Current consumption is measured while doing one data packet transmission.
1 	Measurements are compared with existing work.
1 	IEEE 802.15.4 protocol implementation is done using Verilog language.
2 	Code implementation is done in such a manner so that it can be ported to any platform with minimal changes.
2 	It can also be modified to suit any special experimental setup requirements.


# 77
### http://arxiv.org/abs/1203.4841v1
## Achieving Congestion Diversity in Multi-hop Wireless Mesh Networks

0 	This paper reports on the first systematic study of congestion-aware routing algorithms for wireless mesh networks to achieve an improved end-end delay performance.
0 	In particular, we compare 802.11 compatible implementations of a set of congestion-aware routing protocols against our implementation of state of the art shortest path routing protocol (SRCR).
1 	We implement congestion-aware routing algorithms Backpressure (BP), Enhanced-Backpressure (E-BP) adapted from [1], [2] suitably adjusted for 802.11 implementation.
1 	We then propose and implement Congestion Diversity Protocol (CDP) adapted from [3] recognizing the limitations of BP and E-BP for 802.11-based wireless networks.
2 	SRCR solely utilizes link qualities, while BP relies on queue differential to route packets.
2	CDP and E-BP rely on distance metrics which take into account queue backlogs and link qualities in the network.
2 	E-BP computes its metric by summing the ETX and queue differential, while CDP determines its metric by calculating the least draining time to the destination.
2 	Our small testbed consisting of twelve 802.11g nodes enables us to empirically compare the performance of congestion-aware routing protocols (BP, E-BP and CDP) against benchmark SRCR.
2 	For medium to high load UDP traffic, we observe that CDP exhibits significant improvement with respect to both end-end delay and throughput over other protocols with no loss of performance for TCP traffic.
2 	Backpressure-based routing algorithms (BP and E-BP) show poorer performance for UDP and TCP traffic.
2 	Finally, we carefully study the effects of the modular approach to congestion-aware routing design in which the MAC layer is left intact


# 78
### http://arxiv.org/abs/1203.5874v2
## Optimizing Channel Access for Event-Driven Wireless Sensor Networks: Analysis and Enhancements

0 	We study the problem of medium access control in domain of event-driven wireless sensor networks (WSNs).
0 	In this kind of WSN, sensor nodes send data to sink node only when an event occurs in the monitoring area.
0 	The nodes in this kind of WSNs encounter correlated traffic as a subset of nodes start sending data by sensing a common event simultaneously.
0 	We wish to rethink of medium access control (MAC) for this type of traffic characteristics.
0 	For WSNs, many existing MAC protocols utilize the basic CSMA/CA strategy such as IEEE 802.11 Binary Exponential Backoff (BEB) algorithm to handle the collisions among packets when more than one node need to access the channel.
1 	We show that this BEB algorithm does not work well without incurring access delay or performance degradation due to increased number of collisions and retransmissions when nodes encounter correlated traffic.
1 	Based on above observations in mind, We present a Adaptive Random Backoff (ARB) algorithm that is capable of mitigating the impact of correlated traffic and capable of minimizing the chance of collisions.
2 	ARB is based on minor modifications of BEB.
2 	We show using numerical analysis that our proposals improve the channel access in terms of latency, throughput, and frame dropping probability as compared with IEEE 802.11 DCF.
2 	Simulations using NS-2 network simulator are conducted to validate the analytical results.


# 79
### http://arxiv.org/abs/1207.0163v3
## Optimizing TCP Performance in Multi-AP Residential Broadband Connections via Mini-Slot Access

0 	The high bandwidth demand of Internet applications has recently driven the need of increasing the residential download speed.
0 	A practical solution to the problem has been proposed aggregating the bandwidth of 802.11 Access Points (APs) backhauls in range via 802.11 connections.
0 	Since 802.11 devices are usually single-radio, the communication to multiple APs on different radio-channels requires the introduction of a time-division multiple access (TDMA) policy at the client station.
0 	Current investigation in this area supposes that there is a sufficient number of TCP flows to saturate the Asymmetric Digital Subscriber Line (ADSL) behind the APs.
0 	However, this may be not guaranteed according to the user traffic pattern.
0 	As a consequence, a TDMA policy introduces additional delays in the end-to-end transmissions that will cause degradation of the TCP throughput and an under-utilization of the AP backhauls.
0 	In this paper, we first perform an in-depth experimental analysis with a customized 802.11 driver of how the usage of multi-AP TDMA affects the observed Round-Trip-Time (RTT) of TCP flows.
0 	Then, we introduce a simple analytical model that accurately predicts the TCP RTT when accessing the wireless medium with a Multi-AP TDMA policy.
1 	Based on this model, we propose a resource allocation algorithm that runs locally at the station and it greatly reduces the observed TCP RTT with a very low computational cost.
2 	Our proposed scheme can improve up to 1:5 times the aggregate throughput observed by the station compared to state-of-the-art multi-AP TDMA allocations.
2 	We also show that the throughput performance of the algorithm is very close to the theoretical upper-bound in key simulation scenarios.


# 80
### http://arxiv.org/abs/1207.4265v1
## Spot: An accurate and efficient multi-entity device-free WLAN localization system

0 	Device-free (DF) localization in WLANs has been introduced as a value-added service that allows tracking indoor entities that do not carry any devices.
0 	Previous work in DF WLAN localization focused on the tracking of a single entity due to the intractability of the multi-entity tracking problem whose complexity grows exponentially with the number of humans being tracked.
0 	In this paper, we introduce Spot as an accurate and efficient system for multi-entity DF detection and tracking.
0 	Spot is based on a probabilistic energy minimization framework that combines a conditional random field with a Markov model to capture the temporal and spatial relations between the entities' poses.
1 	A novel cross-calibration technique is introduced to reduce the calibration overhead of multiple entities to linear, regardless of the number of humans being tracked.
1 	This also helps in increasing the system accuracy.
1 	We design the energy minimization function with the goal of being efficiently solved in mind.
1 	We show that the designed function can be mapped to a binary graph-cut problem whose solution has a linear complexity on average and a third order polynomial in the worst case.
1 	We further employ clustering on the estimated location candidates to reduce outliers and obtain more accurate tracking.
2 	Experimental evaluation in two typical testbeds, with a side-by-side comparison with the state-of-the-art, shows that Spot can achieve a multi-entity tracking accuracy of less than 1.1m.
2 	This corresponds to at least 36% enhancement in median distance error over the state-of-the-art DF localization systems, which can only track a single entity.
2 	In addition, Spot can estimate the number of entities correctly to within one difference error.
2 	This highlights that Spot achieves its goals of having an accurate and efficient software-only DF tracking solution of multiple entities in indoor environments.


# 81
### http://arxiv.org/abs/1207.5298v4
## Building Blocks of Physical-layer Network Coding

0 	This paper investigates the fundamental building blocks of physical-layer network coding (PNC).
0 	Most prior work on PNC focused on its application in a simple two-way-relay channel (TWRC) consisting of three nodes only.
0 	Studies of the application of PNC in general networks are relatively few.
0 	This paper is an attempt to fill this gap.
0 	We put forth two ideas: 1) A general network can be decomposed into small building blocks of PNC, referred to as the PNC atoms, for scheduling of PNC transmissions. 2) We identify nine PNC atoms, with TWRC being one of them.
2 	Three major results are as follows.
2 	First, using the decomposition framework, the throughput performance of PNC is shown to be significantly better than those of the traditional multi-hop scheme and the conventional network coding scheme. For example, under heavy traffic volume, PNC can achieve 100% throughput gain relative to the traditional multi-hop scheme.
2 	Second, PNC decomposition based on a variety of different PNC atoms can yield much better performance than PNC decomposition based on the TWRC atom alone.
2 	Third, three out of the nine atoms are most important to good performance.
2 	Specifically, the decomposition based on these three atoms is good enough most of the time, and it is not necessary to use the other six atoms.


# 82
### http://arxiv.org/abs/1207.5736v1
## Differentiated QoS with Modified C/I Based Scheduling Algorithm

0 	Second-generation (2G) digital cellular systems constitute the majority of cellular communication deployed today.
0 	A variety of services of 2G systems has increased significantly and this will continue to grow even further in the emerging third-generation (3G) systems.
0 	Universal Mobile Telecommunication System (UMTS) is a third-generation mobile communications system which uses the Wide-Band Code Division Multiple Access (WCDMA) technique to support a wide variety of services, like speech, video telephony, Internet browsing, etc.
0 	These services require a wide range of Quality of Service (QoS) requirements.
0 	QoS is an important issue as the number of multimedia services increases day by day.
0 	Differentiated QoS methods allow the differentiation of users based on their priority levels and channel conditions so that the network can allocate the bandwidth for a particular request based on the QoS requirements.
0 	These requirements are controlled by Radio Resource Management (RRM) mechanisms.
0 	In this paper we have proposed two RRM algorithms which are modification to the existing scheduling algorithms.
0 	One is Prioritized C/I scheduling, which takes the priorities into consideration, and this algorithm serves the user with highest priority.
0 	Other algorithm is Modified Inverse C/I scheduling, which takes channel conditions into consideration and serves the users in degraded conditions, thereby improving QoS.
1 	The performance evaluation of two algorithms is done with EURANE extensions for NS-2.
2 	Simulation results shows the improvement in QoS for the users who are at equidistance from Base Station (BS) but requesting for different services by implementing Prioritized C/I scheduling and also for the users who are in degraded conditions by implementing Modified Inverse C/I scheduling when compared to Max C/I and Inverse C/I scheduling algorithm respectively.


# 83
### http://arxiv.org/abs/1208.0384v1
## Global Adaptive Routing Algorithm Without Additional Congestion Propagation Network

0 	Adaptive routing algorithm has been employed in multichip interconnection networks in order to improve network performance.
0 	Does a algorithm use local or global network state?
0 	This is the key question in adaptive routing.
0 	In many traffic patterns, the ignorance of global network state, leading to routing selection based only on local congestion information, tends to violate global load balance.
0 	To attack the load balance issue in adapting routing, some global adaptive routing algorithms introduce a congestion propagation network to obtain global network status information, such as Regional Congestion Awareness (RCA) and Destination Based Adaptive Routing (DBAR).
0 	However, the congestion propagation network leads to additional power and area consumption which cannot be ignored.
0 	From another view, if we just increase the bandwidth between neighbor nodes with the wires used to build the congestion propagation network, the network performance could be improved as well.
0 	In this paper, we propose a global adaptive routing algorithm without employing the additional congestion propagation network.
1 	Our algorithm obtains the global network state in a novel way, and can offer significant improvement than the base-line local adaptive routing algorithm (xy-adaptive algorithm which selects routing based on local congestion information in each hop) for both medium and high injection rates.
1 	In wormhole flow control, all the routing information (flit id, source node id, destination node id, vc id and address) is contained in head flit, and data is carried in body flits.
1 	As a result, there are always many free bits in the head flit, especially when the bandwidth is 128-bits which is normal in interconnection network design.
1 	Then, we can use these free bits in the head flit to propagate global congestion information but not increase the number of flits.


# 84
### http://arxiv.org/abs/1208.1896v1
## Bittorrent Network Traffic Forecasting With ARMA

0 	In recent years, there are some major changes in the way content is being distributed over the network.
0 	The content distribution techniques have recently started to embrace peer-to-peer (P2P) systems as an alternative to the traditional client-server architecture.
0 	P2P systemsthat are based on the BitTorrent protocol uses end-users' resources to provide a cost effective distribution of bandwidth intensive content to thousands of users.
0 	The BitTorrent protocol system offers a scalable mechanism for distributing a large volume of data to a set of peers over the Internet.
0 	With the growing demand for file sharing and content distribution, BitTorrent has become one of the most popular Internet applications and contributes to a signification fraction of the Internet traffic.
0 	With the wide usage of the BitTorrent protocol system, it has basically solved one of the major problems where data can be quickly transferred to a group of interested parties.
0 	The strength of the BitTorrent protocol lies in efficient bandwidth utilization for the downloading and uploading processes.
0 	However, the usage of BitTorrent protocol also causes latency for other applications in terms of network bandwidth which in turn has caused concerns for the Internet Service Providers, who strives for quality of service for all their customers.
0 	In this paper, we study the network traffic patterns of theBitTorrent network traffic and investigate its behavior by usingthe time series ARMA model.
0 	Our experimental results show that BitTorrent network traffic can be modeled and forecasted by using ARMA models.
1 	We compared and evaluated the forecasted network traffic with the real traffic patterns.
2 	This modeling can be utilized by the Internet Service Providers to manage their network bandwidth and also detect any abnormality in their network.


# 85
### http://arxiv.org/abs/1208.2314v1
## Analytical Study of Pre-congestion notification (PCN) techniques

0 	Maintaining the quality of service (QOS) and controlling the network congestion are quite complicated tasks.
0 	They cause degrading the performance of the network, and disturbing the continuous communication process.
0 	To overcome these issues, one step towards this dilemma has been taken in form of Pre-congestion notification (PCN) technique.
0 	PCN uses a packet marking technique within a PCN domain over IP networks.
0 	It is notified by egress node that works as guard at entry point of network.
0 	Egress node gives feedback to communicating servers whether rate on the link is exceeded than configured admissible threshold or within the limit.
0 	Based on this feedback, admission decisions are taken to determine whether to allow/block new coming flows or terminate already accepted.
0 	The actual question is about selection of right algorithm for PCN domain.
1 	In this paper, we investigate the analytical behavior of some known PCN algorithms.
1 	We make slide modifications in originality of PCN algorithms without disquieting working process in order to employ those within similar types of scenarios.
0 	Our goal is to simulate them either in highly congested or less congested realistic scenarios.
2 	On the basis of simulation done in ns2, we are able to recommend each PCN algorithm for specific conditions.
2 	Finally, we develop a benchmark that helps researchers and scientific communities to pick the right algorithm.
2 	Furthermore, the benchmark is designed to achieve specific objectives according to the users' requirements without congesting the network.


# 86
### http://arxiv.org/abs/1208.2409v1
## Transmission Delay of Multi-hop Heterogeneous Networks for Medical Applications

0 	Nowadays, with increase in ageing population, Health care market keeps growing.
0 	There is a need for monitoring of Health issues.
0 	Body Area Network consists of wireless sensors attached on or inside human body for monitoring vital Health related problems e.g, Electro Cardiogram (ECG), ElectroEncephalogram (EEG), ElectronyStagmography(ENG) etc.
0 	Data is recorded by sensors and is sent towards Health care center.
0 	Due to life threatening situations, timely sending of data is essential.
0 	For data to reach Health care center, there must be a proper way of sending data through reliable connection and with minimum delay.
1 	In this paper transmission delay of different paths, through which data is sent from sensor to Health care center over heterogeneous multi-hop wireless channel is analyzed.
1 	Data of medical related diseases is sent through three different paths.
1 	In all three paths, data from sensors first reaches ZigBee, which is the common link in all three paths.
1 	After ZigBee there are three available networks, through which data is sent.
1 	Wireless Local Area Network (WLAN), Worldwide Interoperability for Microwave Access (WiMAX), Universal Mobile Telecommunication System (UMTS) are connected with ZigBee.
1 	Each network (WLAN, WiMAX, UMTS) is setup according to environmental conditions, suitability of device and availability of structure for that device.
1 	Data from these networks is sent to IP-Cloud, which is further connected to Health care center.
0 	Main aim of this paper is to calculate delay of each link in each path over multihop wireless channel.


# 87
### http://arxiv.org/abs/1208.5526v1
## Coded Path Protection Part 1: Efficient Conversion of Sharing to Coding

0 	Link failures in wide area networks are common and cause significant data losses.
0 	Mesh-based protection schemes offer high capacity efficiency but they are slow and require complex signaling.
0 	Additionally, real-time reconfigurations of cross-connects threaten their transmission integrity.
0 	On the other hand, there are other schemes that are proactive.
0 	Proactivity results in higher restoration speed, lower signaling complexity, and higher transmission integrity.
1 	This paper introduces a coding-based proactive protection scheme, named Coded Path Protection (CPP).
1 	In CPP, a backup stream of the primary data is encoded with other data streams, resulting in capacity savings.
1 	In addition to a systematic approach of building valid coding structures, this paper presents an optimal and simple capacity placement and coding group formation algorithm.
1 	The algorithm converts the sharing structure of any solution of a Shared Path Protection (SPP) technique into a coding structure with minimum extra capacity.
1 	We conducted quantitative and qualitative comparisons of our technique with the SPP.
2 	Simulation results confirm that CPP provides faster link failure recovery than SPP while it incurs marginal extra capacity beyond that of SPP.
1 	In this Part 1 of the paper, we describe the theory and an algorithm for converting a given SPP solution into a CPP solution.


# 88
### http://arxiv.org/abs/1210.3047v1
## A Performance Analysis of LAR Protocol for Vehicular Ad Hoc Networks in City Scenarios

0 	In this paper, performance analysis of Location Aided Routing (LAR) protocol in different city scenarios has been done.
0 	The mobility model considered is Manhattan model.
0 	This mobility model used to emulate the movement pattern of nodes i.e., vehicles on streets defined by maps.
0 	Our objective is to provide a qualitative analysis of the LAR protocol in different city scenarios in Vehicular Ad hoc Networks.
1 	We have considered three different city scenarios for the analysis of the protocol.
1 	The simulation work has been conducted using the Glomosim 2.03 simulator.
2 	The results show that LAR1 protocol achieves maximum packet delivery ratio is 99.68 % and maximum average end-to-end delay is 7.319969 ms when the network is sparsely populated.
2 	Further, for densely populated network maximum achieved packet delivery ratio is 87.58% and average end-to-end delay is 0.017684 ms.


# 89
### http://arxiv.org/abs/1210.3147v1
## Performance Analysis of Probabilistic Rebroadcasting in Grid FSR for MANET

0 	Mobile Ad-hoc Network (MANET) is the self organizing collection of mobile nodes.
0 	The communication in MANET is done via a wireless media.
0 	Ad hoc wireless networks have massive commercial and military potential because of their mobility support.
0 	Due to demanding real time multimedia applications, Quality of Services (QoS) support in such infrastructure less networks have become essential.
0 	QoS routing in mobile Ad-Hoc networks is challenging due to rapid change in network topology.
0 	In this paper, we focused to reduce flooding performance of the Fisheye State Routing (FSR) protocol in Grid using ns-2 network simulator under different performance metrics scenario in respect to number of Nodes.
0 	For example, the connection establishment is costly in terms of time and resource where the network is mostly affected by connection request flooding.
1 	The proposed approach presents a way to reduce flooding in MANETs.
1 	Flooding is dictated by the propagation of connection-request packets from the source to its neighborhood nodes.
1 	The proposed architecture embarks on the concept of sharing neighborhood information.
1 	The proposed approach focuses on exposing its neighborhood peer to another node that is referred to as its friend-node, which had requested/forwarded connection request.
1 	If there is a high probability for the friend node to communicate through the exposed routes, this could improve the efficacy of bandwidth utilization by reducing flooding, as the routes have been acquired, without any broadcasts.
1 	Friendship between nodes is quantized based on empirical computations and heuristic algorithms.
1 	The nodes store the neighborhood information in their cache that is periodically verified for consistency.
2 	Simulation results show the performance of this proposed method.


# 90
### http://arxiv.org/abs/1210.3702v1
## Estimation and compensation of inter carrier interference in wimax physical layer under various channel models

0 	WiMAX is Wireless Interoperability for Microwave Access has emerged as a promising solution for transmission of higher data rates for fixed and mobile applications.
0 	IEEE 802.16d and e are the standards proposed.
0 	To attain higher data rates the Multi Carrier System with Multiple Input and Multiple Output MIMO is incorporated in the WiMAX.
0 	And all these sub carriers are considered to be orthogonal to each other.
0 	As the number of sub carriers is increased there is no guarantee of sustained orthogonality, i.e. at some point the carriers are not independent to each other, and hence where the orthogonality can be loosed which leads to interference and also owing to the synchronization between transmitter and receiver local oscillator, it causes interference known as Inter Carrier Interference (ICI).
1 	In this scheme at the transmitter side the modulated data and a few predefined pilot symbols are mapped onto the non neighboring sub carriers with weighting coefficients of +1 and -1.
1 	With the aid of pilot symbols the frequency offset is exactly estimated by using Maximum Likelihood Estimation MLE and hence can be minimized.
1 	At demodulation stage the received signals are linearly combined along with their weighted oefficients and pilot symbols, called as Pilot Aided Self Cancellation Method PASCS.
2 	The simulations are carried out on Stanford University Interim (SUI)channels.
2 	The simulation results shows that by incorporating this method into WiMAX systems it performs better when the Line Of Sight (LOS) component is present in the transmission and also it improves the Bit Error Rate (BER) and Carrier to Interference Ratio (CIR).
2 	The CIR can be improved 20 dB.
1 	In this paper the effectiveness of PASCS scheme is compared with the Self Cancellation Method (SCM).
2 	It provides accurate estimation of frequency offset and when residual CFO is less significant the ICI can be diminished successfully.

# 91
### http://arxiv.org/abs/1210.5917v1
## Dynamic Link adaptation Based on Coexistence-Fingerprint Detection for WSN


0         Operating in the ISM band, the wireless sensor network (WSN) risks being interfered by other concurrent networks.
0        Our concerns are the technologies that do not perform listening before transmission such as Bluetooth, and the ones that do not detect other technologies due to their channel sensing techniques like WIFI.
1         To overcome this issue a WSN node should be able to identify the presence of such technologies.
2         This will allow deducing the characteristics of the generated traffic of these technologies, and thus the behavior of the channel can be predicted.
2         These predictions would help to trigger adequate reactions as to avoid or synchronize with the concurrent net- works.
0         Many works exist on link adaptation, but they concern blind adaptations which are unintelligent and solve momentarily the problem that may reappear over time.
0         In this paper, we perform several experiments on a real testbed to categorize the model of the bit errors in corrupted received packets.
1         These experiments are performed under different conditions of channel noise and interferences.
2         This allows us to identify each corruption pattern as a fingerprint for the interfering technology.
1         Then we propose the mechanism FIM to identify on the fly the source of the corruption.
1         With an implementation on "Tmote Sky" motes using Tinyos1.x, We demonstrate the use of FIM for link adaptation in a coexistence environment.
2         Our mechanism led to throughput improvements of 87%-100% depending on the transmission rate and channel quality.




# 92
### http://arxiv.org/abs/1211.1782v1
## Resource Allocation in Mobile WiMAX Network: An Optimal Approach


0         In the last few years there has been significant growth in the area of wireless communication.
0        IEEE 802.16/WiMAX is the network which is designed for providing high speed wide area broadband wireless access; WiMAX is an emerging wireless technology for creating multi-hop Mesh network.
1         Future generation networks will be characterized by variable and high data rates, Quality of Services (QoS), seamless mobility both within a network and between networks of different technologies and service providers.
0         A technology is developed to accomplish these necessities is regular by IEEE, is 802.16, also called as WiMAX (Worldwide Interoperability for Microwave Access).
0        This architecture aims to apply Long range connectivity, High data rates, High security, Low power utilization and Excellent Quality of Services and squat deployment costs to a wireless access technology on a metropolitan level.
2         In this paper we have observed the performance analysis of location based resource allocation for WiMAX and WLAN-WiMAX client and in second phase we observed the rate-adaptive algorithms.
1         We know that base station (BS) is observed the ranging first for all subscribers then established the link between them and in final phase they will allocate the resource with Subcarriers allocation according to the demand (UL) i.e. video, voice and data application.
1         We propose linear approach, Active-Set optimization and Genetic Algorithm for Resource Allocation in downlink Mobile WiMAX networks.
2         Purpose of proposed algorithms is to optimize total throughput.
2        Simulation results show that Genetic Algorithm and Active-Set algorithm performs better than previous methods in terms of higher capacities but GA have high complexity then active set.




# 93
### http://arxiv.org/abs/1211.4294v1
## Effect of AWGN & Fading (Raleigh & Rician) channels on BER performance of a WiMAX communication System


0         The emergence of WIMAX has attracted significant interests from all fields of wireless communications including students, researchers, system engineers and operators.
0         The WIMAX can also be considered to be the main technology in the implementation of other networks like wireless sensor networks.
0         Developing an understanding of the WIMAX system can be achieved by looking at the model of the WIMAX system.
0         This paper discusses the model building of the WIMAX physical layer using computer MATLAB 7.5 versions.
0        This model is a useful tool for BER (Bit error rate) performance evaluation for the real data communication by the WIMAX physical layer under different communication channels AWGN and fading channel (Rayleigh and Rician), different channel encoding rates and digital modulation schemes which is described in this paper.
0        This paper investigates the effect of communication channels of IEEE 802.16 OFDM based WIMAX Physical Layer.
1        The performance measures we presented in this paper are: the bit error rate (BER) versus the ratio of bit energy to noise power spectral density (Eb/No).
0         The system parameters used in this paper are based on IEEE 802.16 standards.
2        The simulation model built for this research work, demonstrates that AWGN channel has better performance than Rayleigh and Rician fading channels.
1         Synthetic data is used to simulate this research work.




# 94
### http://arxiv.org/abs/1211.5720v1
## Cognitive Radio Transmission Strategies for Primary Markovian Channels


0         A fundamental problem in cognitive radio systems is that the cognitive radio is ignorant of the primary channel state and, hence, of the amount of actual harm it inflicts on the primary license holder.
0         Sensing the primary transmitter does not help in this regard.
1         To tackle this issue, we assume in this paper that the cognitive user can eavesdrop on the ACK/NACK Automatic Repeat reQuest (ARQ) fed back from the primary receiver to the primary transmitter.
1         Assuming a primary channel state that follows a Markov chain, this feedback gives the cognitive radio an indication of the primary link quality.
1         Based on the ACK/NACK received, we devise optimal transmission strategies for the cognitive radio so as to maximize a weighted sum of primary and secondary throughput.
1         The actual weight used during network operation is determined by the degree of protection afforded to the primary link.
1         We begin by formulating the problem for a channel with a general number of states.
1         We then study a two-state model where we characterize a scheme that spans the boundary of the primary-secondary rate region.
1         Moreover, we study a three-state model where we derive the optimal strategy using dynamic programming.
1         We also extend our two-state model to a two-channel case, where the secondary user can decide to transmit on a particular channel or not to transmit at all.
2         We provide numerical results for our optimal strategies and compare them with simple greedy algorithms for a range of primary channel parameters.
2         Finally, we investigate the case where some of the parameters are unknown and are learned using hidden Markov models (HMM).


# 96
### http://arxiv.org/abs/1301.1294v2
## FAST CLOUD: Pushing the Envelope on Delay Performance of Cloud Storage with Coding


0        Our paper presents solutions that can significantly improve the delay performance of putting and retrieving data in and out of cloud storage.
1         We first focus on measuring the delay performance of a very popular cloud storage service Amazon S3.
2         We establish that there is significant randomness in service times for reading and writing small and medium size objects when assigned distinct keys.
2         We further demonstrate that using erasure coding, parallel connections to storage cloud and limited chunking (i.e., dividing the object into a few smaller objects) together pushes the envelope on service time distributions significantly (e.g., 76%, 80%, and 85% reductions in mean, 90th, and 99th percentiles for 2 Mbyte files) at the expense of additional storage (e.g., 1.75x).
2         However, chunking and erasure coding increase the load and hence the queuing delays while reducing the supportable rate region in number of requests per second per node.
0         Thus, in the second part of our paper we focus on analyzing the delay performance when chunking, FEC, and parallel connections are used together.
1         Based on this analysis, we develop load adaptive algorithms that can pick the best code rate on a per request basis by using off-line computed queue backlog thresholds.
2         The solutions work with homogeneous services with fixed object sizes, chunk sizes, operation type (e.g., read or write) as well as heterogeneous services with mixture of object sizes, chunk sizes, and operation types.
1         We also present a simple greedy solution that opportunistically uses idle connections and picks the erasure coding rate accordingly on the fly.
2         Both backlog and greedy solutions support the full rate region and provide best mean delay performance when compared to the best fixed coding rate policy.
2         Our evaluations show that backlog based solutions achieve better delay performance at higher percentile values than the greedy solution.




# 97
### http://arxiv.org/abs/1301.7245v1
## Femtocell Architectures with Spectrum Sharing for Cellular Radio Networks


0         Femtocells are an emerging technology aimed at providing gains to both network operators and end-users.
0         These gains come at a cost of increased interference, specifically the cross network interference between the macrocell and femtocell networks.
0         This interference is one of the main performance limiting factors in allowing an underlaid femtocell network to share the spectrum with the cellular network.
1         To manage this interference, we first propose a femtocell architecture that orthog- onally partitions the network bandwidth between the macrocell and femtocell networks.
2         This scheme eliminates the cross network interference thus giving the femtocells more freedom over their use of the spectrum.
2        Specifically, no interference constraint is imposed by the cellular network allowing femto users to transmit at a constant power on randomly selected channels.
2         Although simple, this scheme is enough to give gains up to 200% in sum rate.
1         We then propose a second architecture where both networks share the bandwidth simultaneously.
1         A femtocell power control scheme that relies on minimal coordination with the macrocell base station is used in conjunction with an interference sensing channel assignment mechanism.
2         These two schemes together yield sum rate gains up to 200%.
1         We then develop a technique for macro users to join a nearby femtocell and share a common chan- nel with a femtocell user through the use of successive interfer- ence cancellation.
2         By adding this mechanism to the power control and channel assignment schemes, we show sum rate gains over 300% and up to 90% power savings for macrocell users.




# 98
### http://arxiv.org/abs/1303.5365v2
## Improving Network Efficiency by Removing Energy Holes in WSNs


0        Cluster based Wireless Sensor Networks (WSNs) have been widely used for better performance in terms of energy efficiency.
0         Efficient use of energy is challenging task of designing these protocols.
0         Energy holedare created due to quickly drain the energy of a few nodes due to non-uniform distribution in the network.
0         Normally, energy holes make the data routing failure when nodes transmit data back to the base station.
1         We proposedEnergy-efficient HOleRemoving Mechanism (E-HORM) technique to remove energy holes.
1         In this technique, we use sleep and awake mechanism for sensor nodes to save energy.
1         This approach finds the maximum distance node to calculate the maximum energy for data transmission.
1         We considered it as a threshold energy Eth.
1         Every node first checks its energy level for data transmission.
1         If the energy level is less than Eth, it cannot transmit data.
1         We also explain mathematically the energy consumption and average energy saving of sensor nodes in each round.
2         Extensive simulations showed that when use this approach for WSNs significantly helps to extend the network lifetime and stability period.




# 99
### http://arxiv.org/abs/1306.1651v1
## Accurate Indoor Localization Using Acoustic Direction Finding via Smart Phones


1        We propose and implement a novel indoor localization scheme, Swadloon, built upon an accurate acoustic direction finding.
0         Swadloon leverages sensors of the smartphone without the requirement of any specialized devices.
0         The scheme Swadloon does not rely on any fingerprints and is very easy to use: a user only needs to shake the phone for a short duration before walking and localization.
1         Our Swadloon design exploits a key observation: the relative shift and velocity of the phone-shaking movement corresponds to the subtle phase and frequency shift of the Doppler effects experienced in the received acoustic signal by the phone.
1         A novel method is designed to derive the direction from the phone to the acoustic source by combining the velocity calculated from the subtle Doppler shift with the one from the inertial sensors of the phone.
1         Then a real-time precise localization and tracking is enabled by using a few anchor speakers with known locations.
0         Major challenges in implementing Swadloon are to measure the frequency shift precisely and to estimate the shaking velocity accurately when the speed of phone-shaking is low and changes arbitrarily.
1         We propose rigorous methods to address these challenges, then design and deploy Swadloon in several floors of an indoor building each with area about 2000m^2.
2         Our extensive experiments show that the mean error of direction finding is around 2.1 degree when the acoustic source is within the range of 32m.
2         For indoor localization, the 90-percentile errors are under 0.92m, while the maximum error is 1.73m and the mean is about 0.5m.
2         For real-time tracking, the errors are within 0.4m for walks of 51m.




# 100
### http://arxiv.org/abs/1306.6428v1
## Internet Control Plane Event Identification using Model Based Change Point Detection Techniques


0        In the raise of many global organizations deploying their data centers and content services in India, the prefix reachability performance study from global destinations garners our attention.
0         The events such as failures and attacks occurring in the Internet topology have impact on Autonomous System (AS) paths announced in the control plane and reachability of prefixes from spatially distributed ASes.
0         As a consequence the customer reachability to the services in terms of increased latency and outages for a short or long time are experienced.
0         The challenge in control plane event detection is when the data plane traffic is able to reach the intended destinations correctly.
0         However detection of such events are crucial for the operations of content and data center industries.
1         By monitoring the spatially distributed routing table features like AS path length distributions, spatial prefix reachability distribution and covering to overlap route ratio, we can detect the control plane events.
1         In our work, we study prefix AS paths from the publicly available route-view data and analyze the global reachability as well as reachability to Indian AS topology.
1         To capture the spatial events in a single temporal pattern, we propose a counting based measure using prefixes announced by x % of spatial peers.
2         Employing statistical characteristics change point detection and temporal aberration algorithm on the time series of the proposed measure, we identify the occurrence of long and stochastic control plane events.
2         The impact and duration of the events are also quantified.
2         We validate the mechanisms over the proposed measure using the SEA-Me-We4 cable cut event manifestations in the control plane of Indian AS topology.
0         The cable cut events occurred on 6th June 2012 (long term event) and 17th April 2012 (stochastic event) are considered for validation.




# 101
### http://arxiv.org/abs/1307.0084v2
## Catch a Breath: Non-invasive Respiration Rate Monitoring via Wireless Communication


0         Radio signals are sensitive to changes in the environment, which for example is reflected on the received signal strength (RSS) measurements of low-cost wireless devices.
0         This information has been used effectively in the past years e.g. in device-free localization and tracking.
0         Recent literature has also shown that the fading information of the wireless channel can be exploited to estimate the breathing rate of a person in a non-invasive manner; a research topic we address in this paper.
0         To the best of our knowledge, we demonstrate for the first time that the respiration rate of a person can be accurately estimated using only a single IEEE 802.15.4 compliant TX-RX pair.
1         We exploit channel diversity, low-jitter periodic communication, and oversampling to enhance the breathing estimates, and make use of a decimation filter to decrease the computational requirements of breathing estimation.
1         In addition, we develop a hidden Markov model (HMM) to identify the time instances when breathing estimation is not possible, i.e., during times when other motion than breathing occurs.
2         We experimentally validate the accuracy of the system and the results suggest that the respiration rate can be estimated with a mean error of 0.03 breaths per minute, the lowest breathing rate error reported to date using IEEE 802.15 4 compliant transceivers.
2         We also demonstrate that the breathing of two people can be monitored simultaneously, a result not reported in earlier literature.




# 102
### http://arxiv.org/abs/1307.3402v1
## Improving Data Security in Infrastructure Networks Based on Unipath Routing


0         An infrastructure network is a self-organizing network which uses Access Point (AP) of wireless links that connecting one node with another.
0         These nodes can communicate without using ad hoc, instead these nodes form an arbitrary topology (BSS/ESS) in which these nodes play the role of routers.
0         Though the efficiency of Infrastructure networks is high, they are highly vulnerable to security attacks.
0         Detecting/Preventing these attacks over the network is highly challenging task.
0         Many solutions are proposed to provide authentication, confidentiality, availability, secure routing and intrusion avoidance in infrastructure networks.
0         Providing security in such dynamically changing networks is a hard task.
0         Characteristic of infrastructure network should also be taken into consideration in order to design efficient solutions.
1         In this study, we focus on efficiently increasing the flow transmission confidentiality in infrastructure networks based on multi-path routing.
1         In order to increase confidentiality of transmitted data, we take advantage of the existence of multiple paths between nodes in an infrastructure network with the help of Access Point.
1         In this approach the original data is split into package and are forwarded through access point.
1         The encrypted packets are then forwarded in different disjoint paths that exist between sender and receiver.
1         Even if an attacker succeeds to obtain one or more transmitted packets, the probability of reconstructing the original message is very low.




# 103
### http://arxiv.org/abs/1307.6349v1
## Communicating Is Crowdsourcing: Wi-Fi Indoor Localization with CSI-based Speed Estimation


0         Numerous indoor localization techniques have been proposed recently to meet the intensive demand for location based service, and Wi-Fi fingerprint-based approaches are the most popular and inexpensive solutions.
0         Among them, one of the main trends is to incorporate the built-in sensors of smartphone and to exploit crowdsourcing potentials.
0         However the noisy built-in sensors and multi-tasking limitation of underline OS often hinder the effectiveness of these schemes.
0         In this work, we propose a passive crowdsourcing CSI-based indoor localization scheme, C2 IL.
0         Our scheme C2 IL only requires the locating-device (e.g., a phone) to have a 802.11n wireless connection, and it does not rely on inertial sensors only existing in some smartphones.
0         C2 IL is built upon our innovative method to accurately estimate the moving distance purely based on 802.11n Channel State Information (CSI).
0         Our extensive evaluations show that the moving distance estimation error of our scheme is within 3% of the actual moving distance regardless of varying speeds and environment.
0         Relying on the accurate moving distance estimation as constraints, we are able to construct a more accurate mapping between RSS fingerprints and location.
1         To address the challenges of collecting fingerprints, a crowdsourcing- based scheme is designed to gradually establish the mapping and populate the fingerprints.
1         In C2 IL, we design a trajectory clustering-based localization algorithm to provide precise real-time indoor localization and tracking.
1         We developed and deployed a practical working system of C2 IL in a large office environment.
2         Extensive evaluation results indicate that our scheme C2 IL provides accurate localization with error 2m at 80% at very complex indoor environment with minimal overhead.




# 104
### http://arxiv.org/abs/1307.7111v1
## LPCH and UDLPCH: Location-aware Routing Techniques in WSNs


0        Wireless sensor nodes along with Base Station (BS) constitute a Wireless Sensor Network (WSN).
0         Nodes comprise of tiny power battery.
0         Nodes sense the data and send it to BS.
0         WSNs need protocol for efficient energy consumption of the network.
0         In direct transmission and minimum transmission energy routing protocols, energy consumption is not well distributed.
0         However, LEACH (Low-Energy Adaptive Clustering Hierarchy) is a clustering protocol; randomly selects the Cluster Heads (CHs) in each round.
0         However, random selection of CHs does not guarantee efficient energy consumption of the network.
1         Therefore, we proposed new clustering techniques in routing protocols, Location-aware Permanent CH (LPCH) and User Defined Location-aware Permanent CH (UDLPCH).
1         In both protocols, network field is physically divided in to two regions, equal number of nodes are randomly deployed in each region.
1         In LPCH, number of CHs are selected by LEACH algorithm in first round.
1         However in UDLPCH, equal and optimum number of CHs are selected in each region, throughout the network life time number of CHs are remain same.
2         Simulation results show that stability period and throughput of LPCH is greater than LEACH, stability period and throughput of UDLPCH is greater than LPCH.




# 105
### http://arxiv.org/abs/1309.2208v1
## A Novel Methodology to Overcome Routing Misbehavior in MANET using Retaliation Model


0         MANET is a cooperative network in which nodes are responsible for forwarding as well as routing.
0         Noncooperation is still a big challenge that certainly degrades the performance and reliability of a MANET.
0         This paper presents a novel methodology to overcome routing misbehavior in MANET using Retaliation Model.
1         In this model node misbehavior is watched and an equivalent misbehavior is given in return.
1         This model employs several parameters such as number of packets forwarded, number of packets received for forwarding, packet forwarding ratio etc. to calculate Grade and Bonus Points.
1         The Grade is used to isolate selfish nodes from the routing paths and the Bonus Points defines the number of packets dropped by an honest node in retaliation over its misconducts.
1         The implementation is done in "GloMoSim" on top of the DSR protocol.
2         We obtained up to 40% packet delivery ratio with a cost of a minimum of 7.5% overhead compared to DSR.
2         To minimize total control traffic overhead we have included the FG Model with our model and it reduces the overhead up to 75%.
2         This model enforces cooperation due to its stricter punishment strategy and justifies its name.



# 121
### http://arxiv.org/abs/1412.7684v1
## Efficient Switch Architectures for Pre-configured Backup Protection with Sharing in Elastic Optical Networks (EON)

0 	In this paper, we address the problem of providing survivability in elastic optical networks (EONs).
0 	EONs use fine granular frequency slots or flexible grids, when compared to the conventional fixed grid networks and therefore utilize the frequency spectrum efficiently.
1 	For providing survivability in EONs, we consider a recently proposed survivability method for conventional fixed grid networks, known as pre-configured backup protection with sharing (PBPS), because of its benefits over the traditional survivability approaches such as dedicated and shared protection.
1 	In PBPS, backup paths can be pre-configured and at the same time they can share resources.Therefore, both short recovery time and efficient resource usage can be achieved.
2 	We find that the existing switch architectures do not support both PBPS and EONs.
2 	Specifically, we identify and illustrate that, if a switch architecture is not carefully designed, several key problems/issues might arise in certain scenarios. Such problems include unnecessary resource consumption, inability of using existing free resources, and incapability of sharing backup paths. These problems appear when PBPS is adopted in EONs and they do not arise in fixed grid networks.
1 	In this paper, we propose new switch architectures which support both PBPS and EONs.
1 	Particularly, we illustrate that, our switch architectures avoid the specific problems/issues mentioned above. Therefore, our switch architectures support using resources more efficiently and reducing blocking of requests.


# 122
### http://arxiv.org/abs/1412.8617v1
## Color Filtering Localization for Three-Dimensional Underwater Acoustic Sensor Networks

0 	Accurate localization for mobile nodes has been an important and fundamental problem in underwater acoustic sensor networks (UASNs).
0 	The detection information returned from a mobile node is meaningful only if its location is known.
1 	In this paper, we propose two localization algorithms based on color filtering technology called PCFL and ACFL.
1 	PCFL and ACFL aim at collaboratively accomplishing accurate localization of underwater mobile nodes with minimum energy expenditure. They both adopt the overlapping signal region of task anchors which can communicate with the mobile node directly as the current sampling area.
1 	PCFL employs the projected distances between each of the task projections and the mobile node, while ACFL adopts the direct distance between each of the task anchors and the mobile node.
1 	Also the proportion factor of distance is proposed to weight the RGB values.
1 	By comparing the nearness degrees of the RGB sequences between the samples and the mobile node, samples can be filtered out. And the normalized nearness degrees are considered as the weighted standards to calculate coordinates of the mobile nodes.
2 	The simulation results show that the proposed methods have excellent localization performance and can timely localize the mobile node.
2 	The average localization error of PCFL can decline by about 30. 4% than the AFLA method.


# 123
### http://arxiv.org/abs/1007.1548v1
## Stability Analysis of GI/G/c/K Retrial Queue with Constant Retrial Rate

0 	We consider a GI/G/c/K-type retrial queueing system with constant retrial rate.
0 	The system consists of a primary queue and an orbit queue.
0 	The primary queue has $c$ identical servers and can accommodate the maximal number of $K$ jobs.
0 	If a newly arriving job finds the full primary queue, it joins the orbit.
0 	The original primary jobs arrive to the system according to a renewal process.
0 	The jobs have general i. i.	d. service times.
0 	A job in front of the orbit queue retries to enter the primary queue after an exponentially distributed time independent of the orbit queue length.
0 	Telephone exchange systems, Medium Access Protocols and short TCP transfers are just some applications of the proposed queueing system.
1 	For this system we establish minimal sufficient stability conditions.
2 	Our model is very general.
2 	In addition, to the known particular cases (e.g., M/G/1/1 or M/M/c/c systems), the proposed model covers as particular cases the deterministic service model and the Erlang model with constant retrial rate.
0 	The latter particular cases have not been considered in the past.
2 	The obtained stability conditions have clear probabilistic interpretation.


# 124
### http://arxiv.org/abs/1007.2280v1
## Phase Changes in the Evolution of the IPv4 and IPv6 AS-Level Internet Topologies

0 	In this paper we investigate the evolution of the IPv4 and IPv6 Internet topologies at the autonomous system (AS) level over a long period of time.
0 	We provide abundant empirical evidence that there is a phase transition in the growth trend of the two networks.
0 	For the IPv4 network, the phase change occurred in 2001.
0 	Before then the network's size grew exponentially, and thereafter it followed a linear growth.
0 	Changes are also observed around the same time for the maximum node degree, the average node degree and the average shortest path length.
0 	For the IPv6 network, the phase change occurred in late 2006.
2 	It is notable that the observed phase transitions in the two networks are different, for example the size of IPv6 network initially grew linearly and then shifted to an exponential growth.
2 	Our results show that following decades of rapid expansion up to the beginning of this century, the IPv4 network has now evolved into a mature, steady stage characterised by a relatively slow growth with a stable network structure; whereas the IPv6 network, after a slow startup process, has just taken off to a full speed growth.
2 	We also provide insight into the possible impact of IPv6-over-IPv4 tunneling deployment scheme on the evolution of the IPv6 network.
0 	The Internet topology generators so far are based on an inexplicit assumption that the evolution of Internet follows non-changing dynamic mechanisms.	
2   This assumption, however, is invalidated by our results.
2 	Our work reveals insights into the Internet evolution and provides inputs to future AS-Level Internet models.


# 125
### http://arxiv.org/abs/1007.4066v2
## A Tutorial on Broadcasting Packets over Multiple-Channels in a Multi-Inferface Network Setting in NS-2

0 	With the proliferation of cheaper electronic devices, wireless communication over multiple-channels in a multi-interface network is now possible.
0 	For instace, wireless sensor nodes can now operate over multiplechannels.
0 	Moreover, cognitive radio sensor networks are also evolving, which also operates over multiple-channels.
0 	In the market, we can find antennas that can support the operation of multiple channels, for e.g. the cc2420 antenna that is used for communication between wireless sensor nodes consists of 16 programmable channels.
0 	The proper utilization of multiple-channels reduces the interference between the nodes and increase the network throughput.
1 	Recently, a Cognitive Radio Cognitive Network (CRCN) patch for NS-2 simulator has proposed to support multi-channel multi-interface capability in NS-2.
0 	In this tutorial, we consider how to simulate a multi-channel multiinterface wireless network using the NS-2 simulator.
0 	This tutorial is trageted to the novice users who wants to understand the implementation of multi-channel multi-interface in NS-2.
1 	We take the Cognitive Radio Cognitive Network (CRCN) patch for NS-2 simulator and demonstrate broadcasting over multiple-channels in a multi-interface network setting.
2 	In our seeting, node braodcasts the Hello packets to its neighbors.
2 	Neighboring nodes receive the Hello packets if and only if they are tuned to the same channel.
2 	We demonstrate through example that the tuning of receivers can be done in two fashions.


# 106
### http://arxiv.org/abs/1309.2904v1
## A System-Theoretic Clean Slate Approach to Provably Secure Ad Hoc Wireless Networking

0 	Traditionally, wireless network protocols have been designed for performance.
0 	Subsequently, as attacks have been identified, patches have been developed.
0 	This has resulted in an "arms race" development process of discovering vulnerabilities and then patching them.
0 	The fundamental difficulty with this approach is that other vulnerabilities may still exist.
0 	No provable security or performance guarantees can ever be provided.
1 	We develop a system-theoretic approach to security that provides a complete protocol suite with provable guarantees, as well as proof of min-max optimality with respect to any given utility function of source-destination rates.
1 	Our approach is based on a model capturing the essential features of an adhoc wireless network that has been infiltrated with hostile nodes.
1 	We consider any collection of nodes, some good and some bad, possessing specified capabilities vis-a-vis cryptography, wireless communication and clocks.
1 	The good nodes do not know the bad nodes.
1 	The bad nodes can collaborate perfectly, and are capable of any disruptive acts ranging from simply jamming to non-cooperation with the protocols in any manner they please.
2   The protocol suite caters to the complete life-cycle, all the way from birth of nodes, through all phases of ad hoc network formation, leading to an optimized network carrying data reliably.
2 	It provably achieves the min-max of the utility function, where the max is over all protocol suites published and followed by the good nodes, while the min is over all Byzantine behaviors of the bad nodes.
2 	Under the protocol suite, the bad nodes do not benefit from any actions other than jamming or cooperating.
2 	This approach supersedes much previous work that deals with several types of attacks.


# 107
### http://arxiv.org/abs/1309.5049v3
## Uni-MUMAC: A Unified Down/Up-link MU-MIMO MAC Protocol for IEEE 802.11ac WLANs

0 	Due to the dominance of the downlink traffic in Wireless Local Area Networks (WLANs), a large number of previous research efforts have been put to enhance the transmission from the Access Point (AP) to stations (STAs).
0 	The downlink Multi-User Multiple-Input Multiple-Output (MU-MIMO) technique, supported by the latest IEEE amendment-802.11ac, is considered as one of the key enhancements leading WLANs to the Gigabit era.
0 	However, as cloud uploading services, Peer-to-Peer (P2P) and telepresence applications get popular, the need for a higher uplink capacity becomes inevitable.
1 	In this paper, a unified down/up-link Medium Access Control (MAC) protocol called Uni-MUMAC is proposed to enhance the performance of IEEE 802.11ac WLANs by exploring the multi-user spatial multiplexing technique.
1 	Specifically, in the downlink, we implement an IEEE 802.11ac-compliant MU-MIMO transmission scheme to allow the AP to simultaneously send frames to a group of STAs.
1 	In the uplink, we extend the traditional one round channel access contention to two rounds, which coordinate multiple STAs to transmit frames to the AP simultaneously.
1 	2-nd round Contention Window (CW2nd), a parameter that makes the length of the 2-nd contention round elastic according to the traffic condition, is introduced.
1 	Uni-MUMAC is evaluated through simulations in saturated and non-saturated conditions when both downlink and uplink traffic are present in the system.
1 	We also propose an analytic saturation model to validate the simulation results.
2 	By properly setting CW2nd and other parameters, Uni-MUMAC is compared to a prominent multi-user transmission scheme in the literature.
2 	The results exhibit that Uni-MUMAC not only performs well in the downlink-dominant scenario, but it is also able to balance both the downlink and uplink throughput in the emerging uplink bandwidth-hungry scenario.


# 108
### http://arxiv.org/abs/1310.5794v1
## An Operational Approach For Wimax At Ultra High Bandwidth With Spectrum 60 Ghz

0   WiMax is a promising network of today industry.
0 	It provides P2P and P2MP point to multipoint broadband services up to thirty miles.
0 	Its operational frequency range is 10 GHz to 60 GHz.
0 	It provides data rate of 75Mbps per channel; with an end-to-end encryption called CCMP (Counter Mode with Cipher Block Chaining Message Authentication Code Protocol).
0 	CCMP is an Advanced Encryption Standard AES based encryption method, which delivers secure communication.
0 	Telecom industry seeks secure, cheaper, wireless metro area network, that full fill the today internet demand in most efficient way.
1 	Our research explores the new dimension of WiMax with HEMT High Electron Mobility Transistor using un-licensed Band.
0 	The Aim of this paper is to simulate 60GHz unlicensed WiMax band in Matlab.
0 	This research explores millimeter waves, related electronics, mathematics of WiMax and simulated graph comparison.
1 	It determines available capacity verses coverage area and transmission bit error probability.
1 	Further it highlights the ideal modulation condition in different terrains.
2 	Research proofs that WiMax will be the future promising wireless network.


# 109
### http://arxiv.org/abs/1310.6880v2
## Capacity Analysis of IEEE 802.11ah WLANs for M2M Communications

0 	Focusing on the increasing market of the sensors and actuators networks, the IEEE 802.11ah Task Group is currently working on the standardization of a new amendment.
0 	This new amendment will operate at the sub-1GHz band, ensure transmission ranges up to 1 Km, data rates above 100 kbps and very low power operation.
0 	With IEEE 802.11ah, the WLANs will offer a solution for applications such as smart metering, plan automation, eHealth or surveillance.
0 	Moreover, thanks to a hierarchical signalling, the IEEE 802.11ah will be able to manage a higher number of stations (STAs) and improve the 802.11 Power Saving Mechanisms.
1 	In order to support a high number of STAs, two different signalling modes are proposed, TIM and Non-TIM Offset.
1 	In this paper we present a theoretical model to predict the maximum number of STAs supported by both modes depending on the traffic load and the data rate used.
1 	Moreover, the IEEE 802.11ah performance and energy consumption for both signalling modes and for different traffic patterns and data rates is evaluated.
2 	Results show that both modes achieve similar Packet Delivery Ratio values but the energy consumed with the TIM Offset is, in average, a 11.7% lower.


# 110
### http://arxiv.org/abs/1311.3181v1
## Comparative Study of Various VOIP Applications in 802.11a Wireless Network Scenario

0 	Today, Voice over Wireless Local Area Network (VOWLAN) is the most accepted Internet application.
0 	There are a large number of literatures regarding the performance of various WLAN networks.
0 	Most of them focus on simulations and modeling, but there are also some experiments with real networks.
1 	This paper explains the comparison of performance of two different VOIP (Voice over Internet Protocol) applications over the same IEEE 802.11a wireless network.
0   Radio link standard 802.11a have maximum transmission rate of 54Mbps.
1 	First protocol is session initiation protocol (SIP) and second is H.323 protocol.
1 	First one has an agent called SIP proxy.
1 	Second have a gateway reflects the characteristics of a Switched Circuit Network (SCN).
2 	With this comparison we have required to obtain a better understanding of wireless network suitability for voice communication in IP network.


# 111
### http://arxiv.org/abs/1311.3184v1
## Comparative Study of QOS Parameters of SIP protocol in 802.11a and 802.11b Network

0 	Present day, the internet telephony growth is much faster than previous.
0 	Now we are familiar with digitized packet of voice stream.
0 	So, we have required VOIP communication.
0 	SIP is one type of VOIP protocol.
0 	This one has a SIP proxy.
0 	There have one of the important communication environment Wireless LAN (WLAN).
0 	WLAN have different radio link standard.
1 	Here I am comparing SIP protocol in two radio link standard 802.11a and 802.11b environment.
2 	The first one have maximum transmission rate of 54Mbps and second one have maximum transmission rate of 11Mbps.
1 	In this paper I want to show the results in a comparative plot.
2 	These comparisons include server /client throughput, packet drops, end to end delay etc.


# 112
### http://arxiv.org/abs/1311.3483v1
## Subsiding routing misbehavior in MANET using "Mirror Model"

0 	Noncooperation or failure to work together is a big challenge that surely degrades the performance and reliability of Mobile Adhoc Networks.
0 	In MANETs, nodes have dual responsibilities of forwarding and routing, that's why it needs unison with nodes.
0 	To sort out non-cooperation a real life behavior should be implemented, so that misbehavior is nullified.
1 	In this paper, we present the "Mirror Model" that strictly enforces cooperation due to its punishment strategy.
1 	Node's behavior is watched by its neighbors in PON mode, to update the NPF, NPRF values for a threshold time.
1 	After the expiry of the threshold time each node calculates the PFR and broadcasts its neighbors.
1 	Similarly all neighbors broadcasted PFR is received and processed by the node to define the 'G' and 'BP' values.
1 	The G value is used to isolate selfish nodes from the routing paths and BP denotes the amount of packets to be dropped by an honest node against a selfish node in spite of its misbehavior/packet drops.
2 	Cooperation within the neighbors, certainly result in subsiding misbehavior of selfish nodes, therein enhancing cooperation of the whole MANET.
2 	This model ensures honesty and reliability in MANET because it does not eliminate a node, but it behaves in the same way as the node behaved.
2 	Therefore, it justifies its name, after all mirrors reflects the same.
2 	We have implemented the model in "GloMoSim" on top of the DSR protocol, resulting its effectiveness, as compared to the DSR protocol when the network is misconducting for its selfish needs.


# 113
### http://arxiv.org/abs/1311.4293v1
## Scalable Oriented-Service Architecture for Heterogeneous and Ubiquitous IoT Domains

0 	Internet of Things (IoT) grows quickly, and 50 billion of IoT devices will be interconnected by 2020.
0 	For the huge number of IoT devices, a high scalable discovery architecture is required to provide autonomous registration and look-up of IoT resources and services.
0 	The architecture should enable dynamic updates when new IoT devices are incorporated into Internet, and changes are made to the existing ones.
0 	Nowadays in Internet, the most used discovery architecture is the Domain Name System (DNS).
0 	DNS offers a scalable solution through two distributed mechanisms: multicast DNS (mDNS) and DNS Service Directory (DNS-SD).
0 	Both mechanisms have been applied to discover resources and services in local IoT domains.
0 	However, a full architecture has not still been designed to support global discovery, local directories and a search engine for ubiquitous IoT domains.
0 	Moreover, the architecture should provide other transversal functionalities such as a common semantic for describing services and resources, and a service layer for interconnecting with M2M platforms and mobile clients.
1 	This paper presents an oriented-service architecture based on DNS to support a global discovery, local directories and a distributed search engine to enable a scalable looking-up of IoT resources and services.
1 	The architecture provides two lightweight discovery mechanisms based on mDNS and DNS-SD that have been optimized for the constraints of IoT devices to allow autonomous registration.
1 	Moreover, we analyse and provide other relevant elements such semantic description and communications interfaces to support the heterogeneity of IoT devices and clients.
2 	All these elements contribute to build a scalable architecture for the discovery and access of heterogeneous and ubiquitous IoT domains.


# 114
### http://arxiv.org/abs/1312.4179v3
## Multi-Parameter Decision Support with Data Transmission over GSM/GPRS Network: a Case Study of Landslide Monitoring

0 	The planet Earth has hundreds of impact events, with some occurrences causing both in terms of human casualty as well as economic losses.
0 	Such attitudes of earth pushed the frontiers to develop innovative monitoring strategies for the earth system.
0 	To make that real, although, will require coherent and real-time data by observing the earth behavior contiguously.
0 	Wireless Sensor Network (WSN) appears to be the best suitable infrastructure to sense environmental parameters of our interests.
0 	In this event of earth observation, another important issue is the monitoring system with high level of precision.
0 	There are different types of sensors to measure the behavioral aspects of earth.
0 	The sensors integrated with WSN, provide an accurate and contiguous data for analysis and interpretation.
0 	This paper briefly addresses earth observation and areas of critical importance to people and society.
1 	A case study has also been carried out for disaster like Landslide in the North Eastern region of India.
1 	Application software has been developed for the said study for online data acquisition and analysis with pre-disaster early warning system.
1 	The system monitors the changing geotechnical condition of this region using various geo-technical sensors like Rain gauge, In-place Inclinometer, Tilt-meter, Piezo-meter and Crack meter.
1 	This paper also touches upon the aspects of data transmission over Global System for Mobile Communication (GSM) / General Packet Radio Service (GPRS) to a remote data center.


# 115
### http://arxiv.org/abs/1312.6501v1
## On-Demand WebRTC Tunneling in Restricted Networks

1 	In this paper we present the implementation of a WebRTC gateway service that can forward ad-hoc RTP data plane traffic from a browser on one local network to a browser on another local network.
0 	The advantage compared to the existing IETF STUN (RFC 5389), TURN (RFC 5766) and ICE (RFC 5245) protocols is that it does not require a public host and port mapping for each participating local host, and it works with more restrictive firewall policies.
0 	WebRTC implements ICE which combines STUN and TURN probes to automatically find the best connection between two peers who want to communicate.
0 	In corporate networks, simple hole punching and NAT traversal techniques typically do not work, e.g. because of symmetric NATs.
0 	Dynamic allocation of ports on an external 3rd party relay service is also typically blocked on restricted hosts.
1 	In our use case, doctors at hospitals can only access port 80 through the hospital firewall on external machines, and they need to communicate with patients who are typically behind a NAT in a local WiFi network.
0 	VPN solutions only work for staff but not between patients and staff.
1 	Our solution solves this problem by redirecting all WebRTC traffic through a gateway service on the local network that has a secure tunnel established with a public gateway.
1 	The public gateway redirects traffic from multiple concurrent streams securely between local gateway services that connect to it.
1 	The local gateways also communicate with browsers on their local network to mimic a direct browser-to-browser connection without having to change the browser runtime.
2 	We have demonstrated that this technique works well within the hospital network and arbitrary patient networks, without the need for any individual host configuration.
2 	In our evaluation we show that the latency overhead is 18-20 ms for each concurrent stream added to the same gateway service.


# 116
### http://arxiv.org/abs/1312.6829v1
## A Localization Strategy Based on N-times Trilateral Centroid with Weight

0 	Localization based on received signal strength indication (RSSI) is a low cost and low complexity technology, and it is widely applied in distance-based localization of wireless sensor networks (WSNs).
0 	Error of existed localization technologies is significant.
1 	This paper presents the N-times trilateral centroid weighted localization algorithm (NTCWLA), which can reduce the error considerably.
1 	Considering the instability of RSSI, we use the weighted average of many RSSIs as current RSSI.
1 	To improve the accuracy we select a number of (no less than three) reliable beacon nodes to increase the localization times.
1 	Then we calculate the distances between reliable beacon nodes and the mobile node using an empirical formula.
1 	The mobile node is located N times using the trilateral centroid algorithm.
1 	Finally, we take the weighted average of the filtered reference coordinates as the mobile node's coordinates.
1 	We conduct experiments with the STM32W108 chip which supports IEEE 802.15.4.
2 	The results show that the proposed algorithm performs better than the trilateral centroid algorithm.


# 117
### http://arxiv.org/abs/1312.6837v1
## Evaluating IEEE 802.15.4 for Cyber-Physical Systems

0 	With rapid advancements in sensing, networking, and computing technologies, recent years have witnessed the emergence of cyber-physical systems (CPS) in a broad range of application domains.
0 	CPS is a new class of engineered systems that features the integration of computation, communications, and control.
0 	In contrast to general-purpose computing systems, many cyber-physical applications are safety-cricial.
0 	These applications impose considerable requirements on quality of service (QoS) of the employed networking infrastruture.
0 	Since IEEE 802.15.4 has been widely considered as a suitable protocol for CPS over wireless sensor and actuator networks, it is of vital importance to evaluate its performance extensively.
1 	Serving for this purpose, this paper will analyze the performance of IEEE 802.15.4 standard operating in different modes respectively.
1 	Extensive simulations have been conducted to examine how network QoS will be impacted by some critical parameters.
2 	The results are presented and analyzed, which provide some useful insights for network parameter configuration and optimization for CPS design.


# 118
### http://arxiv.org/abs/1412.0366v1
## Node Failure Time and Coverage Loss Time Analysis for Maximum Stability Vs Minimum Distance Spanning Tree based Data Gathering in Mobile Sensor Networks

0 	A mobile sensor network is a wireless network of sensor nodes that move arbitrarily.
0 	In this paper, we explore the use of a maximum stability spanning tree-based data gathering (Max.Stability-DG) algorithm and a minimum-distance spanning tree-based data gathering (MST-DG) algorithm for mobile sensor networks.
1 	We analyze the impact of these two algorithms on the node failure times and the resulting coverage loss due to node failures.
1 	Both the Max.Stability-DG and MST-DG algorithms are based on a greedy strategy of determining a data gathering tree when one is needed and using that tree as long as it exists.
1 	The Max.Stability-DG algorithm assumes the availability of the complete knowledge of future topology changes and determines a data gathering tree whose corresponding spanning tree would exist for the longest time since the current time instant; whereas, the MST-DG algorithm determines a data gathering tree whose corresponding spanning tree is the minimum distance tree at the current time instant.
2 	We observe the Max.Stability-DG trees to incur a longer network lifetime (time of disconnection of the network of live sensor nodes due to node failures), a larger coverage loss time for a particular fraction of loss of coverage as well as a lower fraction of coverage loss at any time.
2 	The tradeoff is that the Max.Stability-DG trees incur a lower node lifetime (the time of first node failure) due to repeated use of a data gathering tree for a longer time.


# 119
### http://arxiv.org/abs/1412.1395v2
## A High Efficiency MAC Protocol for WLANs: Providing Fairness in Dense Scenarios

0 	Collisions are a main cause of throughput degradation in WLANs.
0 	The current contention mechanism used in IEEE 802.11 networks is called Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA).
0 	It uses a Binary Exponential Backoff (BEB) technique to randomise each contender attempt of transmitting, effectively reducing the collision probability.
0 	Nevertheless, CSMA/CA relies on a random backoff that while effective and fully decentralised, in principle is unable to completely eliminate collisions, therefore degrading the network throughput as more contenders attempt to share the channel.
1 	To overcome these situations, Carrier Sense Multiple Access with Enhanced Collision Avoidance (CSMA/ECA) is able to create a collision-free schedule in a fully decentralised manner using a deterministic backoff after successful transmissions.
1 	Hysteresis and Fair Share are two extensions of CSMA/ECA to support a large number of contenders in a collision-free schedule.
1 	CSMA/ECA offers better throughput than CSMA/CA and short-term throughput fairness.
1 	This work describes CSMA/ECA and its extensions.
2 	Additionally, it provides the first evaluation results of CSMA/ECA with non-saturated traffic, channel errors, and its performance when coexisting with CSMA/CA nodes.
2 	Furthermore, it describes the effects of imperfect clocks over CSMA/ECA and present a mechanism to leverage the impact of channel errors and the addition/withdrawal of nodes over collision-free schedules.
2 	Finally, experimental results on throughput and lost frames from a CSMA/ECA implementation using commercial hardware and open-source firmware are presented.


# 120
### http://arxiv.org/abs/1412.2168v1
## An Energy Efficient Risk Notification Message Dissemination Protocol for Vehicular Ad hoc Networks

0 	We propose the design and development of an energy-efficient Risk Notification Message Dissemination Protocol (RNMDP) for vehicular ad hoc networks (VANETs).
0 	RNMDP propagates Risk Notification Messages (RNMs) from their location of origin (called the Risk Zone) to vehicles approaching the Risk Zone.
0 	RNMDP assumes each node is aware of its current location in the network.
1 	The protocol works as follows: A RNM is broadcast in the neighborhood of the Risk Zone.
1 	A node receiving the RNM from another node waits for a Rebroadcast-Wait-Time before deciding to rebroadcast the message.
1 	The Rebroadcast-Wait-Time for a node is modeled based on the ratio of the distance between the node and the immediate sender of the RNM and the direction of movement of the node.
1 	Priority for rebroadcast is given for nodes farthest away from the sender and traveling towards the Risk Zone.
1 	Nodes that are traveling in lanes in direction away from the Risk Zone are also considered for rebroadcast, albeit with a larger Rebroadcast-Wait-Time.
1 	During the Rebroadcast-Wait-Time, if a node hears the same RNM again rebroadcast in the neighborhood, then the node stops from further broadcasting the message.
1 	If a node does not hear the RNM in its neighborhood during the RebroadcastWait-Time, the node broadcasts the message in its neighborhood.
1 	A RNM is considered to have been delivered to all the vehicles in the road, if the message reaches the Target Zone.
1 	The performance of RNMDP has been compared with that of the commonly used flooding strategy through extensive simulations conducted for highway networks with different number of lanes and lane density.
2 	Simulation results indicate that with a slightly larger delay (i.e., no more than 35% of the delay incurred for flooding), RNMDP can achieve the same message delivery ratio attained by flooding, but at a relatively much lower energy loss compared to flooding.


# 136
### http://arxiv.org/abs/1602.04440v1
## A new scheme for maximizing the lifetime of heterogeneous wireless sensor networks

0 	Heterogeneous wireless sensor network consists of wireless sensor nodes with different abilities, such as different computing power and different initial energy.
0 	We present in this paper a new scheme for maximizing heterogeneous WSN lifetime.
1 	The proposed scheme employs two types of sensor nodes that are named (consistent with IEEE 802.15.4 standard) Full Function Device (FFD) and Reduced Function Device (RFD).
0 	The FFDs are the expensive sensor nodes with high power and computational capabilities compared to the RFDs which are cheap sensors with a limited power supply.
1 	The scheme divides the network into smaller sub-networks (regions) that are built from sectors and tracks.
0 	The objective of this research is to balance and reduce the communication load on RFDs, reduce the delay, and increase the connectivity and lifetime, by using a limited number of FFDs.
1 	We investigate the performance of our scheme via numerical simulation and compare it to other related schemes that are presented for homogeneous WSNs with chain topology, such as Pegasis, Epegasis and Chiron.
2 	In addition to extending the lifetime, our scheme also results in reducing the data transmission delay compared to the related schemes.
2	Furthermore, the scheme increases the network security and reduces the RFDs power consumption by preventing the direct communication with the base station (BS).
2 	The FFD is the communication bridge between RFDs and BS.
2 	The FFD communicate with the BS using the one-hop approach or multi-hop approach through other FFDs.


# 137
### http://arxiv.org/abs/1606.04997v1
## Adaptive Quorum-Based Channel-Hopping Distributed Coordination Scheme for Cognitive Radio Networks

0 	One of the most important challenges in deploying cognitive radio networks (CRNs) is to find a common control channel (CCC) to all secondary users (SUs) that enables efficient CR communications.
0 	This challenge is attributed to the dynamic time-varying change of network topology, location and spectrum availability conditions.
0 	Rendezvous, which is the process of establishing control communications, is an essential requirement to enable efficient communication between any two pair of CR nodes.
0 	The most popular CR rendezvous protocols are based on quorum systems (QSs).
0 	Quorum systems are systematic approaches, which have several attractive properties that can be utilized to establish communication without the need of a CCC and so overcome the rendezvous (RDV) problem.
1 	In this thesis, we propose new channel-hopping-based distributed rendezvous algorithm based on grid-based-quorum techniques.
2 	The proposed algorithm increases the probability of RDV within a single cycle by allowing CR nodes to meet more often according to intersection property of quorum systems.
1 	Our proposed algorithm is called Adaptive_Quorum-Based Channel-Hopping Distributed Coordination Scheme for Cognitive Radio Networks.
1 	The main idea of our algorithm is to dynamically adjusting the selected QS by CR users according to the varying traffic loads in the CRN.
2 	The proposed algorithm decreases the average time to rendezvous (TTR) and increase the probability of RDV.
1 	We evaluate the performance of our algorithm through Matlab simulations.
1 	The performance of proposed algorithm is compared with two different design scheme.
2	The results show that our algorithm can reduce TTR, increase the RDV, and decrease the energy consumption per successful RDV.


# 138
### http://arxiv.org/abs/1606.05047v1
## Towards Characterizing International Routing Detours

0 	There are currently no requirements (technical or otherwise) that BGP paths must be contained within national boundaries.
0 	Indeed, some paths experience international detours, i.e., originate in one country, cross international boundaries and return to the same country.
0 	In most cases these are sensible traffic engineering or peering decisions at ISPs that serve multiple countries.
0 	In some cases such detours may be suspicious.
0 	Characterizing international detours is useful to a number of players: (a) network engineers trying to diagnose persistent problems, (b) policy makers aiming at adhering to certain national communication policies, (c) entrepreneurs looking for opportunities to deploy new networks, or (d) privacy-conscious states trying to minimize the amount of internal communication traversing different jurisdictions.
0 	In this paper we characterize international detours in the Internet during the month of January 2016.
1 	To detect detours we sample BGP RIBs every 8 hours from 461 RouteViews and RIPE RIS peers spanning 30 countries.
1 	Then geolocate visible ASes by geolocating each BGP prefix announced by each AS, mapping its presence at IXPs and geolocation infrastructure IPs.
1 	Finally, analyze each global BGP RIB entry looking for detours.
2 	Our analysis shows more than 5K unique BGP prefixes experienced a detour.
2 	A few ASes cause most detours and a small fraction of prefixes were affected the most.
2 	We observe about 544K detours.
2 	Detours either last for a few days or persist the entire month.
2 	Out of all the detours, more than 90% were transient detours that lasted for 72 hours or less.
2 	We also show different countries experience different characteristics of detours.


# 139
### http://arxiv.org/abs/1606.07613v1
## Carrier-Grade Anomaly Detection Using Time-to-Live Header Information

0 	Time-to-Live data in the IP header offers two interesting characteristics: First, different IP stacks pick different start TTL values.Second, each traversed router should decrement the TTL value.
0 	The combination of both offers host and route fingerprinting options.
1 	We present the first work to investigate Internet-wide TTL behavior at carrier scale and evaluate its fit to detect anomalies, predominantly spoofed source IP addresses.
1 	Using purpose-built software, we capture 2 weeks of raw TTL data at a 40 Gbit/s Internet uplink.
1 	For further insight, we actively measure observed hosts and conduct large-scale hitlist-based measurements, which yields three complementary data sets for IPv4 and IPv6.
2 	A majority (69% IPv4; 81% IPv6) of passively observed multi-packet hosts exhibit one stable TTL value.
2 	Active measurements on unstable hosts yield a stable anchor TTL value for more than 85% of responsive hosts.
1 	We develop a structure to further classify unstable hosts taking, for example, temporal stability into account.
2 	Correlation of TTL values with BGP data is clear, yet unpredictive.
2 	The results indicate that carrier-grade TTL anomaly detection can yield significant insights in the following categories: First, the method can flag anomalies based on TTL observations (yet likely at a difficult false positive/false negative trade-off).Second, the method can establish trust that a packet originates from its acclaimed source.


# 140
### http://arxiv.org/abs/1606.08936v1
## A Time-constraint Satisfying and Cost-reducing node evaluation metric for Message Routing in Mobile Crowd Sensing Networks

0 	In mobile crowd sensing networks data forwarding through opportunistic contacts between participants.
0 	Data is replicated to encountered participants.
0 	For optimizing data delivery ratio and reducing redundant data a lot of data forwarding schemes, which selectively replicate data to encountered participants through node's data forwarding metric are proposed.
0 	However most of them neglect a kind of redundant data whose Time-To-Live is expired.
1 	For reducing this kind of redundant data we proposed a new method to evaluate node's data forwarding metric, which is used to measure the node's probability of forwarding data to destination within data's constraint time.
1 	The method is divided into two parts.
1 	The first is evaluating nodes whether have possibility to contact destination within time constraint based on transient cluster.
1 	We propose a method to detect node's transient cluster, which is based on node's contact rate.
1 	Only node, which has possibility to contact destination, has chances to the second step.
2 	It effectively reduces the computational complexity.
1 	The second is calculating data forwarding probability of node to destination according to individual ICT (inter contact time) distribution.
2 	Evaluation results show that our proposed transient cluster detection method is more simple and quick.
2 	And from two aspects of data delivery ratio and network overhead our approach outperforms other existing data forwarding approach.


# 141
### http://arxiv.org/abs/0809.1061v1
## A Novel Proportional Fairness Criterion for Throughput Allocation in Multirate IEEE 802.11

0 	This paper focuses on multirate IEEE 802.11 Wireless LAN employing the mandatory Distributed Coordination Function (DCF) option.
0 	Its aim is threefold.
1	Upon starting from the multi-dimensional Markovian state transition model proposed by Malone \textit{et.al.}for characterizing the behavior of the IEEE 802.11 protocol at the Medium Access Control layer, it presents an extension accounting for packet transmission failures due to channel errors.
1	Second, it establishes the conditions under which a network constituted by $N$ stations, each station transmitting with its own bit rate, $R^{(s)}_d$, and packet rate, $\lambda_s$, can be assumed loaded.
1 	Finally, it proposes a modified Proportional Fairness (PF) criterion, suitable for mitigating the \textit{rate anomaly} problem of multirate loaded IEEE 802.11 Wireless LANs, employing the mandatory DCF option.
2 	Compared to the widely adopted assumption of saturated network, the proposed fairness criterion can be applied to general loaded networks.
2 	The throughput allocation resulting from the proposed algorithm is able to greatly increase the aggregate throughput of the DCF, while ensuring fairness levels among the stations of the same order as the ones guaranteed by the classical PF criterion.
2 	Simulation results are presented for some sample scenarios, confirming the effectiveness of the proposed criterion for optimized throughput allocation.


# 142
### http://arxiv.org/abs/1002.1689v1
## Saturation Throughput Analysis of IEEE 802.11b Wireless Local Area Networks under High Interference Considering Capture Effects

0 	Distributed contention based Medium Access Control (MAC) protocols are the fundamental components for IEEE 802.11 based Wireless Local Area Networks (WLANs).
0 	Contention windows (CW) change dynamically to adapt to the current contention level, Upon each packet collision, a station doubles its CW to reduce further collision of packets.
0 	IEEE 802.11 Distributed Coordination Function (DCF) suffers from a common problem in erroneous channel.
0 	They cannot distinguish noise lost packets from collision lost packets.
0 	In both situations a station does not receive its ACK and doubles the CW to reduce further packet collisions.
0 	This increases backoff overhead unnecessarily in addition to the noise lost packets, reduces the throughput significantly.
0 	Furthermore, the aggregate throughput of a practical WLAN strongly depends on the channel conditions.
0 	In real radio environment, the received signal power at the access point from a station is subjected to deterministic path loss, shadowing and fast multipath fading.
1 	In this paper, we propose a new saturation throughput analysis for IEEE 802.11 DCF considering erroneous channel and capture effects.
1 	To alleviate the low performance of IEEE 802.11 DCF, we introduce a mechanism that greatly outperforms under noisy environment with low network traffic and compare their performances to the existing standards.
1 	We extend the multidimensional Markov chain model initially proposed by Bianchi(3) to characterize the behavior of DCF in order to account both real channel conditions and capture effects, especially in a high interference radio environment.


# 143
### http://arxiv.org/abs/1002.1834v1
## AROMA: Automatic Generation of Radio Maps for Localization Systems

0 	WLAN localization has become an active research field recently.
0 	Due to the wide WLAN deployment, WLAN localization provides ubiquitous coverage and adds to the value of the wireless network by providing the location of its users without using any additional hardware.
0 	However, WLAN localization systems usually require constructing a radio map, which is a major barrier of WLAN localization systems' deployment.
0 	The radio map stores information about the signal strength from different signal strength streams at selected locations in the site of interest.
0 	Typical construction of a radio map involves measurements and calibrations making it a tedious and time-consuming operation.
0 	In this paper, we present the AROMA system that automatically constructs accurate active and passive radio maps for both device-based and device-free WLAN localization systems.
0 	AROMA has three main goals: high accuracy, low computational requirements, and minimum user overhead.
1 	To achieve high accuracy, AROMA uses 3D ray tracing enhanced with the uniform theory of diffraction (UTD) to model the electric field behavior and the human shadowing effect.
1 	AROMA also automates a number of routine tasks, such as importing building models and automatic sampling of the area of interest, to reduce the user's overhead.
1 	Finally, AROMA uses a number of optimization techniques to reduce the computational requirements.
1 	We present our system architecture and describe the details of its different components that allow AROMA to achieve its goals.
1 	We evaluate AROMA in two different testbeds.
2 	Our experiments show that the predicted signal strength differs from the measurements by a maximum average absolute error of 3.18 dBm achieving a maximum localization error of 2.44m for both the device-based and device-free cases.


# 144
### http://arxiv.org/abs/1002.1954v1
## High Throughput of WiMAX MIMO OFDM Including Adaptive Modulation and Coding

0	WiMAX technology is based on the IEEE 802.16 specification of which IEEE 802.16-2004 and 802.16e amendment are Physical (PHY) layer specifications.
0 	IEEE 802.16-2004 currently supports several multiple-antenna options including Space-Time Codes (STC), Multiple-Input Multiple-Output (MIMO) antenna systems and Adaptive Antenna Systems (AAS).
0 	The most recent WiMAX standard (802.16e) supports broadband applications to mobile terminals and laptops.
1 	Using Adaptive Modulation and Coding (AMC) we analyze the performance of OFDM physical layer in WiMAX based on the simulation results of Bit Error Rate (BER), and data throughput.
1 	The performance analysis of OFDM PHY is done.
1 	In this paper, an extension to the basic SISO mode, a number of 2 by 2 MIMO extensions are analysed under different combinations of digital modulation (QPSK, 16QAM and 64QAM) and Convolutional Code (CC) with half, two-third and three quarter rated codes.
2 	The intent of this paper is to provide an idea of the benefits of multiple antenna systems over single antenna systems in WiMAX type deployments.


# 145
### http://arxiv.org/abs/1002.2403v1
## Impact of Random Loss on TCP Performance in Mobile Ad hoc Networks (IEEE 802.11), A Simulation-Based Analysis

0 	Initially TCP was designed with the notion in mind that wired networks are generally reliable and any segment loss in a transmission is due to congestion in the network rather than an unreliable medium (The assumptions is that the packet loss caused by damage is much less than 1 percent) .
0 	This notion doesnt hold in wireless parts of the network.
0 	Wireless links are highly unreliable and they lose segments all the time due to a number of factors.
0 	Very few papers are available which uses TCP for MANET.
0 	In this paper, an attempt have been made to justify the use of TCP variants (Tahoe and Reno) for loss of packet due to random noise introduces in the MANET.
1 	For the present analysis the simulation has been carried out for TCP variants (Tahoe and Reno) by introduces 0, 10, 20 and 30 percent noise.
1 	The comparison of TCP variants is made by running simulation for 0, 10, 20 and 30 percent of data packet loss due to noise in the transmission link and the effect of throughput and congestion window has been examined.
2 	During the simulation we have observed that throughput has been decreased when a drop of multiple segments happens, further we have observed in the case of TCP variant (Reno) throughput is better at 1 percent (Figure 5) which implies a network with short burst of error and low BER, causing only one segment to be lost.
2 	When multiple segments are lost due to error prone nature of link, Tahoe perform better than Reno (Figure 13), that gives a significant saving of time (64.28 percent) in comparison with Reno (Table 4).
1 	Several simulations have been run with ns 2 simulator in order to acquire a better understanding of these TCP variants and the way they perform their function.
2 	We conclude with a discussion of whether these TCP versions can be used in Mobile Ad hoc Network.


# 146
### http://arxiv.org/abs/1002.3084v2
## Channel Fragmentation in Dynamic Spectrum Access Systems - a Theoretical Study

0 	Dynamic Spectrum Access systems exploit temporarily available spectrum (`white spaces') and can spread transmissions over a number of non-contiguous sub-channels.
0 	Such methods are highly beneficial in terms of spectrum utilization.
0 	However, excessive fragmentation degrades performance and hence off-sets the benefits.
0 	Thus, there is a need to study these processes so as to determine how to ensure acceptable levels of fragmentation.
1	Hence, we present experimental and analytical results derived from a mathematical model.
1 	We model a system operating at capacity serving requests for bandwidth by assigning a collection of gaps (sub-channels) with no limitations on the fragment size.
2 	Our main theoretical result shows that even if fragments can be arbitrarily small, the system does not degrade with time.
2 	Namely, the average total number of fragments remains bounded.
2 	Within the very difficult class of dynamic fragmentation models (including models of storage fragmentation), this result appears to be the first of its kind.
2 	Extensive experimental results describe behavior, at times unexpected, of fragmentation under different algorithms.
2 	Our model also applies to dynamic linked-list storage allocation, and provides a novel analysis in that domain.
2 	We prove that, interestingly, the 50% rule of the classical (non-fragmented) allocation model carries over to our model.
2 	Overall, the paper provides insights into the potential behavior of practical fragmentation algorithms.


# 147
### http://arxiv.org/abs/1002.3328v1
## Error Performance Analysis to Increase Capacity of A Cellular System Using SDMA

0 	One of the biggest drawbacks of the wireless environment is the limited bandwidth.
0	However, the users sharing this limited bandwidth have been increasing considerably.
0 	Space Division Multiple Access (SDMA) is a new technology by which the capacity of existing mobile communication systems can economically be increased.
0 	This paper has been presented how the capacity can be enhanced by using SDMA with smart antennas in mobile communications system.
1 	Based on Adaptive Antenna Array (AAA) technology the spatial dimension of the existing system is exploited by means of forming independent radio beams in each of the original channels.
1 	This paper analyses the comparison of average Bit Error Rate (BER) of SDMA and CDMA technique and the different ways in which SDMA can be introduced to increase the capacity of a cellular system.
1 	The probability of error is found for a standard omni directional base station antenna, and another set of curves is found for flat top beam having a directivity of 5.1dB.
1 	It is assumed that k separate flat top beams can be formed by base station and pointed each of the k users within the cell of interest.
2 	Noticing that for an average probability of error greater than 0.1 in a propagation path loss environment of n=4, the flat top beam will support 200 users, whereas the omni-directional antenna will support only 50 users.
2 	This increase the number of user is roughly equal to the directivity offered by the flat top beam system, and illustrates the promise SDMA offers for improving capacity in wireless system.
1 	Here multipath fading is not considered.


# 148
### http://arxiv.org/abs/1002.4833v1
## Analytical Evaluation of Unfairness Problem in Wireless LANs

0 	The number of users using wireless Local Area Network is increasing exponentially and their behavior is changing day after day.
0 	Nowadays, users of wireless LAN are using huge amount of bandwidth because of the explosive growth of some services and applications such as video sharing.
0 	This situation imposes massive pressure on the wireless LAN performance especially in term of fairness among wireless stations.
0 	The limited resources are not distributed fairly in saturated conditions.
0 	The most important resource is the access point buffer space.
0 	This importance is a result of access point being the bottleneck between two different types of networks.
0 	These two types are wired network with relatively huge bandwidth and wireless network with much smaller bandwidth.
0 	Also the unfairness problem is keep getting worse because of the greedy nature Transmission Control Protocol (TCP).
1 	In this paper, we conduct a comprehensive study on wireless LAN dynamics and proposed a new mathematical model that describes the performance and effects of its behavior.
1 	We validate the proposed model by using the simulation technique.
2 	The proposed model was able to produce very good approximation in most of the cases.
2 	It also gave us a great insight into the effective variables in the wireless LAN behavior and what are the dimensions of the unfairness problem.


########
# 46
### http://arxiv.org/abs/1006.3373v1
## Design and Implementation VOIP Service on Open IMS and Asterisk Servers Interconnected through Enum Server

0 	Asterisk and Open IMS use SIP signal protocol to enable both of them can be connected.
0 	To facilitate both relationships, Enum server- that is able to translate the numbering address such as PSTN (E.164) to URI address (Uniform Resource Identifier)- can be used.
1 	In this research, we interconnect Open IMS and Asterisk server Enum server.
1 	We then analyze the server performance and PDD (Post Dial Delay) values resulted by the system.
2 	As the result of the experiment, we found that, for a call from Open IMS user to analog Asterisk telephone (FXS) with a arrival call each servers is 30 call/sec, the maximum PDD value is 493.656 ms.
2 	Open IMS is able to serve maximum 30 call/s with computer processor 1.55 GHz, while the Asterisk with computer processor 3.0 GHz, may serve up to 55 call/sec.
2 	Enum on server with 1.15 GHz computer processor have the capability of serving maximum of 8156 queries/sec.


# 47
### http://arxiv.org/abs/1006.4225v2
## Optimal Spectrum Sharing in MIMO Cognitive Radio Networks via Semidefinite Programming

0 	In this paper, we study the optimal secondary-link beamforming pattern that balances between the SU's throughput and the interference it causes to PUs in MIMO cognitive radio networks.
0 	In particular, we aim to maximize the throughput of the SU, while keeping the interference temperature at the primary receivers below a certain threshold.
0 	Unlike traditional MIMO systems, SUs may not have the luxury of knowing the channel state information (CSI) on the links to PUs.
0 	This presents a key challenge for a secondary transmitter to steer interference away from primary receivers.
0 	In this paper, we consider three scenarios, namely when the secondary transmitter has complete, partial, or no knowledge about the channels to the primary receivers.
0 	In particular, when complete CSI is not available, the interference-temperature constraints are to be satisfied with high probability, thus resulting in chance constraints that are typically hard to deal with.
1 	Our contribution is fourfold.
1 	First, by analyzing the distributional characteristics of MIMO channels, we propose a unified homogeneous QCQP formulation that can be applied to all three scenarios.
1 	The homogeneous QCQP formulation, though non-convex, is amenable to semidefinite programming (SDP) relaxation methods.
2 	Secondly, we show that the SDP relaxation admits no gap when the number of primary links is no larger than two.
1 	Thirdly, we propose a randomized polynomial-time algorithm for constructing a near-optimal solution to the QCQP problem when there are more than two primary links.
2 	Finally, we show that when the secondary transmitter has no CSI on the links to primary receivers, the optimal solution to the QCQP problem can be found by a simple matrix eigenvalue-eigenvector computation, which can be done much more efficiently than solving the QCQP directly.


# 48
### http://arxiv.org/abs/1006.4406v1
## Slow Adaptive OFDMA Systems Through Chance Constrained Programming

0 	Adaptive OFDMA has recently been recognized as a promising technique for providing high spectral efficiency in future broadband wireless systems.
0 	The research over the last decade on adaptive OFDMA systems has focused on adapting the allocation of radio resources, such as subcarriers and power, to the instantaneous channel conditions of all users.
0 	However, such "fast" adaptation requires high computational complexity and excessive signaling overhead.
0 	This hinders the deployment of adaptive OFDMA systems worldwide.
0 	This paper proposes a slow adaptive OFDMA scheme, in which the subcarrier allocation is updated on a much slower timescale than that of the fluctuation of instantaneous channel conditions.
0 	Meanwhile, the data rate requirements of individual users are accommodated on the fast timescale with high probability, thereby meeting the requirements except occasional outage.
0 	Such an objective has a natural chance constrained programming formulation, which is known to be intractable.
1 	To circumvent this difficulty, we formulate safe tractable constraints for the problem based on recent advances in chance constrained programming.
1 	We then develop a polynomial-time algorithm for computing an optimal solution to the reformulated problem.
2 	Our results show that the proposed slow adaptation scheme drastically reduces both computational cost and control signaling overhead when compared with the conventional fast adaptive OFDMA.
2 	Our work can be viewed as an initial attempt to apply the chance constrained programming methodology to wireless system designs.
2 	Given that most wireless systems can tolerate an occasional dip in the quality of service, we hope that the proposed methodology will find further applications in wireless communications.


# 49
### http://arxiv.org/abs/1010.4986v1
## A Testbed Implementation for Securing OLSR in Mobile Ad hoc Networks

0 	Contemporary personal computing devices are increasingly required to be portable and mobile enabling user's wireless access, to wired network infrastructures and services.
0 	This approach to mobile computing and communication is only appropriate in situations where a coherent infrastructure is available.
0 	There are many situations where these requirements are not fulfilled such as; developing nations, rural areas, natural disasters, and military conflicts to name but a few.
0 	A practical solution is to use mobile devices interconnected via a wireless medium to form a network, known as a Mobile Ad-hoc Network (MANET), and provide the services normally found in wired networks.
0 	Security in MANETs is an issue of paramount importance due to the wireless nature of the communication links.
0 	Additionally due to the lack of central administration security issues are different from conventional networks.
1 	For the purposes of this article we have used the "WMN test-bed" to enable secure routing in MANETs.
0 	The use of cryptography is an efficient proven way of securing data in communications, but some cryptographic algorithms are not as efficient as others and require more processing power, which is detrimental to MANETs.
1 	In this article we have assessed different cryptographic approaches to securing the OLSR (Optimised Link State Routing) protocol to provide a basis for research.
2 	We conclude the paper with a series of performance evaluation results regarding different cryptographic and hashing schemes.
2 	Our findings clearly show that the most efficient combination of algorithms used for authentication and encryption are SHA-1 and AES respectively.
2 	Using this combination over their counterparts will lead to a considerable reduction in processing time and delay on the network, creating an efficient transaction moving towards satisfying resource constraints and security requirements.


# 50
### http://arxiv.org/abs/1101.2759v1
## Routing Security Issues in Wireless Sensor Networks: Attacks and Defenses

0 	Wireless Sensor Networks (WSNs) are rapidly emerging as an important new area in wireless and mobile computing research.
0 	Applications of WSNs are numerous and growing, and range from indoor deployment scenarios in the home and office to outdoor deployment scenarios in adversary's territory in a tactical battleground (Akyildiz et al.,2002).
0 	For military environment, dispersal of WSNs into an adversary's territory enables the detection and tracking of enemy soldiers and vehicles.
0 	For home/office environments, indoor sensor networks offer the ability to monitor the health of the elderly and to detect intruders via a wireless home security system.
0 	In each of these scenarios, lives and livelihoods may depend on the timeliness and correctness of the sensor data obtained from dispersed sensor nodes.
0 	As a result, such WSNs must be secured to prevent an intruder from obstructing the delivery of correct sensor data and from forging sensor data.
1 	To address the latter problem, end-to-end data integrity checksums and post-processing of senor data can be used to identify forged sensor data (Estrin et al.,1999; Hu et al.,2003a; Ye et al.,2004).
1 	The focus of this chapter is on routing security in WSNs.
0 	Most of the currently existing routing protocols for WSNs make an optimization on the limited capabilities of the nodes and the application-specific nature of the network, but do not any the security aspects of the protocols.
0 	Although these protocols have not been designed with security as a goal, it is extremely important to analyze their security properties.
2 	When the defender has the liabilities of insecure wireless communication, limited node capabilities, and possible insider threats, and the adversaries can use powerful laptops with high energy and long range communication to attack the network, designing a secure routing protocol for WSNs is obviously a non-trivial task.


# 51
### http://arxiv.org/abs/1101.3835v1
## Relay Selection with Partial Information in Wireless Sensor Networks

0 	Our work is motivated by geographical forwarding of sporadic alarm packets to a base station in a wireless sensor network (WSN), where the nodes are sleep-wake cycling periodically and asynchronously.
1 	When a node (referred to as the source) gets a packet to forward, either by detecting an event or from an upstream node, it has to wait for its neighbors in a forwarding set (referred to as relays) to wake-up.
1 	Each of the relays is associated with a random reward (e.g., the progress made towards the sink) that is iid.
1 	To begin with, the source is uncertain about the number of relays, their wake-up times and the reward values, but knows their distributions.
1 	At each relay wake-up instant, when a relay reveals its reward value, the source's problem is to forward the packet or to wait for further relays to wake-up.
1 	In this setting, we seek to minimize the expected waiting time at the source subject to a lower bound on the average reward.
0 	In terms of the operations research literature, our work can be considered as a variant of the asset selling problem.
1 	We formulate the relay selection problem as a partially observable Markov decision process (POMDP), where the unknown state is the number of relays.
1 	We begin by considering the case where the source knows the number of relays.
1 	For the general case, where the source only knows a pmf on the number of relays, it has to maintain a posterior pmf on the number of relays and forward the packet iff the pmf is in an optimum stopping set.
2 	We show that the optimum stopping set is convex and obtain inner and outer bounds to this set.
2 	The computational complexity of the above policies motivates us to formulate an alternative simplified model, the optimal policy for which is a simple threshold rule.
2 	We provide simulation results to compare the performance of the various one-hop and end-to-end forwarding policies.


# 52
### http://arxiv.org/abs/1102.0682v1
## A Study of IEEE 802.15.4 Security Framework for Wireless Body Area Network

0 	A Wireless Body Area Network (WBAN) is a collection of low-power and lightweight wireless sensor nodes that are used to monitor the human body functions and the surrounding environment.
0 	It supports a number of innovative and interesting applications, including ubiquitous healthcare and Consumer Electronics (CE) applications.
0 	Since WBAN nodes are used to collect sensitive (life-critical) information and may operate in hostile environments, they require strict security mechanisms to prevent malicious interaction with the system.
1 	In this paper, we first highlight major security requirements and Denial of Service (DoS) attacks in WBAN at Physical, Medium Access Control (MAC), Network, and Transport layers.
1 	Then we discuss the IEEE 802.15.4 security framework and identify the security vulnerabilities and major attacks in the context of WBAN.
1 	Different types of attacks on the Contention Access Period (CAP) and Contention Free Period (CFP) parts of the superframe are analyzed and discussed.
2 	It is observed that a smart attacker can successfully corrupt an increasing number of GTS slots in the CFP period and can considerably affect the Quality of Service (QoS) in WBAN (since most of the data is carried in CFP period).
2 	As we increase the number of smart attackers the corrupted GTS slots are eventually increased, which prevents the legitimate nodes to utilize the bandwidth efficiently.
2 	This means that the direct adaptation of IEEE 802.15.4 security framework for WBAN is not totally secure for certain WBAN applications.
2 	New solutions are required to integrate high level security in WBAN.


# 53
### http://arxiv.org/abs/1102.3607v1
## Fairness issues in a chain of IEEE 802.11 stations

0 	We study a simple general scenario of ad hoc networks based on IEEE 802.11 wireless communications, consisting in a chain of transmitters, each of them being in the carrier sense area of its neighbors.
0 	Each transmitter always attempts to send some data frames to one receiver in its transmission area, forming a pair sender-receiver.
0 	This scenario includes the three pairs fairness problem, and allows to study some fairness issues of the IEEE 802.11 medium access mechanism.
1 	We show by simulation that interesting phenomena appear, depending on the number n of pairs in the chain and of its parity.
1 	We also point out a notable asymptotic behavior.
1 	We introduce a powerful modeling, by simply considering the probability for a transmitter to send data while its neighbors are waiting.
1 	This model leads to a non-linear system of equations, which matches very well the simulations, and which allows to study both small and very large chains.
1 	We then analyze the fairness issue in the chain regarding some parameters, as well as the asymptotic behavior.
2 	By studying very long chains, we notice good asymptotic fairness of the IEEE 802.11 medium sharing mechanism.
2 	As an application, we show how to increase the fairness in a chain of three pairs.


# 54
### http://arxiv.org/abs/1102.4106v1
## An Overview of IEEE 802.15.6 Standard

0 	Wireless Body Area Networks (WBAN) has emerged as a key technology to provide real-time health monitoring of a patient and diagnose many life threatening diseases.
0 	WBAN operates in close vicinity to, on, or inside a human body and supports a variety of medical and non-medical applications.
0 	IEEE 802 has established a Task Group called IEEE 802.15.6 for the standardization of WBAN.
0 	The purpose of the group is to establish a communication standard optimized for low-power in-body/on-body nodes to serve a variety of medical and non-medical applications.
1 	This paper explains the most important features of the new IEEE 802.15.6 standard.
1 	The standard defines a Medium Access Control (MAC) layer supporting several Physical (PHY) layers.
1 	We briefly overview the PHY and MAC layers specifications together with the bandwidth efficiency of IEEE 802.15.6 standard.
2 	We also discuss the security paradigm of the standard.


# 55
### http://arxiv.org/abs/1102.4176v1
## Contract-Based Cooperative Spectrum Sharing

0 	Providing proper economic incentives is essential for the success of dynamic spectrum sharing.
0 	Cooperative spectrum sharing is one effective way to achieve this goal.
0 	In cooperative spectrum sharing, secondary users (SUs) relay traffics for primary users (PUs), in exchange for dedicated transmission time for the SUs' own communication needs.
0 	In this paper, we study the cooperative spectrum sharing under incomplete information, where SUs' types (capturing their heterogeneity in relay channel gains and evaluations of power consumptions) are private information and not known by PUs.
0 	Inspired by the contract theory, we model the network as a labor market.
1 	The single PU is the employer who offers a contract to the SUs.
1 	The contract consists of a set of contract items representing combinations of spectrum accessing time (i.e., reward) and relaying power (i.e., contribution).
1 	The SUs are employees, and each of them selects the best contract item to maximize his payoff.
1 	We study the optimal contract design for both weak and strong incomplete information scenarios.
1 	First, we provide necessary and sufficient conditions for feasible contracts in both scenarios.
1 	In the weak incomplete information scenario, we further derive the optimal contract that achieves the same maximum PU's utility as in the complete information benchmark.
1 	In the strong incomplete information scenario, we propose a Decompose-and-Compare algorithm that achieves a close-to-optimal contract.
2 	We future show that the PU's average utility loss due to the suboptimal algorithm and the strong incomplete information are both relatively small (less than 2% and 1:3%, respectively, in our numerical results with two SU types).


# 56
### http://arxiv.org/abs/1103.1518v1
## One Bad Apple Spoils the Bunch: Exploiting P2P Applications to Trace and Profile Tor Users

0 	Tor is a popular low-latency anonymity network.
0 	However, Tor does not protect against the exploitation of an insecure application to reveal the IP address of, or trace, a TCP stream.
0 	In addition, because of the linkability of Tor streams sent together over a single circuit, tracing one stream sent over a circuit traces them all.
0 	Surprisingly, it is unknown whether this linkability allows in practice to trace a significant number of streams originating from secure (i.e., proxied) applications.
0 	In this paper, we show that linkability allows us to trace 193% of additional streams, including 27% of HTTP streams possibly originating from "secure" browsers.
1 	In particular, we traced 9% of Tor streams carried by our instrumented exit nodes.
1 	Using BitTorrent as the insecure application, we design two attacks tracing BitTorrent users on Tor.
1 	We run these attacks in the wild for 23 days and reveal 10,000 IP addresses of Tor users.
1 	Using these IP addresses, we then profile not only the BitTorrent downloads but also the websites visited per country of origin of Tor users.
2 	We show that BitTorrent users on Tor are over-represented in some countries as compared to BitTorrent users outside of Tor.
2 	By analyzing the type of content downloaded, we then explain the observed behaviors by the higher concentration of pornographic content downloaded at the scale of a country.
2 	Finally, we present results suggesting the existence of an underground BitTorrent ecosystem on Tor.


# 57
### http://arxiv.org/abs/1103.2212v2
## Stability and Queueing Analysis of IEEE 802.11 Distributed Coordination Function

0 	A widely adopted two-dimensional Markov chain model of the IEEE 802.11 DCF was introduced by Bianchi to characterize the backoff behavior of a single node under a saturated traffic condition.
0 	Using this approach, we propose a queuing model for the 802.11 DCF under a non-saturated traffic environment.
1 	The input buffer of each node is modeled as a Geo/G/1 queue, and the packet service time distribution is derived from Markov state space of 802.11 DCF with the underlying scheduling algorithm.
1 	The DCF defines two access mechanisms, namely the Basic access mechanism and the request-to-send/clear-to-send (RTS/CTS) access mechanism.
1 	Based on our model, performance analyses of both schemes are studied with probabilistic exponential backoff scheduling.
1 	We obtain the characteristic equation of network throughput and expressions of packet queueing delay.
1 	Specifically, we obtain the stable throughput and bounded delay regions with respect to the retransmission factor according to the basic queueing analysis.
1 	For both access schemes, the bounded delay region is a subset of the stable throughput region.
2 	Our results show that the RTS/CTS access mechanism is more stable and performs better than the Basic access mechanism.
2 	The analysis in this paper is verified by simulation results.


# 58
### http://arxiv.org/abs/1103.3340v1
## A Dynamic Multimedia User-Weight Classification Scheme for IEEE_802.11 WLANs

0 	In this paper we expose a dynamic traffic-classification scheme to support multimedia applications such as voice and broadband video transmissions over IEEE 802.11 Wireless Local Area Networks (WLANs).
0 	Obviously, over a Wi-Fi link and to better serve these applications - which normally have strict bounded transmission delay or minimum link rate requirement - a service differentiation technique can be applied to the media traffic transmitted by the same mobile node using the well-known 802.11e Enhanced Distributed Channel Access (EDCA) protocol.
0 	However, the given EDCA mode does not offer user differentiation, which can be viewed as a deficiency in multi-access wireless networks.
0	Accordingly, we propose a new inter-node priority access scheme for IEEE 802.11e networks which is compatible with the EDCA scheme.
1 	The proposed scheme joins a dynamic user-weight to each mobile station depending on its outgoing data, and therefore deploys inter-node priority for the channel access to complement the existing EDCA inter-frame priority.
2 	This provides efficient quality of service control across multiple users within the same coverage area of an access point.
2 	We provide performance evaluations to compare the proposed access model with the basic EDCA 802.11 MAC protocol mode to elucidate the quality improvement achieved for multimedia communication over 802.11 WLANs.


# 59
### http://arxiv.org/abs/1103.4769v1
## High-Energy-First (HEF) Heuristic for Energy-Efficient Target Coverage Problem

0 	Target coverage problem in wireless sensor networks is concerned with maximizing the lifetime of the network while continuously monitoring a set of targets.
0 	A sensor covers targets which are within the sensing range.
0 	For a set of sensors and a set of targets, the sensor-target coverage relationship is assumed to be known.
0 	A sensor cover is a set of sensors that covers all the targets.
0 	The target coverage problem is to determine a set of sensor covers with maximum aggregated lifetime while constraining the life of each sensor by its initial battery life.
0 	The problem is proved to be NP-complete and heuristic algorithms to solve this problem are proposed.
0 	In the present study, we give a unified interpretation of earlier algorithms and propose a new and efficient algorithm.
0 	We show that all known algorithms are based on a common reasoning though they seem to be derived from different algorithmic paradigms.
0 	We also show that though some algorithms guarantee bound on the quality of the solution, this bound is not meaningful and not practical too.
0 	Our interpretation provides a better insight to the solution techniques.
1 	We propose a new greedy heuristic which prioritizes sensors on residual battery life.
1 	We show empirically that the proposed algorithm outperforms all other heuristics in terms of quality of solution.
2 	Our experimental study over a large set of randomly generated problem instances also reveals that a very na\"ive greedy approach yields solutions which is reasonably (appx.10%) close to the actual optimal solutions.


# 60
### http://arxiv.org/abs/1105.3864v2
## Component Based Clustering in Wireless Sensor Networks

0 	Clustering is an important research topic for wireless sensor networks (WSNs).
0 	A large variety of approaches has been presented focusing on different performance metrics.
0 	Even though all of them have many practical applications, an extremely limited number of software implementations is available to the research community.
0 	Furthermore, these very few techniques are implemented for specific WSN systems or are integrated in complex applications.
0 	Thus it is very difficult to comparatively study their performance and almost impossible to reuse them in future applications under a different scope.
0 	In this work we study a large body of well established algorithms.
1 	We identify their main building blocks and propose a component-based architecture for developing clustering algorithms that (a) promotes exchangeability of algorithms thus enabling the fast prototyping of new approaches, (b) allows cross-layer implementations to realize complex applications, (c) offers a common platform to comparatively study the performance of different approaches, (d) is hardware and OS independent.
1 	We implement 5 well known algorithms and discuss how to implement 11 more.
1 	We conduct an extended simulation study to demonstrate the faithfulness of our implementations when compared to the original implementations.
1 	Our simulations are at very large scale thus also demonstrating the scalability of the original algorithms beyond their original presentations.
1 	We also conduct experiments to assess their practicality in real WSNs.
2 	We demonstrate how the implemented clustering algorithms can be combined with routing and group key establishment algorithms to construct WSN applications.
2 	Our study clearly demonstrates the applicability of our approach and the benefits it offers to both research & development communities.


# 286
### http://arxiv.org/abs/1805.07743v4
## Joint Path Selection and Rate Allocation Framework for 5G Self-Backhauled mmWave Networks

0 	Owing to severe path loss and unreliable transmission over a long distance at higher frequency bands, we investigate the problem of path selection and rate allocation for multi-hop self-backhaul millimeter wave (mmWave) networks.
0 	Enabling multi-hop mmWave transmissions raises a potential issue of increased latency, and thus, in this work we aim at addressing the fundamental questions: how to select the best multi-hop paths and how to allocate rates over these paths subject to latency constraints?
1 	In this regard, we propose a new system design, which exploits multiple antenna diversity, mmWave bandwidth, and traffic splitting techniques to improve the downlink transmission.
1 	The studied problem is cast as a network utility maximization, subject to an upper delay bound constraint, network stability, and network dynamics.
1 	By leveraging stochastic optimization, the problem is decoupled into: path selection and rate allocation sub-problems, whereby a framework which selects the best paths is proposed using reinforcement learning techniques.
1 	Moreover, the rate allocation is a nonconvex program, which is converted into a convex one by using the successive convex approximation method.
1 	Via mathematical analysis, we provide a comprehensive performance analysis and convergence proofs for the proposed solution.
2 	Numerical results show that our approach ensures reliable communication with a guaranteed probability of up to $99.9999\%$, and reduces latency by $50.64\%$ and $92.9\%$ as compared to baseline models.
2 	Furthermore, the results showcase the key trade-off between latency and network arrival rate.


# 287
### http://arxiv.org/abs/1806.05026v1
## An Analytical Model for Wireless Mesh Networks with Collision-Free TDMA and Finite Queues

0 	Wireless mesh networks are a promising technology for connecting sensors and actuators with high flexibility and low investment costs.
0 	In industrial applications, however, reliability is essential.
0 	Therefore, two time-slotted medium access methods, DSME and TSCH, were added to the IEEE 802.15.4 standard.
0 	They allow collision-free communication in multi-hop networks and provide channel hopping for mitigating external interferences.
0 	The slot schedule used in these networks is of high importance for the network performance.
1 	This paper supports the development of efficient schedules by providing an analytical model for the assessment of such schedules, focused on TSCH.
1 	A Markov chain model for the finite queue on every node is introduced that takes the slot distribution into account.
1 	The models of all nodes are interconnected to calculate network metrics such as packet delivery ratio, end-to-end delay and throughput.
1 	An evaluation compares the model with a simulation of the Orchestra schedule.
2 	The model is applied to Orchestra as well as to two simple distributed scheduling algorithms to demonstrate the importance of traffic-awareness for achieving high throughput.



# 289
### http://arxiv.org/abs/1807.02205v1
## OSDF: An Intent-based Software Defined Network Programming Framework

0 	Software Defined Networking (SDN) offers flexibility to program a network based on a set of network requirements.
0 	Programming the networks using SDN is not completely straightforward because a programmer must deal with low level details.
0 	To solve the problem, researchers proposed a set of network programming languages that provide a set of high level abstractions to hide low level hardware details.
0 	Most of the proposed languages provide abstractions related to packet processing and flows, and still require a programmer to specify low-level match-action fields to configure and monitor a network.
0 	Recently, in an attempt to raise the level at which programmers work, researchers have begun to investigate Intent-based, descriptive northbound interfaces.
0 	The work is still in early stages, and further investigation is required before intent-based systems will be adopted by enterprise networks.
1 	To help achieve the goal of moving to an intent-based design, we propose an SDN-based network programming framework, the Open Software Defined Framework (OSDF).
1 	OSDF provides a high level Application Programming Interface (API) that can be used by managers and network administrators to express network requirements for applications and policies for multiple domains.
1 	OSDF also provides a set of high level network operation services that handle common network configuration, monitoring, and Quality of Service (QoS) provisioning.
1 	OSDF is equipped with a policy conflict management module to help a network administrator detect and resolve policy conflicts.
1 	The paper shows how OSDF can be used and explains application-based policies.
2 	Finally, the paper reports the results of both testbed measurements and simulations that are used to evaluate the framework from multiple perspectives, including functionality and performance.

### 41
##### doi: 10.1109/TLT.2016.258343
#### IP Addressing: Problem-Based Learning Approach on Computer Networks


0	  The case study presented in this paper describes the pedagogical aspects and experience gathered while using an e-learning tool named IPA-PBL.
0	  Its main purpose is to provide additional motivation for adopting theoretical principles and procedures in a computer networks course.
1     In the proposed model, the sequencing of activities of the learning process is grouped into three phases based on educational goals.
1     In this way, the same tool is used on several courses with different curricula.
1	  In IPA-PBL, problem-based learning (PBL) is applied as a pedagogical strategy, as well as a set of concrete methods implemented in the software.
1     Together with the pedagogical model, specific domain ontology is designed.
1     In this way, the learner's knowledge can be analyzed in order to collect data necessary for the dynamic adaptation of system behavior.
2	  The results collected while using IPA-PBL are compared to those obtained without using the system.
2     Statistical analysis, together with pertaining considerations and conclusions, are also presented in the paper.


### 42
##### doi: 10.1109/TLT.2016.258848
#### Needles in the Haystack: Finding Content Worth Preparing for Workplace Learning with the KEP Model


0	  Knowledge transfer between employees is a primary concern in organizations.
0	  Employees create or acquire content that partially represents knowledge.
0    These knowledge elements are specific to the context in and for which they are created and rarely address the learning needs of other employees in other work situations.
0     Organizations therefore need to support the preparation of knowledge elements to facilitate knowledge transfer, but often have limited resources to process a plethora of content.
1	  This paper presents the Knowledge Element Preparation (KEP) model that helps to structure the complex decision to select knowledge elements worthy of preparation out of ample available content and assign them to preparation tasks.
1	  The model combines the benefits of prepared knowledge elements in workplace learning, which we identified in an ethnographically informed study of a software development company, with efforts discussed in the literature.
1	  We implemented and reflected on the model in a case study of a research and development project.
2     Our findings suggest that we can estimate the benefits of adaptively delivered content based on the importance of topics, types of knowledge elements, and preparation tasks.
2     We also contribute personas, dimensions of knowledge elements, and knowledge work situations as instruments to facilitate the instantiation of the KEP model.


### 43
##### doi: 10.1109/TLT.2016.259816
#### Teaching with a Dual-Channel Classroom Feedback System in the Digital Classroom Environment


0	  Teaching with a classroom feedback system can benefit both teaching and learning practices of interactivity.
1	  In this paper, we propose a dual-channel classroom feedback system integrated with a back-end e-Learning system.
1	  The system consists of learning agents running on the students' computers and a teaching agent running on the instructor's computer.
1	  The learning agent collects both instructional and social responses from the students and then sends them back to the instructor's computer through a two-channel mechanism.
1     The instructional responses are obtained by recognizing the spoken keywords; while the social responses are obtained by analyzing the social signals provided by students' head movements.
1     Later, the teaching agent displays the summarized responses on the teaching dashboard for the instructor to evaluate their teaching practices.
2     Empirical experiment results show that the system has an acceptable performance and provides enhanced interactivity in both learning and teaching.
2     Also, further analysis reveals that the dual-channel mechanism not only provides the basic functions of a classroom feedback system, the student's responses to the instructor's questions, but also promotes both students and instructors to be engaged and attentive in class.
2     As the two-channel feedback mechanism can be embedded into an e-Learning system, the proposed system is an enhancement of a digital classroom environment.
2     In short, with the help of the two-channel feedback mechanism, interactivity on teaching practices and learning activities can be greatly improved.
2     Students can then acquire a much better learning experience and satisfaction.


### 44
##### doi: 10.1109/TLT.2016.251509
#### Adaptive Social Learning Based on Crowdsourcing


0	  Many techniques have been developed to enhance learning experience with computer technology.
0	  A particularly great influence of technology on learning came with the emergence of the web and adaptive educational hypermedia systems.
0     While the web enables users to interact and collaborate with each other to create, organize, and share knowledge via user-generated content, majority of e-learning systems do not utilize the power of their users to create high quality educational content and provide data for adaptive algorithms.
1	  In this paper, we introduce a novel social learning framework that allows anybody to author educational content in a form of mini-lessons, learn lessons by following adaptive learning pathways as well as interact with their peers as in any social network.
1	  The proposed approach combines concepts of crowd-sourcing, online social networks, and complex adaptive systems to engage users in efficient learning through teaching process.
1	  We first describe the main idea behind the framework and how users interact with it, and then we describe SALT system that implements the framework.
1	  We also performed evaluation of the SALT system via several classroom studies.
2     Our results show that collective learning experiences can be efficiently utilized in adaptive social learning.
2     We found that students tend to form stable clusters that survive very high similarity threshold.
2     Meanwhile, our learning pathway analysis showed that almost all students have their own unique best pathway.
2     Experiments with various recommendation algorithms showed that most algorithms obtain very small penalty in all classes.


### 45
##### doi: 10.1109/TLT.2015.251338
#### Integrating Model-Driven and Data-Driven Techniques for Analyzing Learning Behaviors in Open-Ended Learning Environments


0	  Research in computer-based learning environments has long recognized the vital role of adaptivity in promoting effective, individualized learning among students.
0	  Adaptive scaffolding capabilities are particularly important in open-ended learning environments, which provide students with opportunities for solving authentic and complex problems, and the choice to adopt a variety of strategies and approaches to solving these problems.
0	  To help students overcome their difficulties and become effective learners and problem solvers, we have to develop methods that can track and interpret students' open-ended learning and problem-solving behaviors.
0	  The complexity of the problems and the open-ended nature of the solution processes pose considerable challenges to accurately interpret and evaluate student behaviors and performance as they work on the system.
1	  In this paper, we develop a framework that combines model-driven strategy detection with data-driven pattern discovery for analyzing students' learning activity data in open-ended environments.
2	  We present results from an in-depth case study of multiple activity patterns identified in data from the Betty's Brain learning environment.
2     The results illustrate the benefits of combining model- and data-driven techniques to precisely characterize the learning behavior of students in an open-ended environment.


### 46
##### doi: 10.1109/TLT.2016.251442
#### Learning How to Construct Models of Dynamic Systems: An Initial Evaluation of the Dragoon Intelligent Tutoring System


0	  Constructing models of dynamic systems is an important skill in both mathematics and science instruction.
0	  However, it has proved difficult to teach.
1     Dragoon is an intelligent tutoring system intended to quickly and effectively teach this important skill.
1	  This paper describes Dragoon and an evaluation of it.
2	  The evaluation randomly assigned students in a university class to either Dragoon or baseline instruction that used Dragoon as an editor only.
2     Among students who did use their systems, the tutored students scored reliably higher (p <; .021, d = 1.06) on the post-test than the students who used only the conventional editor-based instruction.


### 47
##### doi: 10.1109/TLT.2016.257435
#### Cognitive Diffusion Model: Facilitating EFL Learning in an Authentic Environment


0	  For this study, we designed learning activities in which students applied newly acquired knowledge to solve meaningful daily life problems in their local community - a real, familiar, and relevant environment for students.
0	  For example, students learned about signs and rules in class and then applied this new knowledge to create their own rules for a location in their community (e.g., playground rules that tell visitors what is or is not allowed to do in a local playground) to make it more environmentally friendly.
1	  To facilitate this, we developed a mobile learning system equipped with a dictionary as well as textual annotation, recording, and sharing functions.
1	  This mobile learning system enables students to take pictures of objects, describe them verbally or in writing, and share their work with peers.
1	  Our goal was to study the effectiveness of learning activities supported by a mobile learning system on the cognitive learning process by examining the changes in students' cognitive processes and the distribution of students who reach a certain level of cognition before and after learning.
1	  Fifty-seven junior high school students participated in the research, and their views of the mobile learning system and interest in continuing use were also explored.
1	  Students were divided into one control (n = 26) group and one experimental (n = 31) group.
1	  The control group completed learning activities using a traditional approach while the experimental group used a learning system installed in tablet PCs.
1	  The effectiveness of the mobile PC system on students' cognitive processes was tested by comparing the control and experimental groups' pre-test and post-test outcomes.
1	  Changes in students' cognitive processes were measured by calculating the differences in student scores among three tasks.
1	  The distribution of students who reached a certain level of cognition was derived based on their learning performance.
1	  Students' perceptions were evaluated using a questionnaire survey.
1     The mobile learning system kept records of how students used it.
2     Our results show that the experimental students significantly outperformed the control students on test items related to high cognitive levels.
2     Students made clear cognitive progress from the second topic to the third one.
2     Most students rated the learning system highly and want to use it in the future.
2     Finally, the results show that creating text annotations is the best indicator of learning.
2     Based on these results, we recommend applying appropriate learning activities supported by a mobile learning system to facilitate students' cognitive processes when they are studying English as a foreign language in an authentic environment.


### 48
##### doi: 10.1109/TLT.2016.255948
#### Specialized Intervention Using Tablet Devices for Communication Deficits in Children with Autism Spectrum Disorders


0	  New possibilities offered by mobile devices for special education students have led to the design of skill acquisition software applications.
0	  Advances in mobile technologies development have made progress possible in helping teachers with autistic students modelling and evaluation.
1     “Chain of Words” theoretical basis is the autism inventory known as IDEA (Inventory of Autism Spectrum Disorders).
1	  Our application is based on the functional area of communication.
1	  Tests carried out in educational institutions using “Chain of Words” have shown that it is an adequate intervention supporting tool for such deficits.
2     In addition, teacher can customize task contents according to each child's characteristics; thus allowing a more personal intervention within the communication field.


### 49
##### doi: 10.1109/TLT.2016.256547
#### Automatic Chinese Factual Question Generation


0	  Question generation is an emerging research area of artificial intelligence in education.
0	  Question authoring tools are important in educational technologies, e.g., intelligent tutoring systems, as well as in dialogue systems.
0	  Approaches to generate factual questions, i.e., questions that have concrete answers, mainly make use of the syntactical and semantic information in a declarative sentence, which is then transformed into questions.
0	  Recently, some research has been conducted to investigate Chinese factual question generation with some limited success.
0	  Reported performance is poor due to unavoidable errors (e.g., sentence parsing, name entity recognition, and rule-based question transformation errors) and the complexity of long Chinese sentences.
1	  This article introduces a novel Chinese question generation system based on three stages, sentence simplification, question generation and ranking, to address the challenge of automatically generating factual questions in Chinese.
1	  The proposed approach and system have been evaluated on sentences from the New Practical Chinese Reader corpus.
2     Experimental results show that ranking improves more than 20 percentage of questions rated as acceptable by annotators, from 65 percent of all questions to 87 percent of the top ranked 25 percent questions.


### 50
##### doi: 10.1109/TLT.2015.251260
#### An Architecture Combining IMS-LD and Web Services for Flexible Data-Transfer in CSCL


1	  This article presents evaluation data regarding the MAPIS3 architecture which is proposed as a solution for the data-transfer among various tools to promote flexible collaborative learning designs.
1	  We describe the problem that this architecture deals with as “tool orchestration” in collaborative learning settings.
1     This term refers to a situation where data relevant to a collaborative learning activity need to be forwarded to and processed by various learning technological tools (e.g. a forum, a pedagogical agent, a service or a software component that provides a specific functionality, etc.), in order for the collaborative activity to be efficiently represented and teachers' pedagogical level decisions implemented.
1	  To facilitate data-transfer among the various tools and accomplish flexible interventions during runtime, the architecture employs a key component (“mediator component”) which makes use of an IMS-LD based representation of the activity.
2	  By implementing the architecture tradeoff analysis method in three case studies, evaluation data regarding the proposed architecture have been recorded and are presented in this paper.
2	  Targeted stakeholders (learners, teachers, and developers) provided valuable insights on the capacity of the architecture to efficiently facilitate tool orchestration during the realization of a flexible IMS-LD based course.
2     Additionally, limitations of IMS-LD are discussed and suggestions are made on how to tackle these constraints and increase flexibility during tool orchestration in collaborative learning deployment.


### 51
##### doi: 10.1109/TLT.2016.255666
#### CMX: The Effects of an Educational MMORPG on Learning and Teaching Computer Programming


0	  Computer programming has for decades posed several difficulties for students of all educational levels.
0	  A number of teaching approaches have been proposed over the years but none seems to fulfil the needs of students nowadays.
0     Students use computers mainly for playing games and the Internet and as quite a few researchers state this aspect of computers should be taken into account in the way we educate them.
1	  Towards this direction, this paper aims to examine the effects of using an educational Massive Multiplayer Online Role Playing Game (MMORPG) on teaching and learning computer programming.
1	  The educational features of an MMORPG called CMX are presented along with a design framework that was devised taking into account previous work in designing educational games.
1	  The effects of CMX on teaching and learning computer programming are assessed through a study with first-year undergraduate students.
1	  Seventy six students used CMX over a period of five weeks for learning various procedural programming concepts.
1	  Students evaluated various aspects of CMX byfilling in a questionnaire that was based on an evaluation framework, which was devised in accordance with the design framework of CMX.
1	  Moreover, the results of a midterm exam that took place priorto using CMX and students' accomplishments in the context of CMX were recorded and analyzed.
2	  The results show that the majority of the students was entertained by playing the game while learning, and felt motivated to continue based on the game's scenario due to the variety of activities included.
2	  In regards to the students' performance, a pre-test and a post-test were carried out in the experimental group, i.e., the participants of this study, and the control group, i.e., students of the course that continued to get taught the same concepts and performed the same assignments as the experimental group, but traditionally.
2     The pre-test and post-test analysis of the performance results for both groups showed that the majority of the students in the experimental group increased their performance in computer programming.
2     Furthermore, students stated they had a positive attitude in regards to re-using CMX in the future in order to learn additional programming concepts.
2     The positive results of this study pave the way for CMX being used in the classroom and expanding the game's functionalities that will further increase students' performance and support teachers in delivering the required knowledge.
2     Moreover, the work reported in this paper offers game designers and teachers methodological and empirical results for game-based learning in such a difficult domain as is computer programming.
2     What is more, the design and evaluation frameworks presented are general enough that they can be easily adjusted and/or extended for designing and assessing educational games in other domains as well.


### 52
##### doi: 10.1109/TLT.2016.257270
#### Investigating the Impact of Gaming Habits, Gender, and Age on the Effectiveness of an Educational Video Game: An Exploratory Study


1	  This study examines the influence of players' age, gender, and gaming preferences and habits (from now on, “gaming preferences”) on the effectiveness of a specific videogame that has been designed to increase the interest towards classical theater among teenagers.
1	  Using a validated instrument, participants were divided into four groups based on their gaming preferences: (1) Well-rounded (WR) gamers, who play all types of games often; (2) Hardcore players, who frequently tend to play first-person shooter (FPS) and sports games; (3) Casual players, who play moderately and tend to play music, social, and puzzle games; and (4) Non-gamers, who barely play videogames at all.
2     Among all of the participants' personal factors (age, gender, and type of player) that were measured, only gaming preferences seemed to have a significant (p<;.05) positive influence on students' interest in theater-going.
2     Neither age nor gender seemed to affect the outcomes.
2	  Casual and Well-rounded gamers scored higher in the game than Non-gamers and Hardcore players.
1	  Due to these results, we also explored whether the gaming profile affected traditional educational approaches.
2     Traditional education worked better than videogames only for students who do not usually play videogames.
2     This study suggests that gaming preferences may influence the effectiveness of different educational approaches.
2     Knowing students' gaming preferences in advance may help educators find the best educational approach for each student.


### 53
##### doi: 10.1109/TLT.2016.256547
#### A Fuzzy Group Decision Making Model for Ordinal Peer Assessment


0	  Massive Open Online Courses (MOOCs) are becoming an increasingly popular choice for education but, to reach their full extent, they require the resolution of new issues like assessing students at scale.
0	  A feasible approach to tackle this problem is peer assessment, in which students also play the role of assessor for assignments submitted by others.
0     Unfortunately, students are unreliable graders so peer assessment often does not deliver accurate results.
1	  In order to mitigate this issue, we propose a new model for ordinal peer assessment based on the principles of fuzzy group decision making.
1	  In our approach, each student is asked to rank a few random submissions from the best to the worst and to specify, with a set of intuitive labels, at what extent each submission is better than the following one in the ranking.
1	  Students' provided rankings are then transformed in fuzzy preference relations, expanded to estimate missing values and aggregated through OWA operators.
1	  The aggregated relation is then used to generate a global ranking between the submissions and to estimate their absolute grades.
2     Experimental results are presented and show better performances with respect to other existing ordinal and cardinal peer assessment techniques both in the reconstruction of the correct ranking and on the estimation of students' grades.


### 54
##### doi: 10.1109/TLT.2017.266267
#### Towards Actionable Learning Analytics Using Dispositions


0	  Studies in the field of learning analytics (LA) have shown students' demographics and learning management system (LMS) data to be effective identifiers of “at risk” performance.
0	  However, insights generated by these predictive models may not be suitable for pedagogically informed interventions due to the inability to explain why students display these behavioral patterns.
0	  Therefore, this study aims at providing explanations of students' behaviors on LMS by incorporating dispositional dimensions (e.g., self-regulation and emotions) into conventional learning analytics models.
1	  Using a combination of demographic, trace, and self-reported data of eight contemporary social-cognitive theories of education from 1,069 students in a blended introductory quantitative course, we demonstrate the potential of dispositional characteristics of students, such as procrastination and boredom.
2     Our results highlight the need to move beyond simple engagement metrics, whereby dispositional learning analytics provide an actionable bridge between learning analytics and educational intervention.


### 55
##### doi: 10.1109/TLT.2016.261631
#### Predicting Student Performance from LMS Data: A Comparison of 17 Blended Courses Using Moodle LMS


0	  With the adoption of Learning Management Systems (LMSs) in educational institutions, a lot of data has become available describing students' online behavior.
0	  Many researchers have used these data to predict student performance.
0	  This has led to a rather diverse set of findings, possibly related to the diversity in courses and predictor variables extracted from the LMS, which makes it hard to draw general conclusions about the mechanisms underlying student performance.
1	  We first provide an overview of the theoretical arguments used in learning analytics research and the typical predictors that have been used in recent studies.
1	  We then analyze 17 blended courses with 4,989 students in a single institution using Moodle LMS, in which we predict student performance from LMS predictor variables as used in the literature and from in-between assessment grades, using both multi-level and standard regressions.
2     Our analyses show that the results of predictive modeling, notwithstanding the fact that they are collected within a single institution, strongly vary across courses.
2     Thus, the portability of the prediction models across courses is low.
2     In addition, we show that for the purpose of early intervention or when in-between assessment grades are taken into account, LMS data are of little (additional) value.
2     We outline the implications of our findings and emphasize the need to include more specific theoretical argumentation and additional data sources other than just the LMS data.


### 56
##### doi: 10.1109/TLT.2016.259952
#### Perceiving Learning at a Glance: A Systematic Literature Review of Learning Dashboard Research


0	  This paper presents a systematic literature review of the state-of-the-art of research on learning dashboards in the fields of Learning Analytics and Educational Data Mining.
0	  Research on learning dashboards aims to identify what data is meaningful to different stakeholders and how data can be presented to support sense-making processes.
0	  Learning dashboards are becoming popular due to the increased use of educational technologies, such as Learning Management Systems (LMS) and Massive Open Online Courses (MOOCs).
1	  The initial search of five main academic databases and GScholar resulted in 346 papers out of which 55 papers were included in the final analysis.
1	  Our review distinguishes different kinds of research studies as well as various aspects of learning dashboards and their maturity regarding evaluation.
2     As the research field is still relatively young, most studies are exploratory and proof-of-concept.
2	  The review concludes by offering a definition for learning dashboards and by outlining open issues and future lines of work in the area of learning dashboards.
2     There is a need for longitudinal research in authentic settings and studies that systematically compare different dashboard designs.


### 57
##### doi: 10.1109/TLT.2016.262226
#### Am I Performing Well at All?


0	  In collaborative learning environments, students work together on assignments in virtual teams and depend on each other's contribution to achieve their learning objectives.
0	  The online learning environment, however, may not only facilitate but also hamper group communication, coordination, and collaboration.
0     Group awareness widgets that visualize information about the different group members based on information collected from the individuals can foster awareness and reflection processes within the group.
1     In this paper, we present a formative data study about the predictive power of several indicators of an awareness widget based on automatically logged user data from an online learning environment.
1	  In order to test whether the information visualized by the widget is in line with the study outcomes, we instantiated the widget indicators with data from four previous runs of the European Virtual Seminar on Sustainable Development (EVS).
1	  We analyzed whether the tutor gradings in these previous years correlated with the students' scores calculated for the widget indicators.
1	  Furthermore, we tested the predictive power of the widget indicators at various points in time with respect to the final grades of the students.
2     The results of our analysis show that the grades and widget indicator scores are significantly and positively correlated, which provides a useful empirical basis for the development of guidelines for students and tutors on how to interpret the widget's visualizations in live runs.


### 58
##### doi: 10.1109/TLT.2016.262629
#### A Novel Web-Based Approach for Visualization and Inspection of Reading Difficulties on University Students


0	  Existing tools aim to detect university students with early diagnosis of dyslexia or reading difficulties, but there are not developed tools that let those students better understand some aspects of their difficulties.
1	  In this paper, a dashboard for visualizing and inspecting early detected reading difficulties and their characteristics, called PADA (acronym for the Spanish name Panel de Analíticas de Aprendizaje de Dislexia en Adultos), is presented.
1     PADA is a web-based tool designed to facilitate the creation of descriptive visualizations required for a better understanding by students about their learner model.
1     Through information visualization techniques, PADA shows students the knowledge in their learner models in order to help them to increase their awareness and to support reflection and self-regulation about their difficulties in reading.
2     PADA provides different learning analytics on reading performance of students, so that they can self-identify their strengths and weaknesses and self-regulate their learning.
1	  This paper describes examples that cover a variety of visualizations (bar-charts, line-charts, and pie-charts) to show user model fragments as personal details, reading profiles, learning styles, and cognitive traits of the students.
1	  We tested PADA with 26 students (aged 21-53 years) of different academic programs and levels, dyslexic and non-dyslexic.
2	  The results show that PADA can assist students in creating awareness, and help them to understand their difficulties associated with the reading tasks, as well as facilitate reflection and self-regulation in the learning process.
2     Implications for the design of learning analytics are discussed and directions for future work are outlined.


### 59
##### doi: 10.1109/TLT.2016.260774
#### Privacy-Preserving Learning Analytics: Challenges and Techniques


0	  Educational data contains valuable information that can be harvested through learning analytics to provide new insights for a better education system.
0	  However, sharing or analysis of this data introduce privacy risks for the data subjects, mostly students.
0     Existing work in the learning analytics literature identifies the need for privacy and pose interesting research directions, but fails to apply state of the art privacy protection methods with quantifiable and mathematically rigorous privacy guarantees.
1	  This work aims to employ and evaluate such methods on learning analytics by approaching the problem from two perspectives: (1) the data is anonymized and then shared with a learning analytics expert, and (2) the learning analytics expert is given a privacy-preserving interface that governs her access to the data.
1	  We develop proof-of-concept implementations of privacy preserving learning analytics tasks using both perspectives and run them on real and synthetic datasets.
2	  We also present an experimental study on the trade-off between individuals' privacy and the accuracy of the learning analytics tasks.


### 60
##### doi: 10.1109/TLT.2016.263950
#### Combining University Student Self-Regulated Learning Indicators and Engagement with Online Learning Events to Predict Academic Performance


0	  Self-regulated learning theories are used to understand the reasons for different levels of university student academic performance.
0	  Similarly, learning analytics research proposes the combination of detailed data traces derived from technology-mediated tasks with a variety of algorithms to predict student academic performance.
0	  The former approach is designed to provide meaningful pedagogical guidance, while the latter is designed to identify event patterns and relations that can be translated into actionable remediation.
0     The benefits of both approaches have motivated this study to investigate if a combination of the self-report data and data arising from an observation of the engagement of students with online learning events offers a deeper understanding and explanation of why some students achieve relatively higher levels of academic performance.
1     In this paper we explore how to combine data about self-regulated learning skills with observable measures of online activity in a blended learning course to increase predictive capabilities of student academic performance for the purposes of informing teaching and task design.
1     A case study in a course with 145 students showed that the variation of the students' final score for their course is better explained when factors from both approaches are considered.
2     The results point to the potential of adopting a combined use of self-report and observed data to gain a more comprehensive understanding of successful university student learning.


### 61
##### doi: 10.1109/TLT.2016.252137
#### Contextual Markup and Mining in Digital Games for Science Learning: Connecting Player Behaviors to Learning Goals


0	  Digital games can make unique and powerful contributions to K-12 science education, but much of that potential remains unrealized.
0	  Research evaluating games for learning still relies primarily on pre- and post-test data, which limits possible insights into more complex interactions between game design features, gameplay, and formal assessment.
0	  Therefore, a critical step forward involves developing rich representations for analyzing gameplay data.
1	  This paper leverages data mining techniques to model learning and performance, using a metadata markup language that relates game actions to concepts relevant to specific game contexts.
1     We discuss results from a classroom study and identify potential relationships between students' planning/prediction behaviors observed across game levels and improvement on formal assessments.
2     The results have implications for scaffolding specific activities, that include physics learning during gameplay, solution planning and effect prediction.
2     Overall, the approach underscores the value of our contextualized approach to gameplay markup to facilitate data mining and discovery.


### 62
##### doi: 10.1109/TLT.2015.248797
#### Constructing a User-Friendly and Smart Ubiquitous Personalized Learning Environment by Using a Context-Aware Mechanism


0	  Although m-learning applications have been widely researched, few studies have investigated applying adaptive learning content to various learning environments and efficient input interfaces.
1	  This study combined a context-aware mechanism, which can be used to provide suitable learning information anytime and anyplace by using GPS technology, with a rapid and user-friendly QR code interface input into a personalized context-aware recommendation (PCAR) learning system for enabling learners to immediately save useful external contents as learning materials.
1	  To improve students' English application abilities efficiently, GPS combined with an intelligent personalized context-aware learning algorithm was used to obtain English learning content that is more practical.
2     The results of several experiments and investigations indicate that the posttest grades of the experimental group, which used the proposed PCAR system, were higher than those of the control group.
2     Furthermore, approximately 80 percent of the users were satisfied with how the system benefited their learning and with its ease of use.
2     The results also show that the PCAR system markedly enhanced learner interest and learning efficiency by creating a convenient virtual English learning environment.


### 63
##### doi: 10.1109/TLT.2017.275449
#### Near Real-Time Comprehension Classification with Artificial Neural Networks: Decoding e-Learner Non-Verbal Behavior


0	  Comprehension is an important cognitive state for learning.
0	  Human tutors recognize comprehension and non-comprehension states by interpreting learner non-verbal behavior (NVB).
0	  Experienced tutors adapt pedagogy, materials, and instruction to provide additional learning scaffold in the context of perceived learner comprehension.
0     Near real-time assessment for e-learner comprehension of on-screen information could provide a powerful tool for both adaptation within intelligent e-learning platforms and appraisal of tutorial content for learning analytics.
0     However, literature suggests that no existing method for automatic classification of learner comprehension by analysis of NVB can provide a practical solution in an e-learning, on-screen, context.
1     This paper presents design, development, and evaluation of COMPASS, a novel near real-time comprehension classification system for use in detecting learner comprehension of on-screen information during e-learning activities.
1	  COMPASS uses a novel descriptive analysis of learner behavior, image processing techniques, and artificial neural networks to model and classify authentic comprehension indicative non-verbal behavior.
1	  This paper presents a study in which 44 undergraduate students answered on-screen multiple choice questions relating to computer programming.
1	  Using a front-facing USB web camera the behavior of the learner is recorded during reading and appraisal of on-screen information.
1	  The resultant dataset of non-verbal behavior and question-answer scores has been used to train artificial neural network (ANN) to classify comprehension and non-comprehension states in near real-time.
2     The trained comprehension classifier achieved normalized classification accuracy of 75.8 percent.


### 64
##### doi: 10.1109/TLT.2018.278990
#### Predicting Contextual Informativeness for Vocabulary Learning


0	  Vocabulary knowledge is essential to educational progress.
0	  High quality vocabulary instruction requires supportive contextual examples to teach word meaning and proper usage.
0     Identifying such contexts by hand for a large number of words can be difficult.
1	  In this work, we take a statistical learning approach to engineer a system that predicts informativeness of a context for target words that span the range of difficulty from middle school to college level.
1	  Our database (released open source) includes 1,000 hand-selected words associated with approximately 70,000 contextual examples gathered from the Internet.
1	  Our training data included each context rated by 10 individuals on a four-point informativeness scale.
1	  We process the text of each context into a novel collection of approximately 600 numerical features that captures diverse linguistic information.
1	  We then fit a nonparametric regression model using Random Forests and compute out-of-sample prediction performance using cross-validation.
2     Our system performs well enough that it can replace a human judge: for a target word not found in our dataset, we can provide curated contexts to a student learner such that most of the contexts (54 percent) feature rich contextual clues and confusing contexts are rare ( <; 1 percent).
2     Thabstract_segmentation_modele quality of our curated contexts was validated by an independent panel of high school language arts teachers.


### 65
##### doi: 10.1109/TLT.2017.271637
#### Automatic Online Lecture Highlighting Based on Multimedia Analysis


0	  Textbook highlighting is widely considered to be beneficial for students.
1	  In this paper, we propose a comprehensive solution to highlight the online lecture videos in both sentence and segment-level, just as is done with paper books.
2     The solution is based on automatic analysis of multimedia lecture materials, such as speeches, transcripts, and slides, in order to facilitate the online learners in this era of e-learning - especially with MOOCs.
2     Sentence-level lecture highlighting basically uses acoustic features from the audio and the output is implemented in subtitle files of corresponding MOOC videos.
2     In comparison with ground truth created by experts, the precision is over 60 percent, which is better than baseline works and also welcomed by user feedbacks.
2     On the other hand, segment-level lecture highlighting works with statistical analysis, mainly by exploring the speech transcripts, the lecture slides and their connections.
2     With the ground truth created by massive users, an evaluation process shows that general accuracy can reach 70 percent, which is fairly promising.
2     Finally, we also attempt to find potential correlation between these two types of lecture highlights.


### 66
##### doi: 10.1109/TLT.2018.281087
#### Student Emotions in Conversation-Based Assessments


0	  Students can experience a variety of emotions while completing assessments.
0	  Some emotions can get in the way of students performing their best (e.g., anxiety, frustration), whereas other emotions can facilitate student performance (e.g., engagement).
0     Many new, non-traditional assessments, such as automated conversation-based assessments (CBA), are designed with the intention to create a test-taking experience that maximizes beneficial emotions for students and minimizes detrimental emotions.
0	  However, there is a paucity of research on students' actual emotional experiences during these non-traditional assessments.
1	  Across two studies, we investigated students' moment-to-moment emotions during two CBAs that differed on construct (science inquiry, mathematical reasoning) and environment (virtual world, chat box).
1	  We found a similar set of emotions to frequently occur across the two studies and came to the preliminary conclusion that students have a generally positive experience with CBAs and that boredom, confusion, curiosity, delight, engagement/flow, frustration, happiness/enjoyment, hope, and pride are the prevalent emotions in CBAs.
1	  The temporal dynamics of emotions as well as the emotion-performance relationship were also investigated across the two studies.
2     Lastly, we discuss how these findings can inform the development of emotion-sensitive CBAs that can facilitate students being able to perform to the best of their ability.


### 67
##### doi: 10.1109/TLT.2017.275662
#### Let's Set Up Some Subgoals: Understanding Human-Pedagogical Agent Collaborations and Their Implications for Learning and Prompt and Feedback Compliance


0	  Research on collaborative learning between humans and virtual pedagogical agents represents a necessary extension to recent research on the conceptual, theoretical, methodological, analytical, and educational issues behind co-and socially-shared regulated learning between humans.
1	  This study presents a novel coding framework that was developed and used to describe collaborations between learners and a pedagogical agent (PA) during a subgoal setting activity with MetaTutor, an intelligent tutoring system.
1	  Learner-PA interactions were examined across two scaffolding conditions: prompt and feedback (PF), and control.
1	  Learners' compliance to follow the PA's prompts and feedback in the PF condition were also examined.
2     Results demonstrated that learners followed the PA's prompts and feedback to help them set more appropriate subgoals for their learning session the majority of the time.
2     Descriptive statistics revealed that when subgoals were set collaboratively between learners and the PA, they generally lead to higher proportional learning gains when compared to less collaboratively set goals.
2     Taken together, the results provide preliminary evidence that learners are both willing to engage in and benefit from collaborative interactions with PAs when immediate, directional feedback and the opportunity to try again are provided.
2     Implications and future directions for extending co-and socially-shared regulated learning theories to include learner-PA interactions are proposed.


### 68
##### doi: 10.1109/TLT.2017.269847
#### A Digital Coach That Provides Affective and Social Learning Support to Low-Literate Learners


1	  In this study, we investigate if a digital coach for low-literate learners that provides cognitive learning support based on scaffolding can be improved by adding affective learning support based on motivational interviewing, and social learning support based on small talk.
1	  Several knowledge gaps are identified: motivational interviewing and small talk must be translated to control rules for this coach, a formal model of participant emotional states is needed to allow the coach to parse the learner's emotional state, and various sensors must be used to let the coach detect and act on this state.
1     We use the situated Cognitive Engineering (sCE) method to update an existing foundation of knowledge with emotional models, motivational interviewing, and small talk theory, technology, and a new exercise in the volunteer work domain.
1	  We use this foundation to create a design specification for an Embodied Conversational Agent (ECA) coach that provides cognitive, affective, and social learning support for this exercise.
1     A prototype is created, and compared to a prototype that only provides cognitive support in a within- and between-subjects experiment.
2     Results show that both prototypes work as expected: learners interact with the coach and complete all exercises.
2     Almost no significant differences are found between the two prototypes, indicating that the affective and social support were not effective as designed.
2     Potential improvements are provided for future work.
2     Results also show significant differences between two subgroups of low-literate participants, and between men and women, reinforcing the importance of using individualized support measures with this demographic.


### 69
##### doi: 10.1109/TLT.2017.275748
#### Be the Data: Embodied Visual Analytics


0	  With the rise of big data, it is becoming increasingly important to educate groups of students at many educational levels about data analytics.
0	  In particular, students without a strong mathematical background may have an unenthusiastic attitude towards high-dimensional data and find it challenging to understand relevant complex analytical methods, such as dimension reduction.
1	  In this paper, we present an embodied approach for visual analytics designed to teach students about exploring alternative 2D projections of high-dimensional data points using weighted multidimensional scaling.
1	  We propose a novel concept, Be the Data, to explore the possibilities of using human's embodied resources to learn from high-dimensional data.
1     In our implemented system, each student embodies a data point, and the position of students in a physical space represents a 2D projection of the high-dimensional data.
1     Students physically move within the room with respect to each other to collaboratively construct alternative projections and receive visual feedback about relevant data dimensions.
1     In this way, students can pose hypotheses about the data to discover the statistical support as well as learn about complex concepts such as high-dimensional distance.
2	  We conducted educational workshops with students in various age groups inexperienced in complex data analytical methods.
2     Our findings indicate that Be the Data provided the necessary engagement to enable students to quickly learn about high-dimensional data and analysis processes despite their minimal prior knowledge.


### 70
##### doi: 10.1109/TLT.2017.272403
#### Active Learning Environments with Robotic Tangibles: Children's Physical and Virtual Spatial Programming Experiences


0	  As computational thinking becomes increasingly important for children to learn, we must develop interfaces that leverage the ways that young children learn to provide opportunities for them to develop these skills.
1	  Active Learning Environments with Robotic Tangibles (ALERT) and Robopad, an analogous on-screen virtual spatial programming environment for educational Human Robot Interaction (HRI), have been developed.
2	  Evaluations of these in the context of free play and open-ended learning activities show that both systems afford opportunities for young children to engage in spatial programming, creating improvisational and sequential programs that mediate interactions between the environment, robots, and humans in responsive and creative ways.
2     These systems demonstrate innovative opportunities for advancing mixed reality spatial programming activities as a form of HRI that fosters engaging seamless cyberlearning experiences, across formal and informal environments.


### 71
##### doi: 10.1109/TLT.2017.276268
#### an Online Game-Based Platform for Second Language Learning


0	  Computer and smartphone-based applications for second language (L2) learning have become popular tools, being integrated in many classroom-based courses and adopted by the public at large.
0	  Yet, despite a significant body of research that suggests that individuals differ in their ability to learn L2, it is still unclear what factors predict successful L2 acquisition and how L2 teaching software can be designed to adapt to individuals' strengths and weaknesses.
1     Here, we describe the architecture of LANGA, an online game-based platform under development for L2 teaching and research, and present a demonstrative proof-of-concept study using the platform.
1	  LANGA is designed to be both an effective and engaging product from the consumer perspective, and a tool that can be used by researchers to easily implement, deploy and test different training modalities for L2 teaching.
1	  Furthermore, key features of LANGA include easy configuration of training via modular design; emphasis on gamified teaching methods; and the use of automated speech recognition to provide learners feedback on verbal production.
1	  A first prototype of LANGA was tested in a small-scale, proof-of-concept study.
2	  Changes in proficiency from preto post-training were measured using recall and recognition tests, while event-related brain potentials (ERPs) were used to assess changes in brain activity related to lexical access over the course of learning.
2	  The results provided initial validation of the platform: participants were able to learn a large proportion of the words taught, and retained the novel words in a two/weeks follow-up.
2     Future directions on the development of the platform are discussed.


### 72
##### doi: 10.1109/TLT.2017.275067
#### Hybrid Augmented Reality for Participatory Learning: The Hidden Efficacy of Multi-User Game-Based Simulation


0	  The goal of this research is to articulate and test a new hybrid Augmented Reality (AR) environment for conceptual understanding.
1	  From the theoretical lens of embodied interaction, we have designed a multi-user participatory simulation called ARfract where visitors in a science museum can learn about complex scientific concepts on the refraction of light through full-body immersion using optical see-through AR glasses, projection-based AR, and gesture technology.
1	  In particular, we developed two different types of simulations for ARfract, namely a game-based simulation and a non-game simulation to explore how the order of different AR simulations influences the perceived usability, user behaviors, learning experiences, and learning outcomes.
1	  For the experiment, 10 dyads were randomly assigned to one of the two experimental conditions: 1) the game-to-non-game condition and 2) the non-game-to-game condition.
2     The results indicate that the learners who experienced the game-based simulation before the non-game simulation performed better than did the other group with the reversed experience order.
2	  This paper also reports the usability, user behaviors, and learning experience issues regarding the affordances of hybrid AR technologies.
2     The major contribution of this proof-of-concept research is that it articulates our understanding of how particular configurations (i.e., order) of the emerging technologies (i.e., hybrid Augmented Reality systems) and its use can lead to different learning outcomes.


### 73
##### doi: 10.1109/TLT.2017.275449
#### Near Real-Time Comprehension Classification with Artificial Neural Networks: Decoding e-Learner Non-Verbal Behavior


0	  Comprehension is an important cognitive state for learning.
0	  Human tutors recognize comprehension and non-comprehension states by interpreting learner non-verbal behavior (NVB).
0	  Experienced tutors adapt pedagogy, materials, and instruction to provide additional learning scaffold in the context of perceived learner comprehension.
0     Near real-time assessment for e-learner comprehension of on-screen information could provide a powerful tool for both adaptation within intelligent e-learning platforms and appraisal of tutorial content for learning analytics.
0     However, literature suggests that no existing method for automatic classification of learner comprehension by analysis of NVB can provide a practical solution in an e-learning, on-screen, context.
1     This paper presents design, development, and evaluation of COMPASS, a novel near real-time comprehension classification system for use in detecting learner comprehension of on-screen information during e-learning activities.
1	  COMPASS uses a novel descriptive analysis of learner behavior, image processing techniques, and artificial neural networks to model and classify authentic comprehension indicative non-verbal behavior.
1	  This paper presents a study in which 44 undergraduate students answered on-screen multiple choice questions relating to computer programming.
1	  Using a front-facing USB web camera the behavior of the learner is recorded during reading and appraisal of on-screen information.
2	  The resultant dataset of non-verbal behavior and question-answer scores has been used to train artificial neural network (ANN) to classify comprehension and non-comprehension states in near real-time.
2     The trained comprehension classifier achieved normalized classification accuracy of 75.8 percent.


### 74
##### doi: 10.1109/TLT.2018.278990
#### Predicting Contextual Informativeness for Vocabulary Learning


0	  Vocabulary knowledge is essential to educational progress.
0	  High quality vocabulary instruction requires supportive contextual examples to teach word meaning and proper usage.
0     Identifying such contexts by hand for a large number of words can be difficult.
1	  In this work, we take a statistical learning approach to engineer a system that predicts informativeness of a context for target words that span the range of difficulty from middle school to college level.
1	  Our database (released open source) includes 1,000 hand-selected words associated with approximately 70,000 contextual examples gathered from the Internet.
1	  Our training data included each context rated by 10 individuals on a four-point informativeness scale.
1	  We process the text of each context into a novel collection of approximately 600 numerical features that captures diverse linguistic information.
1	  We then fit a nonparametric regression model using Random Forests and compute out-of-sample prediction performance using cross-validation.
2     Our system performs well enough that it can replace a human judge: for a target word not found in our dataset, we can provide curated contexts to a student learner such that most of the contexts (54 percent) feature rich contextual clues and confusing contexts are rare ( <; 1 percent).
2     The quality of our curated contexts was validated by an independent panel of high school language arts teachers.


### 75
##### doi: 10.1109/TLT.2017.271637
#### Automatic Online Lecture Highlighting Based on Multimedia Analysis


0	  Textbook highlighting is widely considered to be beneficial for students.
1	  In this paper, we propose a comprehensive solution to highlight the online lecture videos in both sentence and segment-level, just as is done with paper books.
1     The solution is based on automatic analysis of multimedia lecture materials, such as speeches, transcripts, and slides, in order to facilitate the online learners in this era of e-learning - especially with MOOCs.
1     Sentence-level lecture highlighting basically uses acoustic features from the audio and the output is implemented in subtitle files of corresponding MOOC videos.
2     In comparison with ground truth created by experts, the precision is over 60 percent, which is better than baseline works and also welcomed by user feedbacks.
2     On the other hand, segment-level lecture highlighting works with statistical analysis, mainly by exploring the speech transcripts, the lecture slides and their connections.
2     With the ground truth created by massive users, an evaluation process shows that general accuracy can reach 70 percent, which is fairly promising.
2     Finally, we also attempt to find potential correlation between these two types of lecture highlights.


### 76
##### doi: 10.1109/TLT.2018.281087
#### Student Emotions in Conversation-Based Assessments


0	  Students can experience a variety of emotions while completing assessments.
0	  Some emotions can get in the way of students performing their best (e.g., anxiety, frustration), whereas other emotions can facilitate student performance (e.g., engagement).
0     Many new, non-traditional assessments, such as automated conversation-based assessments (CBA), are designed with the intention to create a test-taking experience that maximizes beneficial emotions for students and minimizes detrimental emotions.
0	  However, there is a paucity of research on students' actual emotional experiences during these non-traditional assessments.
1	  Across two studies, we investigated students' moment-to-moment emotions during two CBAs that differed on construct (science inquiry, mathematical reasoning) and environment (virtual world, chat box).
1	  We found a similar set of emotions to frequently occur across the two studies and came to the preliminary conclusion that students have a generally positive experience with CBAs and that boredom, confusion, curiosity, delight, engagement/flow, frustration, happiness/enjoyment, hope, and pride are the prevalent emotions in CBAs.
1	  The temporal dynamics of emotions as well as the emotion-performance relationship were also investigated across the two studies.
2     Lastly, we discuss how these findings can inform the development of emotion-sensitive CBAs that can facilitate students being able to perform to the best of their ability.


### 77
##### doi: 10.1109/TLT.2017.275662
#### Let's Set Up Some Subgoals: Understanding Human-Pedagogical Agent Collaborations and Their Implications for Learning and Prompt and Feedback Compliance


0	  Research on collaborative learning between humans and virtual pedagogical agents represents a necessary extension to recent research on the conceptual, theoretical, methodological, analytical, and educational issues behind co-and socially-shared regulated learning between humans.
1	  This study presents a novel coding framework that was developed and used to describe collaborations between learners and a pedagogical agent (PA) during a subgoal setting activity with MetaTutor, an intelligent tutoring system.
1	  Learner-PA interactions were examined across two scaffolding conditions: prompt and feedback (PF), and control.
1	  Learners' compliance to follow the PA's prompts and feedback in the PF condition were also examined.
2     Results demonstrated that learners followed the PA's prompts and feedback to help them set more appropriate subgoals for their learning session the majority of the time.
2     Descriptive statistics revealed that when subgoals were set collaboratively between learners and the PA, they generally lead to higher proportional learning gains when compared to less collaboratively set goals.
2     Taken together, the results provide preliminary evidence that learners are both willing to engage in and benefit from collaborative interactions with PAs when immediate, directional feedback and the opportunity to try again are provided.
2     Implications and future directions for extending co-and socially-shared regulated learning theories to include learner-PA interactions are proposed.


### 78
##### doi: 10.1109/TLT.2017.269847
#### A Digital Coach That Provides Affective and Social Learning Support to Low-Literate Learners


0	  In this study, we investigate if a digital coach for low-literate learners that provides cognitive learning support based on scaffolding can be improved by adding affective learning support based on motivational interviewing, and social learning support based on small talk.
0	  Several knowledge gaps are identified: motivational interviewing and small talk must be translated to control rules for this coach, a formal model of participant emotional states is needed to allow the coach to parse the learner's emotional state, and various sensors must be used to let the coach detect and act on this state.
1     We use the situated Cognitive Engineering (sCE) method to update an existing foundation of knowledge with emotional models, motivational interviewing, and small talk theory, technology, and a new exercise in the volunteer work domain.
1	  We use this foundation to create a design specification for an Embodied Conversational Agent (ECA) coach that provides cognitive, affective, and social learning support for this exercise.
1     A prototype is created, and compared to a prototype that only provides cognitive support in a within- and between-subjects experiment.
2     Results show that both prototypes work as expected: learners interact with the coach and complete all exercises.
2     Almost no significant differences are found between the two prototypes, indicating that the affective and social support were not effective as designed.
2     Potential improvements are provided for future work.
2     Results also show significant differences between two subgroups of low-literate participants, and between men and women, reinforcing the importance of using individualized support measures with this demographic.


### 79
##### doi: 10.1109/TLT.2017.275748
#### Be the Data: Embodied Visual Analytics


0	  With the rise of big data, it is becoming increasingly important to educate groups of students at many educational levels about data analytics.
0	  In particular, students without a strong mathematical background may have an unenthusiastic attitude towards high-dimensional data and find it challenging to understand relevant complex analytical methods, such as dimension reduction.
1	  In this paper, we present an embodied approach for visual analytics designed to teach students about exploring alternative 2D projections of high-dimensional data points using weighted multidimensional scaling.
1	  We propose a novel concept, Be the Data, to explore the possibilities of using human's embodied resources to learn from high-dimensional data.
1     In our implemented system, each student embodies a data point, and the position of students in a physical space represents a 2D projection of the high-dimensional data.
1     Students physically move within the room with respect to each other to collaboratively construct alternative projections and receive visual feedback about relevant data dimensions.
1     In this way, students can pose hypotheses about the data to discover the statistical support as well as learn about complex concepts such as high-dimensional distance.
1	  We conducted educational workshops with students in various age groups inexperienced in complex data analytical methods.
2     Our findings indicate that Be the Data provided the necessary engagement to enable students to quickly learn about high-dimensional data and analysis processes despite their minimal prior knowledge.


### 80
##### doi: 10.1109/TLT.2017.272403
#### Active Learning Environments with Robotic Tangibles: Children's Physical and Virtual Spatial Programming Experiences


0	  As computational thinking becomes increasingly important for children to learn, we must develop interfaces that leverage the ways that young children learn to provide opportunities for them to develop these skills.
1	  Active Learning Environments with Robotic Tangibles (ALERT) and Robopad, an analogous on-screen virtual spatial programming environment for educational Human Robot Interaction (HRI), have been developed.
1	  Evaluations of these in the context of free play and open-ended learning activities show that both systems afford opportunities for young children to engage in spatial programming, creating improvisational and sequential programs that mediate interactions between the environment, robots, and humans in responsive and creative ways.
2     These systems demonstrate innovative opportunities for advancing mixed reality spatial programming activities as a form of HRI that fosters engaging seamless cyberlearning experiences, across formal and informal environments.


### 81
##### doi: 10.1109/TLT.2017.276268
#### an Online Game-Based Platform for Second Language Learning


0	  Computer and smartphone-based applications for second language (L2) learning have become popular tools, being integrated in many classroom-based courses and adopted by the public at large.
0	  Yet, despite a significant body of research that suggests that individuals differ in their ability to learn L2, it is still unclear what factors predict successful L2 acquisition and how L2 teaching software can be designed to adapt to individuals' strengths and weaknesses.
1     Here, we describe the architecture of LANGA, an online game-based platform under development for L2 teaching and research, and present a demonstrative proof-of-concept study using the platform.
1	  LANGA is designed to be both an effective and engaging product from the consumer perspective, and a tool that can be used by researchers to easily implement, deploy and test different training modalities for L2 teaching.
1	  Furthermore, key features of LANGA include easy configuration of training via modular design; emphasis on gamified teaching methods; and the use of automated speech recognition to provide learners feedback on verbal production.
1	  A first prototype of LANGA was tested in a small-scale, proof-of-concept study.
2	  Changes in proficiency from preto post-training were measured using recall and recognition tests, while event-related brain potentials (ERPs) were used to assess changes in brain activity related to lexical access over the course of learning.
2	  The results provided initial validation of the platform: participants were able to learn a large proportion of the words taught, and retained the novel words in a two/weeks follow-up.
2     Future directions on the development of the platform are discussed.


### 82
##### doi: 10.1109/TLT.2017.275067
#### Hybrid Augmented Reality for Participatory Learning: The Hidden Efficacy of Multi-User Game-Based Simulation


0	  The goal of this research is to articulate and test a new hybrid Augmented Reality (AR) environment for conceptual understanding.
0	  From the theoretical lens of embodied interaction, we have designed a multi-user participatory simulation called ARfract where visitors in a science museum can learn about complex scientific concepts on the refraction of light through full-body immersion using optical see-through AR glasses, projection-based AR, and gesture technology.
1	  In particular, we developed two different types of simulations for ARfract, namely a game-based simulation and a non-game simulation to explore how the order of different AR simulations influences the perceived usability, user behaviors, learning experiences, and learning outcomes.
1	  For the experiment, 10 dyads were randomly assigned to one of the two experimental conditions: 1) the game-to-non-game condition and 2) the non-game-to-game condition.
2     The results indicate that the learners who experienced the game-based simulation before the non-game simulation performed better than did the other group with the reversed experience order.
2	  This paper also reports the usability, user behaviors, and learning experience issues regarding the affordances of hybrid AR technologies.
2     The major contribution of this proof-of-concept research is that it articulates our understanding of how particular configurations (i.e., order) of the emerging technologies (i.e., hybrid Augmented Reality systems) and its use can lead to different learning outcomes.


### 83
##### doi: 10.1109/TLT.2017.273974
#### A Survey on Virtual Reality for Individuals with Autism Spectrum Disorder: Design Considerations


1	  In this article, state of the art on virtual reality (VR) for individuals with autism spectrum disorder (ASD) with a focus on training/targeted intervention is discussed and reflected upon to explore areas for more future benefits.
1	  We present advantages of VR for individuals with ASD.
1	  We identify challenges and design issues for future training applications regarding individuals with ASD.
1	  We discuss and present design guidelines accumulated in the literature so far, mostly based on observations in user studies exploring the usefulness of VR as a training tool for individuals with ASD, with a systematic literature review.
1	  We present and apply a new taxonomy that classifies previous VR works on training individuals with ASD according to immersive and regular (non-immersive) VR systems and types of social, life and safety skills based on a systematic literature review.
1	  We explore the common design considerations of the previous VR studies for training individuals with ASD.
2     Finally, based on the systematic literature reviews, we identify key gaps in the research on this topic and present future research considerations.


### 84
##### doi: 10.1109/TLT.2017.269276
#### Approximately Optimal Teaching of Approximately Optimal Learners


1	  We propose a method of generating teaching policies for use in intelligent tutoring systems (ITS) for concept learning tasks [1] , e.g., teaching students the meanings of words by showing images that exemplify their meanings à la Rosetta Stone [2] and Duo Lingo [3] .
1	  The approach is grounded in control theory and capitalizes on recent work by [4] , [5] that frames the “teaching” problem as that of finding approximately optimal teaching policies for approximately optimal learners (AOTAOL).
2     Our work expands on [4] , [5] in several ways: (1) We develop a novel student model in which the teacher's actions can partially eliminate hypotheses about the curriculum.
2     (2) With our student model, inference can be conducted analytically rather than numerically, thus allowing computationally efficient planning to optimize learning.
1	  (3) We develop a reinforcement learning-based hierarchical control technique that allows the teaching policy to search through deeper learning trajectories.
2     We demonstrate our approach in a novel ITS for foreign language learning similar to Rosetta Stone and show that the automatically generated AOTAOL teaching policy performs favorably compared to two hand-crafted teaching policies.


### 85
##### doi: 10.1109/TLT.2017.268208
#### Automatic Summarization of Lecture Slides for Enhanced Student PreviewTechnical Report and User Study


1	  This paper is an extension of research originally reported in [1] .
1	  Here, we propose a novel method for summarizing lecture slides to enhance students' preview efficiency and understanding of the content.
0	  Students are often asked to prepare for a class by reading lecture materials.
0	  However, because the attention span of students is limited, this is not always beneficial.
1	  We surveyed 326 students regarding the preview of lecture materials, revealing a preference for summarized materials to preview.
1	  Therefore, we developed an automatic summarization method for condensing original lecture materials into a summarized set.
1	  Our proposed approach utilizes image and text processing to extract important pages from lecture materials, optimizing selection of pages in accordance with a specified preview time.
1	  We applied the proposed summarization method to a set of lecture slides.
2	  In an experiment with 372 students, we compared the effectiveness of the summarized slides and the original materials in terms of quiz scores, preview achievement ratio, and time spent previewing.
2     We found that students who previewed the summarized slides achieved better scores on pre-lecture quizzes, even though they spent less time previewing the material.


### 86
##### doi: 10.1109/TLT.2017.268208
#### A Tool for Introducing Computer Science with Automatic Formative Assessment


1	  In this paper we present a software platform called Chatbot designed to introduce high school students to Computer Science (CS) concepts in an innovative way: by programming chatbots.
1	  A chatbot is a bot that can be programmed to have a conversation with a human or robotic partner in some natural language such as English or Spanish.
1     While programming their chatbots, students use fundamental CS constructs such as variables, conditionals, and finite state automata, among others.
1     Chatbot uses pattern matching, state of the art lemmatization techniques, and finite state automata in order to provide automatic formative assessment to the students.
1	  When an error is found, the formative feedback generated is immediate and task-level.
1     We evaluated Chatbot in two observational studies.
1     An online nation-wide competition where more than 10,000 students participated.
1	  And, a mandatory in-class 15-lesson pilot course in three high schools.
2	  We measured indicators of student engagement (task completion, participation, self reported interest, etc.) and found that girls' engagement with Chatbot was higher than boys' for most indicators.
2     Also, in the online competition, the task completion rate for the students that decided to use Chatbot was five times higher than for the students that chose to use the renowned animation and game programming tool Alice.
2     Our results suggest that the availability of automatic formative assessment may have an impact on task completion and other engagement indicators among high school students.


### 87
##### doi: 10.1109/TLT.2017.267900
#### Automatic Chinese Multiple Choice Question Generation Using Mixed Similarity Strategy


0	  Automatic question generation can help teachers to save the time necessary for constructing examination papers.
0	  Several approaches were proposed to automatically generate multiple-choice questions for vocalbuary assessment or grammar exercises.
0     However, most of these studies focused on generating questions in English with a certain similarity strategy.
1     This paper presents a mixed similarity strategy which generates Chinese multiple choice distractors with a statistical regression model including orthographic, phonological and semantic features, i.e., features that were shown in previous psycholinguistics studies to contribute to character recognition.
1	  In a first experiment, we evaluated the predictive power of the proposed features in measuring Chinese character similarity.
2	  One of the significant experimental results showed that the combination of the four proposed categories of features (structure, semantic radical, stroke and meaning) accounts for 62.5 percent of the variance in the human judgments of character similarity.
1	  In the second experiment, a user study was conducted to evaluate the quality of system-generated questions using a test item analysis method.
1	  Two hundred ninety-six Chinese primary school students (10-11-year-old) participated in this study.
1	  We have compared the mixed strategy with another three common distractor generation strategies, orthographic strategy, semantic strategy, and phonological strategy.
2     One of important findings suggested that the mixed strategy significantly outperformed other three strategies in terms of the distractor usefulness and has a highest discrimination power among four strategies.


### 88
##### doi: 10.1109/TLT.2017.269315
#### Learning Buckets: Helping Teachers Introduce Flexibility in the Management of Learning Artifacts Across Spaces


0	  Technology offers rich opportunities for learning across different physical and virtual spaces.
0	  However, most of current across-spaces proposals are either highly teacher-centered, inflexible in the students' self-management of learning artifacts during the enactment, or allow the teacher little/no control of such students' management of artifacts.
0	  Moreover, these proposals tend to be disconnected from the practices and tools that are usual in the classroom.
0	  How can we achieve a middle ground between keeping the teacher in control of across-spaces situations and, at the same time, providing students with a degree of flexibility to manage learning artifacts?
1     Aiming to address such a challenge we propose the notion of learning bucket, and the Bucket-Server, a system implementing such a notion.
1     A learning bucket is a container of learning artifacts which are generated and/or accessed across-spaces by the students during the enactment, according to constraints configured by teachers at design time.
1     The responsive evaluation conducted, based on a feature analysis and a pilot study with experts, suggests that learning buckets can help evolve from teacher- to student-centered approaches, while maintaining the teacher in control of students' actions.
2     The evaluation also indicates that the Bucket-Server surpasses the support provided by alternative proposals to across-spaces learning.


### 89
##### doi: 10.1109/TLT.2017.269068
#### Orchestration Load Indicators and Patterns: In-the-Wild Studies Using Mobile Eye-Tracking


0	  Orchestration load is the effort a teacher spends in coordinating multiple activities and learning processes.
0	  It has been proposed as a construct to evaluate the usability of learning technologies at the classroom level, in the same way that cognitive load is used as a measure of usability at the individual level.
0     However, so far this notion has remained abstract.
1	  In order to ground orchestration load in empirical evidence and study it in a more systematic and detailed manner, we propose a method to quantify it, based on physiological data (concretely, mobile eye-tracking measures), along with human-coded behavioral data.
1	  This paper presents the results of applying this method to four exploratory case studies, where four teachers orchestrated technology-enhanced face-to-face lessons with primary, secondary school, and university students.
2     The data from these studies provide a first validation of this method in different conditions, and illustrate how it can be used to understand the effect of different classroom factors on orchestration load.
2     From these studies, we also extract empirical insights about classroom orchestration using technology.


### 90
##### doi: 10.1109/TLT.2017.270409
#### Using the Tablet Gestures and Speech of Pairs of Students to Classify Their Collaboration


0	  Effective collaboration between student peers is not spontaneous.
0	  A system that can measure collaboration in real-time may be useful, as it could alert an instructor to pairs that need help in collaborating effectively.
1	  We tested whether superficial measures of speech and user interface actions would suffice for measuring collaboration.
1	  Pairs of students solved complex math problems while data were collected in the form of verbal interaction and user action logs from the students' tablets.
1	  We distinguished four classifications of interactivity: collaboration, cooperation, high asymmetric contribution and low asymmetric contribution.
1	  Human coders used richer data (several video streams) to choose one of these codes for each episode.
1	  Thousands of features were extracted computationally from the log and audio data.
1	  Machine learning was used to induce a detector that also assigned a code to each episode as a function of these features.
1	  Detectors for combinations of codes were induced as well.
2     The best detector's overall accuracy was 96 percent (kappa = 0.92) compared to human coding.
2     This high level of agreement suggests that superficial features of speech and log data do suffice for measuring collaboration.
2     However, these results should be viewed as preliminary because the particular task may have made it relatively easy to distinguish collaboration from cooperation.


### 91
##### doi: 10.1109/TLT.2017.270811
#### Mining Online Discussion Data for Understanding Teachers Reflective Thinking


0	  Teachers' online discussion text data shed light on their reflective thinking.
0	  With the growing scale of text data, the traditional way of manual coding, however, has been challenged.
0     In order to process the large-scale unstructured text data, it is necessary to integrate the inductive content analysis method and educational data mining techniques.
1	  An inductive content analysis on samples taken from 17,624 posts was implemented and the categories of teachers' reflective thinking were obtained.
1	  Based on the results of inductive content analysis, we implemented a single-label text classification algorithm to classify the sample data.
1	  Then, we applied the trained classification model on a large-scale and unexplored online discussion text data set and two types of visualizations of the results were provided.
1	  By using the categories gained from inductive content analysis to create a radar map, teachers' reflection level was represented.
1	  In addition, a cumulative adjacency matrix was created to characterize the evolution of teachers' reflective thinking.
2     This study could partly explain how teachers reflected in online professional learning environments and brought awareness to educational policy makers, teacher training managers, and education researchers.


### 92
##### doi: 10.1109/TLT.2017.268745
#### Evaluating Cognitive and Affective Outcomes of a Digital Game-Based Math Test


0	  Even though digital learning games have become common in education, relatively little is known about the usefulness of game-based assessment.
0	  This paper aims to explore if a game-based math test can provide added value to math education with respect to cognitive and affective outcomes.
1	  We used in-game measures, embedded in the game called Semideus Exam, focusing on conceptual fraction knowledge.
1	  In order to validate the game-based assessment approach, we compared the cognitive outcomes of 51 Finnish sixth graders, who completed both paper-based and game-based math tests in a randomized order.
1	  In addition, the students' test anxiety and flow experience were measured to evaluate the affective outcomes.
2     The results indicate that the game-based test scores correlated significantly with the paper-based test scores suggesting that the game-based assessment was successfully implemented and the game provided comparable data with the paper-based test approach.
2     More importantly, the results revealed that game-based assessment lowered test anxiety and increased engagement which is likely to decrease assessment bias caused by test anxiety.
2     In addition, the results show that earlier playing experience and gender did not influence the game-based test score suggesting fairness of the game-based assessment approach.
2     Although we identified several benefits of the game-based assessment approach, more evidence is needed on the usefulness and fairness of game-based assessments.


### 93
##### doi: 10.1109/TLT.2016.261430
#### From Learners to Earners: Enabling MOOC Learners to Apply Their Skills and Earn Money in an Online Market Place


0	  Massive Open Online Courses (MOOCs) aim to educate the world.
0	  More often than not, however, MOOCs fall short of this goal-a majority of learners are already highly educated (with a Bachelor's degree or more) and come from specific parts of the (developed) world.
0     Learners from developing countries without a higher degree are underrepresented, though desired, in MOOCs.
0     One reason for those learners to drop out of a course can be found in their financial realities and the subsequent limited amount of time they can dedicate to a course besides earning a living.
0     If we could pay learners to take a MOOC, this hurdle would largely disappear.
0	  With MOOCS, this leads to the following fundamental challenge: How can learners be paid at scale?
0	  Ultimately, we envision a recommendation engine that recommends tasks from online market places such as Upwork or witmart to learners, that are relevant to the course content of the MOOC.
0	  In this manner, the learners learn and earn money.
1	  To investigate the feasibility of this vision, in this paper, we explored to what extent (1) online market places contain tasks relevant to a specific MOOC, and (2) learners are able to solve real-world tasks correctly and with sufficient quality.
2     Finally, based on our experimental design, we were also able to investigate the impact of real-world bonus tasks in a MOOC on the general learner population.


### 94
##### doi: 10.1109/TLT.2018.279987
#### A Multimodal Assessment Framework for Integrating Student Writing and Drawing in Elementary Science Learning


0	  Science learning is inherently multimodal, with students utilizing both drawings and writings to explain observations of physical phenomena.
0	  As such assessments in science should accommodate the many ways students express their understanding, especially given evidence that understanding is distributed across both drawing and writing.
0     In recent years advanced automated assessment techniques that evaluate expressive student artifacts have emerged.
0     However, these techniques have largely operated individually, each considering only a single mode.
1	  We propose a framework for the multimodal automated assessment of students' writing and drawing to leverage the synergies inherent across modalities and create a more complete and accurate picture of a student's knowledge.
1	  We introduce a multimodal assessment framework as well as two computational techniques for automatically analyzing student writings and drawings: a convolutional neural network-based model for assessing student writing, and a topology-based model for assessing student drawing.
2	  Evaluations with elementary students' writings and drawings collected with a tablet-based digital science notebook demonstrate that 1) each of the framework's two modalities provide an independent and complementary measure of student science learning, and 2) the computational methods are capable of accurately assessing student work from both modalities and offer the potential for integration in technology-rich learning environments for real-time formative assessment.


### 95
##### doi: 10.1109/TLT.2018.282371
#### Adaptive Gamification for Learning Environments


0	  In spite of their effectiveness, learning environments often fail to engage users and end up under-used.
0	  Many studies show that gamification of learning environments can enhance learners' motivation to use learning environments.
0	  However, learners react differently to specific game mechanics and little is known about how to adapt gaming features to learners' profiles.
1	  In this paper, we propose a process for adapting gaming features based on a player model.
1	  This model is inspired from existing player typologies and types of gamification elements.
1	  Our approach is implemented in a learning environment with five different gaming features, and evaluated with 266 participants.
2     The main results of this study show that, amongst the most engaged learners (i.e., learners who use the environment the longest), those with adapted gaming features spend significantly more time in the learning environment.
2     Furthermore, learners with features that are not adapted have a higher level of amotivation.
2     These results support the relevance of adapting gaming features to enhance learners' engagement, and provide cues on means to implement adaptation mechanisms.


### 96
##### doi: 10.1109/TLT.2018.280818
#### Automatic Question Tagging with Deep Neural Networks


0	  In recent years, computerized adaptive testing (CAT) has gained popularity as an important means to evaluate students' ability.
0	  Assigning tags to test questions is crucial in CAT.
0     Manual tagging is widely used for constructing question banks; however, this approach is time-consuming and might lead to consistency issues.
0	  Automatic question tagging, an alternative, has not been studied extensively.
1	  In this paper, we propose a position-based attention model and keywords-based model to automatically tag questions with knowledge units.
1	  With regard to multiple-choice questions, the proposed models employ mechanisms to capture useful information from keywords to enhance tagging performance.
1	  Unlike traditional machine learning-based tagging methods, our models utilize deep neural networks to represent questions using contextual information.
2     The experimental results show that our proposed models outperform some traditional classification and topic methods by a large margin on an English question bank dataset.


### 97
##### doi: 10.1109/TLT.2018.279319
#### Early Detection Prediction of Learning Outcomes in Online Short-Courses via Learning Behaviors


1	  We study learning outcome prediction for online courses.
0	  Whereas prior work has focused on semester-long courses with frequent student assessments, we focus on short-courses that have single outcomes assigned by instructors at the end.
0	  The lack of performance data and generally small enrollments makes the behavior of learners, captured as they interact with course content and with one another in Social Learning Networks (SLN), essential for prediction.
1	  Our method defines several (machine) learning features based on the processing of behaviors collected on the modes of (human) learning in a course, and uses them in appropriate classifiers.
2     Through evaluation on data captured from three two-week courses hosted through our delivery platforms, we make three key observations: (i) behavioral data contains signals predictive of learning outcomes in short-courses (with classifiers achieving AUCs ≥ 0.8 after the two weeks), (ii) early detection is possible within the first week (AUCs ≥ 0.7 with the first week of data), and (iii) the content features have an “earliest” detection capability (with higher AUC in the first few days), while the SLN features become the more predictive set over time as the network matures.
2     We also discuss how our method can generate behavioral analytics for instructors.


### 98
##### doi: 10.1109/TLT.2018.282331
#### From Study Tactics to Learning Strategies: An Analytical Method for Extracting Interpretable Representations


0	  Research into self-regulated learning has traditionally relied upon self-reported data.
0	  While there is a rich body of literature that has extracted invaluable information from such sources, it suffers from a number of shortcomings.
0	  For instance, it has been shown that surveys often provide insight into students' perceptions about learning rather than how students actually employ study tactics and learning strategies.
0	  Accordingly, recent research has sought to assess students' learning strategies and, by extension, their self-regulated learning via trace data collected from digital learning environments.
0     A number of studies have amply demonstrated the ability of educational data mining and learning analytics methods to identify patterns indicative of learning strategies within trace log data.
0     However, many of these methods are limited in their ability to describe and interpret differences between extracted latent representations at varying levels of granularity (for instance, in terms of the underlying data of student actions and behavior).
1     To address this limitation, the present study proposes a new methodology whereby interpretable representations of student's self-regulating behavior are derived at two theoretically inspired levels: that of learning strategies, and the study tactics that compose them.


### 99
##### doi: 10.1109/TLT.2018.281813
#### Implementing On-Call-Tutor System for Facilitating Peer-Help Activities


1	  In this study, we developed an on-call-tutor system to facilitate peer-help activities.
1	  The system was implemented in a face-to-face heterogeneous classroom with 119 students from different departments who were not familiar with each other.
1	  Students learned Geographic Information System (GIS) in a computer classroom in two groups: students, who learned without our on-call-tutor system, were in a control group whereas those, who learned with our on-call-tutor system, were in an experimental group.
1	  When students had any difficulties during the learning process (e.g., to use GIS), they could request help face-to-face (the control group) or through the system (the experimental group).
1	  When students requested help via the system, it selected one student from a pool of those who perceived himself/herself to have excellent learning progress and then assigned him/her as a tutor to a student in need (tutee).
1	  We carried out this study to explore whether our on-call-tutor system is useful to facilitate peer-help activities and to enhance student learning performance.
1	  To this end, based on the theoretical framework of this study, we designed an experiment in which learning performance and behavior of students in the two groups were explored and compared.
1	  We also analyzed student social network and investigated whether it can be extended with the support of the on-call-tutor system.
1	  Finally, factors that influence making a friend with an unfamiliar classmate and relationship among these factors were explored.
1	  For the data analysis, we gathered student logs to send messages, to help peers, and their practice time.
1	  We also collected students' responses to a questionnaire survey about their attitudes towards using our on-call-tutor system.
1	  In addition, student learning performance was measured and interviews with students were carried out.
2     Our results showed that, compared to students in the control group, those in the experimental group had more peer-help activities and better learning performance.
2     Results also showed that students built their social network in which they interacted with each other and obtained/provided social support and useful knowledge for learning purpose.
2     In addition, we found that usefulness of our system for learning was the main factor that influenced students' willingness to build friendship in the social network with familiar/unfamiliar classmates and then communicate with them.
2     Based on our results, we suggest employing the on-call-tutor system in a heterogeneously grouped classroom in order to facilitate peer-help activities, especially when students learn difficult subjects like computer software and are not acquainted with one another.
2     Our system is useful for students in requesting help and finding a tutor in case when they need assistance or some further learning information.
2     With the assistance of our system, students can build the social network among classmates and communicate with each other in order to find/provide learning assistance and social support.
2     As a result, student peer-help activities can be facilitated and learning performance enhanced.


### 100
##### doi: 10.1109/TLT.2018.280744
#### Personalized Affective Feedback to Address Students’ Frustration in ITS


0	  The importance of affective states in learning has led many Intelligent Tutoring Systems (ITS) to include students' affective states in their learner models.
0	  The adaptation and hence the benefits of an ITS can be improved by detecting and responding to students' affective states.
0	  In prior work, we have created and validated a theory-driven model for detecting students' frustration, as well as identifying its causes as students interact with the ITS.
1	  In this paper, we present a strategy to respond to students' frustration by offering motivational messages that address different causes of frustration.
1     Based on attribution theory, these messages are created to praise the student's effort, attribute the results to the identified cause, show sympathy for failure or obtain feedback from the students.
1	  We implemented our approach in three schools where students interacted with the ITS.
1	  Data from 188 students from the three schools collected across two weeks was used for our analysis.
2     The results suggest that the frustration instances reduced significantly statistically (p <; 0:05), due to the motivational messages.
2     This study suggests that motivational messages that use attribution theory and address the reason for frustration reduce the number of frustration instances per session.


### 101
##### doi: 10.1109/TLT.2018.281087
#### SciChallenge: A Social Media Aware Platform for Contest-Based STEM Education and Motivation of Young Students


0	  Scientific and technological innovations have become increasingly important as we face the benefits and challenges of both globalization and a knowledge-based economy.
0	  Still, enrolment rates in STEM degrees are low in many European countries and consequently there is a lack of adequately educated workforce in industries.
0     We believe that this can be mainly attributed to pedagogical issues, such as the lack of engaging hands-on activities utilized for science and math education in middle and high schools.
1     In this paper, we report our work in the SciChallenge European project, which aims at increasing the interest of preuniversity students in STEM disciplines, through its distinguishing feature, the systematic use of social media for providing and evaluation of the student-generated content.
2     A social media-aware contest and platform were thus developed and tested in a panEuropean contest that attracted >700 participants.
2     The statistical analysis and results revealed that the platform and contest positively influenced participants STEM learning and motivation, while only the gender factor for the younger study group appeared to affect the outcomes (confidence level - p<;.05).


### 102
##### doi: 10.1109/TLT.2017.278442
#### Using Machine Learning to Detect ‘Multiple-Account’ Cheating and Analyze the Influence of Student and Problem Features


0	  One of the reported methods of cheating in online environments in the literature is CAMEO (Copying Answers using Multiple Existences Online), where harvesting accounts are used to obtain correct answers that are later submitted in the master account which gives the student credit to obtain a certificate.
0	  In previous research, we developed an algorithm to identify and label submissions that were cheated using the CAMEO method; this algorithm relied on the IP of the submissions.
1     In this study, we use this tagged sample of submissions to i) compare the influence of student and problems characteristics on CAMEO and ii) build a random forest classifier that detects submissions as CAMEO without relying on IP, achieving sensitivity and specificity levels of 0.966 and 0.996, respectively.
2     Finally, we analyze the importance of the different features of the model finding that student features are the most important variables towards the correct classification of CAMEO submissions, concluding also that student features have more influence on CAMEO than problem features.


### 103
##### doi: 10.1109/TLT.2018.283694
#### When Does Collaboration Lead to Deeper Learning? Renewed Definitions of Collaboration for Engineering Students


0	  Collaboration is an increasingly important and difficult skill for graduate engineers to develop.
0	  While universities provide some measures of collaboration ability of students on graduation, there is still some dissatisfaction with the level of preparedness of students for collaborative activity in the workplace.
1     This paper presents a case study of a first year engineering cohort of more than 350 students to discuss the value of improving both the measures and definitions of collaborative ability on graduation of engineering students in a blended learning context.
1     Research methods from student approaches to learning research and social network analysis are adopted to provide experiential and mathematical evidence of successful collaboration.
2     The results provide a characterization of groups of students with respect to their approach to collaboration and the features most common in productively collaborative students.
2     The discussion has implications for teaching, course design, and how universities define and measure collaborative ability of students.

### 104
##### doi: 10.1109/TLT.2018.283037
#### MOOCs as a Remedial Complement: Students’ Adoption and Learning Outcomes


0	  The effectiveness of remedial mathematics courses in post-secondary education has been a controversial topic for years.
0	  Higher Education institutions need their students to have basic understandings of the subjects to be imparted in the first semesters, but since they come with different backgrounds and prior knowledge, this is not always possible and many students struggle in their first courses.
1	  This paper presents the results of students' adoption and learning outcomes of using four MOOCs as a complementary study resource for an on-campus calculus diagnostic exam.
1	  Over 700 newly admitted university students had to take a mandatory diagnostic exam on four calculus topics before classes started.
1	  MOOCs were proposed as a voluntary support for studying these subjects.
1	  Following a mixed method analysis, we studied why and when the students used the online courses and we also measured the effects of its use in terms of the students' diagnostic exam grades and learning outcomes.
2     The results show that students mostly used the MOOCs to study the subjects that were not covered in their secondary studies.
2     Students who were active in these course topics obtained better scores, having more chances of passing the diagnostic exam than students who did not study with the MOOCs.
2     Furthermore, students not only used the MOOCs for studying for the exam, but also for refreshing concepts for future courses.


### 105
##### doi: 10.1109/TLT.2019.291107
#### Improving Predictive Modeling for At-Risk Student Identification: A Multistage Approach


0	  Performance prediction is a leading topic in learning analytics research due to its potential to impact all tiers of education.
1	  This study proposes a novel predictive modeling method to address the research gaps in existing performance prediction research.
1     The gaps addressed include: the lack of existing research focus on performance prediction rather than identifying key performance factors; the lack of common predictors identified for both K-12 and higher education environments; and the misplaced focus on absolute engagement levels rather than relative engagement levels.
1     Two datasets, one from higher education and the other from a K-12 online school with 13 368 students in more than 300 courses, were applied using the predictive modeling technique.
2     The results showed the newly suggested approach had higher overall accuracy and sensitivity rates than the traditional approach.
2     In addition, two generalizable predictors were identified from instruction-intensive and discussion-intensive courses.


### 106
##### doi: 10.1109/TLT.2019.291216
#### Developing Early Detectors of Student Attrition and Wheel Spinning Using Deep Learning


0	  The increased usage of computer-based learning platforms and online tools in classrooms presents new opportunities to not only study the underlying constructs involved in the learning process, but also use this information to identify and aid struggling students.
0	  Many learning platforms, particularly those driving or supplementing instruction, are only able to provide aid to students who interact with the system.
0     With this in mind, student persistence emerges as a prominent learning construct contributing to students success when learning new material.
0     Conversely, high persistence is not always productive for students, where additional practice does not help the student move toward a state of mastery of the material.
1     In this paper, we apply a transfer learning methodology using deep learning and traditional modeling techniques to study high and low representations of unproductive persistence.
1     We focus on two prominent problems in the fields of educational data mining and learner analytics representing low persistence, characterized as student “stopout,” and unproductive high persistence, operationalized through student “wheel spinning,” in an effort to better understand the relationship between these measures of unproductive persistence (i.e., stopout and wheel spinning) and develop early detectors of these behaviors.
2	  We find that models developed to detect each within and across-assignment stopout and wheel spinning are able to learn sets of features that generalize to predict the other.
2     We further observe how these models perform at each learning opportunity within student assignments to identify when interventions may be deployed to best aid students who are likely to exhibit unproductive persistence.


### 107
##### doi: 10.1109/TLT.2019.291106
#### A Quest for a One-Size-Fits-All Neural Network: Early Prediction of Students at Risk in Online Courses


0	  A significant amount of research effort has been put into finding variables that can identify students at risk based on activity records available in learning management systems (LMS).
0	  These variables often depend on the context, for example, the course structure, how the activities are assessed or whether the course is entirely online or a blended course.
0     To the best of our knowledge, a predictive model that can generalize well to many different types of courses using data available in the LMS does not currently exist in the learning analytics literature.
1     In this study, early prediction of students at risk is tackled by training a number of neural networks to predict which students would likely submit their assignments on time based on their activity up to two days before assignments' due dates.
1     Five different datasets that cover a total of 78 722 student enrolments in 5487 courses have been used in this study.
1     In order to improve how well the neural networks generalize, our networks can perform different forms of feature engineering using course peers data.
1	  The different architectures of these networks have been compared to find the one with more predictive power.
1	  To validate the models trained from the networks, both new datasets and unseen examples extracted from the same datasets have been used for training.
2     Our research show that adding contextual information results in better prediction accuracies and F1 scores.
2     Our networks are able to give predictions with accuracies in the 67.46-81.63% range and F1 scores in the 71.30-83.09% range.


### 108
##### doi: 10.1109/TLT.2019.291183
#### How Widely Can Prediction Models Be Generalized? Performance Prediction in Blended Courses


0	  Blended courses that mix in-person instruction with online platforms are increasingly common in secondary education.
0	  These platforms record a rich amount of data on students' study habits and social interactions.
0     Prior research has shown that these metrics are correlated with students performance in face-to-face classes.
0     However, predictive models for blended courses are still limited and have not yet succeeded at early prediction or cross-class predictions, even for repeated offerings of the same course.
1	  In this paper, we use data from two offerings of two different undergraduate courses to train and evaluate predictive models of student performance based on persistent student characteristics including study habits and social interactions.
1	  We analyze the performance of these models on the same offering, on different offerings of the same course, and across courses to see how well they generalize.
1	  We also evaluate the models on different segments of the courses to determine how early reliable predictions can be made.
2     This paper tells us in part how much data is required to make robust predictions and how cross-class data may be used, or not, to boost model performance.
2     The results of this study will help us better understand how similar the study habits, social activities, and the teamwork styles are across semesters for students in each performance category.
2     These trained models also provide an avenue to improve our existing support platforms to better support struggling students early in the semester with the goal of providing timely intervention.


### 109
##### doi: 10.1109/TLT.2019.291107
#### Interpretable Multiview Early Warning System Adapted to Underrepresented Student Populations


0	  Early warning systems have been progressively implemented in higher education institutions to predict student performance.
0	  However, they usually fail at effectively integrating the many information sources available at universities to make more accurate and timely predictions, they often lack decision-making reasoning to motivate the reasons behind the predictions, and they are generally biased toward the general student body, ignoring the idiosyncrasies of underrepresented student populations (determined by socio-demographic factors such as race, gender, residency, or status as a freshmen, transfer, adult, or first-generation students) that traditionally have greater difficulties and performance gaps.
1	  This paper presents a multiview early warning system built with comprehensible Genetic Programming classification rules adapted to specifically target underrepresented and underperforming student populations.
1	  The system integrates many student information repositories using multiview learning to improve the accuracy and timing of the predictions.
1     Three interfaces have been developed to provide personalized and aggregated comprehensible feedback to students, instructors, and staff to facilitate early intervention and student support.
2     Experimental results, validated with statistical analysis, indicate that this multiview learning approach outperforms traditional classifiers.
2     Learning outcomes will help instructors and policy-makers to deploy strategies to increase retention and improve academics.


### 110
##### doi: 10.1109/TLT.2019.291158
#### Multiview Learning for Early Prognosis of Academic Performance: A Case Study


0	  Educational data mining has gained a lot of attention among scientists in recent years and constitutes an efficient tool for unraveling the concealed knowledge in educational data.
0	  Recently, semisupervised learning methods have been gradually implemented in the educational process demonstrating their usability and effectiveness.
0     Cotraining is a representative semisupervised method aiming to exploit both labeled and unlabeled examples, provided that each example is described by two features views.
0     Nevertheless, it is yet to be used in various scientific fields, among which the educational field as well, since the assumption about the existence of two feature views cannot be easily put into practice.
1	  Within this context, the main purpose of this study is to evaluate the efficiency of a proposed cotraining method for early prognosis of undergraduate students' performance in the final examinations of a distance course based on a plethora of attributes which are naturally divided into two distinct views, since they are originated from different sources.
1	  More specifically, the first view consists of attributes regarding students' characteristics and academic achievements which are manually filled out by their tutors, whereas the second one consists of attributes tracking students' online activity in the course learning management system and which are automatically recorded by the system.
2     The experimental results demonstrate the superiority of the proposed cotraining method as opposed to state-of-the-art semisupervised and supervised methods.


### 111
##### doi: 10.1109/TLT.2019.291107
#### Predicting the Risk of Academic Dropout With Temporal Multi-Objective Optimization


0	  In the European academic systems, the public funding to single universities depends on many factors, which are periodically evaluated.
0	  One of such factors is the rate of success, that is, the rate of students that do complete their course of study.
0     At many levels, therefore, there is an increasing interest in being able to predict the risk that a student will abandon the studies, so that (specific, personal) corrective actions may be designed.
1     In this paper, we propose an innovative temporal optimization model that is able to identify the earliest moment in a student's career in which a reliable prediction can be made concerning his/her risk of dropping out from the course of studies.
2     Unlike most available models, our solution can be based on the academic behavior alone, and our evidence suggests that by ignoring classically used attributes such as the gender or the results of pre-academic studies one obtains more accurate, and less biased, models.
1	  We tested our system on real data from the three-year degree in computer science offered by the University of Ferrara (Italy).


### 112
##### doi: 10.1109/TLT.2019.291335
#### Feature Extraction for Next-Term Prediction of Poor Student Performance


0	  Developing tools to support students and learning in a traditional or online setting is a significant task in today's educational environment.
0	  The initial steps toward enabling such technologies using machine learning techniques focused on predicting the student's performance in terms of the achieved grades.
0     However, these approaches do not perform as well in predicting poor-performing students.
0     The objective of our work is twofold.
1     First, in order to overcome this limitation, we explore if poorly performing students can be more accurately predicted by formulating the problem as binary classification, based on data provided before the start of the semester.
1	  Second, in order to gain insights as to which are the factors that can lead to poor performance, we engineered a number of human-interpretable features that quantify these factors.
1	  These features were derived from the students' grades from the University of Minnesota, an undergraduate public institution.
1	  Based on these features, we perform a study to identify different student groups of interest, while at the same time, identify their importance.
2     As the resulting models provide us with different subsets of correct predictions, their combination can boost the overall performance.


### 113
##### doi: 10.1109/TLT.2019.291216
#### An Early Feedback Prediction System for Learners At-Risk Within a First-Year Higher Education Course


0	  Identifying at-risk students as soon as possible is a challenge in educational institutions.
0	  Decreasing the time lag between identification and real at-risk state may significantly reduce the risk of failure or disengage.
0     In small courses, their identification is relatively easy, but it is impractical on larger ones.
0     Current Learning Management Systems store a large amount of data that could help to generate predictive models to early identification of students in online and blended learning.
1     The contribution of this paper is twofold: First, a new adaptive predictive model is presented based only on students' grades specifically trained for each course.
1	  A deep analysis is performed in the whole institution to evaluate its performance accuracy.
1	  Second, an early warning system is developed, focusing on dashboards visualization for stakeholders (i.e., students and teachers) and an early feedback prediction system to intervene in the case of at-risk identification.
1	  The early warning system has been evaluated in a case study on a first-year undergraduate course in computer science.
2     We show the accuracy of the correct identification of at-risk students, the students' appraisal, and the most common factors that lead to at-risk level.


### 114
##### doi: 10.1109/TLT.2019.291160
#### From Lab to Production: Lessons Learnt and Real-Life Challenges of an Early Student-Dropout Prevention System


0	  This paper presents the work done to support student dropout risk prevention in a real online e-learning environment: A Spanish distance university with thousands of undergraduate students.
0	  The main goal is to prevent students from abandoning the university by means of retention actions focused on the most at-risk students, trying to maximize the effectiveness of institutional efforts in this direction.
1	  With this purpose, we generated predictive models based on the C5.0 algorithm using data from more than 11,000 students collected along five years.
1     Then, we developed SPA (Sistema de Predicciæn de Abandono, dropout prediction system in Spanish), an early warning system that uses these models to generate static early dropout-risk predictions and dynamic periodically updated ones.
1     It also supports the recording of the resulting retention-oriented interventions for further analysis.
1     SPA is in production since 2017 and is currently in its fourth semester of continuous use.
1     It has calculated more than 117,000 risk scores to predict the dropout risk of more than 5700 students.
1     About 13,000 retention actions have been recorded.
2     The white-box predictive models used in production provided reasonably good results, very close to those obtained in the laboratory.
2     On the way from research to production, we faced several challenges that needed to be effectively addressed in order to be successful.
2	  In this paper, we share the challenges faced and the lessons learnt during this process.
2     We hope this helps those who wish to cross the road from predictive modeling with potential value to the exploitation of complete dropout prevention systems that provide sustained value in real production scenarios.


### 115
##### doi: 10.1109/TLT.2019.291128
#### Pedagogical Intervention Practices: Improving Learning Engagement Based on Early Prediction


0	  Most educational institutions adopted the hybrid teaching mode through learning management systems.
0	  The logging data/clickstream could describe learners' online behavior.
0     Many researchers have used them to predict students' performance, which has led to a diverse set of findings, but how to use insights from captured data to enhance learning engagement is an open question.
0     Furthermore, identifying students at risk of failure is only the first step in truly addressing this issue.
0     It is important to create actionable predictive model in the real-world contexts to design interventions.
1	  In this paper, we first extracted features from students' learning activities and study habits to predict students' performance in the Kung Fu style competency education.
1	  Then, we proposed a TrAdaBoost-based transfer learning model, which was pretrained using the data of the former course iteration and applied to the current course iteration.
2     Our results showed that the generalization ability of the prediction model across the teaching iterations is high, and the model can achieve relatively high precision even when the new data are not sufficient to train a model alone.
2     This work helped in timely intervention toward the at-risk students.
1	  In addition, two intervention experiments with split-test were conducted separately in Fall 2017 and Summer 2018.
2     The statistical tests showed that both behavior-based reminding intervention and error-related recommending intervention that based on early prediction played a positive role in improving the blended learning engagement.


### 116
##### doi: 10.1109/TLT.2016.255411
#### Context-Aware Learning in Physics Experiments


0	  Smart Glasses such as Google Glass are mobile computers combining classical Head-Mounted Displays (HMD) with several sensors.
0	  Therefore, contact-free, sensor-based experiments can be linked with relating, near-eye presented multiple representations.
0     We will present a first approach on how Smart Glasses can be used as an experimental tool for head-centered, context-aware, wearable-technology-enhanced, and inquiry-based learning in physics education.
1	  Therefore, we developed an app that is based on the Google Glass platform and designed to perform educational physical experiments on the topic of acoustics.
1	  Its initial application is intended for high-school students whose task is to study the relationship between the frequency of the sound generated by hitting a glass of water and the amount of water in the glass.
1	  The core idea is to have Google Glass automatically measure both the water fill level with the camera and the sound frequency with the microphone, and incrementally generate a fill level/frequency graph in the HMD.
1	  We designed an educational setting and studied its effect on cognitive and affective variables with an intervention-control-group design.
1	  While the intervention group analyzed the fill level/frequency relationship with the Google Glass platform, control group 1 worked on the phenomenon using the same platform implemented on a tablet PC.
1	  Control group 2 analyzed the phenomenon using a tablet PC with a typical mobile-based education platform.
1	  We used a two-way ANCOVA to study learning outcome, wondering, curiosity, cognitive load, and experimentation time as dependent variables of 46 high-school eighth-graders together with group membership and gender influence as independent variables.
2	  While the positive effects of using Google Glass as a mobile lab on wondering and curiosity as well as a positive trend for experimentation time were detected, no differences were analyzed for learning achievement.
2     Although students have a higher cognitive load when working with Google Glass compared to other devices, the cognitive load level is very low in general.


### 117
##### doi: 10.1109/TLT.2016.262704
#### Can You Help Me with My Pitch? Studying a Tool for Real-Time Automated Feedback


0	  In our pursue to study effective real-time feedback in Technology Enhanced Learning, we developed the Presentation Trainer, a tool designed to support the practice of nonverbal communication skills for public speaking.
0	  The tool tracks the user's voice and body to analyze her performance, and selects the type of real-time feedback to be presented.
1	  This paper describes an empirical study where we tested the effects of the Presentation Trainer's feedback on learners who used the tool while practicing for an elevator-pitch.
2     Results from this study reveal that the feedback has a significant effect on the learners' motivation, confidence, self-awareness, and performance.


### 118
##### doi: 10.1109/TLT.2016.255667
#### Enhancing Physical Education with Exergames and Wearable Technology


0	  Increases in the numbers of obese and overweight children are a major issue in post-industrial societies because obesity can lead to severe health-related problems.
0	  In addition, many challenges affect the quantity and quality of physical education (PE) provided by schools.
0	  Exergames that combine exercise with gaming have been recognized as a possible method for motivating children to become physically active and to make PE more fun.
0     Furthermore, exergames that utilize wearable sensors devices allow players' movements to be tracked for estimating the efficiency of exercise.
1	  In this study, we developed the Running Othello 2 (RO2) exergame, where players wear a smartphone and a smart wrist band to compete in a board game enhanced with physical and pedagogical missions.
1	  In physical missions, the game uses inertial sensors and a heart rate meter to detect the physical activities of players.
1	  The pedagogical part of the game is based on the South Korean PE curriculum.
1	  We evaluated RO2 with 61 South Korean third grade elementary school students, 32 of whom learned curriculum topics by playing the game.
1	  The other 29 students comprised a control group who studied the pedagogical content using handouts.
2     The results indicated that learning with RO2 was more efficient, the players were engaged, and their heart rates increased.
2     Based on the evaluation, we identified several issues to be addressed in future research.
2	  Finally, we discussed how RO2 supports the educational affordances of wearables and we explained how exergames using wearables can overcome some of the challenges faced by PE.


### 119
##### doi: 10.1109/TLT.2016.260226
#### Representing and Reconciling Personal Data and Experience in a Wearable Technology Gaming Project


0	  Extant literature has largely not examined how users critically engage with their physical activity monitors, as objective data sense-making is often deemed superior to users' subjective realities.
0	  Our research, however, examines how middle-school youth encounter the representation of their data, as it is converted and actionable in an online game.
0     This ethnographic study illustrates how youth negotiate conflicts between their data and embodied experience.
1	  Using a grounded theory approach, our analysis of interviews and focus groups reveals emergent categories of resistance such as youth evaluating the incompatibility of the device, disputing the device's step-count accuracy and syncing, and disputing the game's conversion of steps.
1     In particular, we highlight the ways youth sometimes privileged their embodied recollections over the device's seemingly accurate data.
1     The article also provides a case of a day during implementation when youth converged on a single form of resistance, game conversion, and examines their reasoning and alternate forms of data validation that we saw in-action on that day.
2     Finally, we discuss benefits to learning and critical engagement that result from users' disputes and conclude by positing the promise in designing physical activity monitors for engagement, instead of exclusively persuasion or reward.


### 120
##### doi: 10.1109/TLT.2016.259714
#### Appropriating Quantified Self Technologies to Support Elementary Statistical Teaching and Learning


0	  Wearable activity tracking devices associated with the Quantified Self movement have potential benefit for educational settings because they produce authentic and granular data about activities and experiences already familiar to youth.
0	  This article explores how that potential could be realized through explicit acknowledgment of and response to tacit design assumptions about how such technologies will be used in practice and strategic design for use in a classroom.
0     We argue that particular practical adaptations that we have identified serve to ensure that the classroom and educational use cases are appropriately considered.
1	  As an example of how those adaptations are realized in actual elementary classrooms, we describe an effort to provide fifth-grade students each with their own Fitbit activity trackers in the context of a multi-week unit exploring core ideas in elementary statistics.
1	  Observational descriptions and transcript excerpts of students and teachers discussing their own Fitbit data are presented to illustrate what opportunities exist to leverage youth familiarity with daily activities in a way that targets development of statistical thinking.
2	  Quantitative written test results showing learning gains and differences between traditional and wearable device-enhanced instruction are also presented.
2     Improvement on several statistical thinking constructs is identified, including in the areas of data display, conceptions of statistics, modeling variability, and informal inference.


### 121
##### doi: 10.1109/TLT.2016.255733
#### Introducing IoT and Wearable Technologies into Task-Based Language Learning for Young Children


0	  In the last few years, in an attempt to further motivate students to learn a foreign language, there has been an increasing interest in task-based teaching techniques, which emphasize communication and the practical use of language, thus moving away from the repetitive grammar-translation methods.
0	  Within this approach, the significance of situating foreign language learners in scenarios where they can meaningfully learn has become a major priority for many educators.
0	  This approach is particularly relevant in the context of teaching foreign languages to young children, who need to be introduced to a new language by means of very concrete vocabulary, which is facilitated by the use of objects that they can handle and see.
1	  In this study, we investigate the benefits of using wearable and Internet-of-Things (IoT) technologies in streamlining the creation of such realistic task-based language learning scenarios.
2     We show that the use of these technologies will prove beneficial by freeing the instructors of having to keep records of the tasks performed by each student during the class session.
2     Instead, instructors can focus their efforts on creating a friendly environment and encouraging students to participate.
2     Our study sets up a basis for showing the great benefits of using wearable and IoT technologies in streamlining 1) the creation of realistic scenarios in which young foreign language learners can feel comfortable engaging in chat and becoming better prepared for social interaction in a foreign language, and 2) the acquisition and processing of performance metrics.


### 122
##### doi: 10.1109/TLT.2016.262756
#### Knowledge Construction in Computer Science and Engineering when Learning Through Making


0	  This paper focuses on a design based research study about STEM (Science, Technology, Engineering and Maths) learning by making through collaboration and production.
0	  This study examines learning by making by students to explore STEM using a constructionist approach with a particular focus on computer science and engineering.
0	  The use of IoT as a technology enhanced learning (TEL) tool created the learning conditions to be studied: (a) collaborative: no one person had the knowledge to complete the project alone, (b) problem-based: no off the shelf solution was used, and (c) multidisciplinary: the learning context pushed the boundaries across the subjects.
1	  The study investigated the learning conditions and indicators of collaboration and production taking place when learning about STEM.
1	  The results were used to inform the design of effective data analytics and visualization tools for the PELARS project to advance practice-based learning activities in STEM teaching.
1     However, more specifically, the findings provide insight into the knowledge construction process when learning through making in complex environments.
2     These insights illustrate the combined pedagogical value of collaboration and production supporting the multidisciplinary learning opportunities.
1	  The importance of community knowledge construction and its relationship to the pedagogical approach is examined.
2     The significance of these findings in the context of IoT TEL tools in education is explored.


### 123
##### doi: 10.1109/TLT.2016.259477
#### A Methodology to Obtain Learning Effective Laboratories with Learning Management System Integration


0	  Online laboratories are useful and valuable resources in high education, especially in engineering studies.
1	  This work presents a methodology to create effective laboratories for learning that interact with a Learning Management System (LMS) to achieve advanced integration.
1     It is based on pedagogical aspects and considers not only the laboratory application itself but also related resources that complement it.
1     The methodology is flexible, covers all possible cases, and it is structured in stages that can be used with any system architecture, standards, or type of online laboratory (virtual, remote, or hybrid) because it abstracts technical aspects at a high level.
2     This methodology facilitates the creation of new online labs so that any teacher, even those without specialized knowledge, can clarify many of the questions that may arise and gain understanding of how to implement an effective online laboratory with LMS integration to assist learning.
2	  As an example and validation of the methodology, this work describes a laboratory developed as a Shared Content Object Reference Model (SCORM) package which is hosted in the institutional LMS at the University of Jaen.
2	  The laboratory was presented to 338 students taking an Industrial Automation class, and student evaluations were quite positive.


### 124
##### doi: 10.1109/TLT.2016.255666
#### A Debate and Decision-Making Tool for Enhanced Learning


0	  Debates have been used to develop critical thinking within teaching environments.
0	  Many learning activities are configured as working groups, which use debates to make decisions.
0     Nevertheless, in a classroom debate, only a few students can participate; large work groups are similarly limited.
0     Whilst the use of web tools would appear to offer a convenient solution, none of those currently available provides an automated system for organizing contributions into a logical structure, or for making decisions.
1	  To address this problem, this paper describes a new tool for managing and structuring debates over the Internet, and presents the results of a series of trials in an educational context.
1	  The tool enables users to post opinions and proposals, and to make multiple group decisions.
2	  The main advantages are that it does not require a moderator, and all contributions are automatically arranged into an intuitive structure.
2     Thus, it enabled large groups to carry out bigger projects.
2     Empirical results showed that it also encouraged the involvement of all the students in debates and allowed the participation of each student to be evaluated.
2     The tool demonstrated its advantages over traditional oral debates and, as far as we are aware, it incorporates features not found in any other comparable web tool.


### 125
##### doi: 10.1109/TLT.2016.252164
#### Agent Supported Serious Game Environment


0	  This study proposes and applies a novel concept for an AI enhanced serious game collaborative environment as a supplementary learning tool in tertiary education.
0	  It is based on previous research that investigated pedagogical agents for a serious game in the OpenSim environment.
1	  The proposed AI features to support the serious game are the following: a) a pedagogical game agent, b) non-playing characters, c) chat bots, and d) a game interface called “Progress Map”.
0     This study aims to explore whether the utilization of AI features in game based collaborative learning in a tertiary education course can positively affect students' attitudes towards the course and educational games, students' game performance, as well as the students' perception of their learning environment.
2     Summarizing, even though the intelligent game environment does not affect students' attitudes, neither towards the course nor towards the educational games, it has a positive impact on the performance of the teams and so it can be considered useful in collaborative game based learning.
2     Moreover, the intelligent game environment improves the cohesiveness in the classroom after the completion of the game activity in terms of helping, supporting, and becoming connected to each-other.


### 126
##### doi: 10.1109/TLT.2016.251817
#### Analyzing the Impact of Using Optional Activities in Self-Regulated Learning


0	  Self-regulated learning (SRL) environments provide students with activities to improve their learning (e.g., by solving exercises), but they might also provide optional activities (e.g., changing an avatar image or setting goals) where students can decide whether they would like to use or do them and how.
0	  Few works have dealt with the use of optional activities in SRL environments.
1	  This paper thus analyzes the use of optional activities in two case studies with a SRL approach.
2     We found that the level of use of optional activites was low with only 23.1 percent of students making use of some functionality, while the level of use of learning activities was higher.
2     Optional activities which are not related to learning are used more.
2     We also explored the behavior of students using some of the optional activities in the courses such as setting goals and voting comments, finding that students finished the goals they set in more than 50 percent of the time and that they voted their peers' comments in a positive way.
2     We also found that gender and the type of course can influence which optional activities are used.
2     Moreover, the relations of the use of optional activities with proficient exercises and learning gains is low when taking out third variables, but we believe that optional activities might motivate students and produce better learning in an indirect way.


### 127
##### doi: 10.1109/TLT.2016.255666
#### BH-ShaDe: A Software Tool that Assists Architecture Students in the Ill-Structured Task of Housing Design


1	  In this paper, we present BH-ShaDe, a new software tool to assist architecture students learning the ill-structured domain/task of housing design.
0	  The software tool provides students with automatic or interactively generated floor plan schemas for basic houses.
0	  The students can then use the generated schemas as initial seeds to develop complete residential projects.
0	  The main goal of our research was to obtain evidence about whether or not such schemas can be useful to architecture students.
1	  A first prototype of the tool was evaluated with 78 students, with positive results.
2	  However, the students seemed to demand increased user participation, so they could contribute to generating better quality starting points.
1	  A second prototype was therefore implemented, allowing a higher degree of interactivity.
1	  The second prototype was evaluated with a new group of 50 students.
2     From the two evaluations performed, it can be concluded that both versions of the tool were able to generate useful starting points (either automatically or interactively) that expedited the design process.
2     Additionally, in the second experiment, we found that neither the nature (automatic or interactive) nor the quality of the starting point seems to have any effect on the perceived quality of the final projects.


### 128
##### doi: 10.1109/TLT.2016.252457
#### Designing a Secure Exam Management System (SEMS) for M-Learning Environments


0	  M-learning has enhanced the e-learning by making the learning process learner-centered.
0	  However, enforcing exam security in open environments where each student has his/her own mobile/tablet device connected to a Wi-Fi network through which it is further connected to the Internet can be one of the most challenging tasks.
0     In such environments, students can easily exchange information over the network during exam time.
1     This paper aims to identify various vulnerabilities that may violate exam security in m-learning environments and to design the appropriate security services and countermeasures that can be put in place to ensure exam security.
1	  It also aims to integrate the resulting secure exam system with an existing, open-source, and widely accepted Learning Management System (LMS) and its service extension to the m-learning environment, namely “the Moodbile Project”.


### 129
##### doi: 10.1109/TLT.2016.254166
#### Early Prediction of Student Profiles Based on Performance and Gaming Preferences


0	  State of the art research shows that gamified learning can be used to engage students and help them perform better.
0	  However, most studies use a one-size-fits-all approach to gamification, where individual differences and needs are ignored.
0	  In a previous study, we identified four types of students attending a gamified college course, characterized by different levels of performance, engagement and behavior.
1	  In this paper, we present a new experiment where we study what data best characterizes each of our student types and explore if this data can be used to predict a student's type early in the course.
1	  To this end, we used machine-learning algorithms to classify student data from one term and predict the students' type on another term.
1	  We identified two sets of relevant features that best describe our types, one containing only performance measurements and another also containing data regarding the students' gaming preferences.
2     Results show that performance alone can be used to predict student type with 79 percent accuracy by midterm.
2     However, its accuracy improves when paired with gaming data at earlier stages of the course.
2     In this paper, we clearly describe our findings and discuss the lessons learned from this experiment.


### 130
##### doi: 10.1109/TLT.2016.254625
#### Supporting Semantic Annotation of Educational Content by Automatic Extraction of Hierarchical Domain Relationships


0	  The domain model is an essential part of an adaptive learning system.
0	  For each educational course, it involves educational content and semantics, which is also viewed as a form of conceptual metadata about educational content.
0	  Due to the size of a domain model, manual domain model creation is a challenging and demanding task for teachers or content (and metadata) authors.
1     We propose a method for the automated acquisition of hierarchical relationships between relevant domain terms from educational content, which constitutes a fundamental step in the semantic composition of an educational course.
1	  The method is based on existing text mining methods and applied to educational content.
1	  We evaluate our approach by performing several experiments.
2     The evaluation shows that the method's performance is very promising.
2     A study in a real-user scenario reveals that despite the fact that utilization of our method does not necessarily improve the speed of the domain model creation nor does it reduce the overall difficulty of the task, a significant improvement in the quality of resulting domain models has been observed.
2     Our work is a promising contribution to the growing field of automated domain model acquisition.



### 132
##### doi: 10.1109/TLT.2015.247199
#### Novel Approach to Facilitating Tradeoff Multi-Objective Grouping Optimization


0	  The grouping problem is critical in collaborative learning (CL) because of the complexity and difficulty in adequate grouping, based on various grouping criteria and numerous learners.
0	  Previous studies have paid attention to certain research questions, and the consideration for a number of learner characteristics has arisen.
0     Such a multi-objective grouping problem is with conflicting grouping objectives, involving the benefit objective (e.g. learning achievement) and cost objective (e.g. class rank) which are conflicting in different directions.
1	  This study first proposed a novel approach based on the enhancement of a Genetic Algorithm (GA) with the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) for facilitating the tradeoff multi-objective grouping optimization, and based on the proposed approach further developed a web-based group support system to help educators for adequate grouping of homogeneous inter-group and heterogeneous intra-group.
1	  In addition, the distribution of learners in the class was considered for group formation.
1	  Two types of experiments were conducted; one involved a performance analysis against a GA and the Random approach, and the other entailed a study on CL with 90 participants.
2     The experimental results showed the following: 1) The proposed approach is not only more effective than a GA and the Random approach but also more efficient than a GA. 2) As a grouping strategy, the proposed approach can facilitate improved learning performance with statistical significance; in other words, the developed system is able to adequately allocate learners to teams for facilitating CL.


### 133
##### doi: 10.1109/TLT.2015.245691
#### Don't Be a Stranger-Designing a Digital Intercultural Sensitivity Training Tool that is Culture General


0	  Digital intercultural training tools play an important role in helping people to mediate cultural misunderstandings.
0	  In recent years, these tools were made to teach about specific cultures, but there has been little attention for the design of a tool to teach about differences across a wide range of cultures.
0	  In this work, we take the first steps to create a digital self-contained culture-general training tool.
1	  In the first part of the article, we focus on different aspects and methods of intercultural training.
1     This information is then used in the second part to evaluate the effect of these different methods on the perception of behaviour in misunderstandings.
2     We found that experiential and story-based approaches may lead to different perceptions of participants.
1	  In the third part, we expanded on these critical incidents, and incorporated virtual characters, to evaluate if experiential incidents in an embedded story can lead to an attribution of perceived differences in behaviour to specific differences in culture and to users becoming less judgemental of inappropriate behaviours by people from different cultures.
2     The results suggest that the tool had some effect, but that a debriefing relating the general differences to specific instances would be beneficial.


### 134
##### doi: 10.1109/TLT.2015.247068
#### VirTUal remoTe labORatories Management System (TUTORES): Using Cloud Computing to Acquire University Practical Skills


0	  The use of practical laboratories is a key in engineering education in order to provide our students with the resources needed to acquire practical skills.
0	  This is specially true in the case of distance education, where no physical interactions between lecturers and students take place, so virtual or remote laboratories must be used.
1     UNED has developed a system to create and manage virtual remote laboratories, aimed at improving the way how practical exercises are conducted.
1     This system is based on cloud computing and virtualization concepts.
1     These Virtual Remote Laboratories (VRLabs) combine features of traditional virtual and remote laboratories but with clear differences over them, among others, VRLabs do not necessarily access real physical devices but are not based on simulations either.
1     Each student is provided with a virtual remote laboratory based on virtualization that he/she will access through the Internet and will use to implement his/her practical assignments.
1	  We present details on how these laboratories are implemented for a subject in a post-degree program in our University.
2	  Furthermore, we also present an evaluation of the system used on such subject aiming at assessing the quality of the system regarding three different concepts, namely perceived usefulness, perceived ease of use, and perceived interaction.
2	  This evaluation is twofold, first, we have conducted a survey over the students of the subject, and second, we have performed another survey over the teaching team of the subject, both have been performed for the 2012-2013 and 2013-2014 academic years.


### 135
##### doi: 10.1109/TLT.2015.251000
#### An Investigation of a Two-Tier Test Strategy in a University Calculus Course: Causes versus Consequences


0	  Online tests have been identified as a core learning activity in higher education.
0	  Unlike conventional online tests, which cannot completely reflect students' learning status, two-tier tests not only consider students' answers, but also take into account reasons for their answers.
0     Due to such significance, research into the two-tier tests had mushroomed but few studies examined why the two-tier test approach was effective.
1	  To this end, we conducted an empirical study, where a lag sequential analysis was used to analyze behavior patterns while qualitative data from the questionnaire were applied to explain why these behavior patterns were happened.
2     The results indicated students with a two-tier test tended to realize the rationale of a concept, instead of relying on their memories.
2     In other words, the two-tier test can facilitate students to develop deep thinking skills.
2     This may be because they considered the two-tier test as a learning tool, instead of an assessment tool only.


### 136
##### doi: 10.1109/TLT.2015.247680
#### Item Response Theory for Peer Assessment


0	  As an assessment method based on a constructivist approach, peer assessment has become popular in recent years.
0	  However, in peer assessment, a problem remains that reliability depends on the rater characteristics.
0     For this reason, some item response models that incorporate rater parameters have been proposed.
0     Those models are expected to improve the reliability if the model parameters can be estimated accurately.
0     However, when applying them to actual peer assessment, the parameter estimation accuracy would be reduced for the following reasons.
0     1) The number of rater parameters increases with two or more times the number of raters because the models include higher-dimensional rater parameters.
0     2) The accuracy of parameter estimation from sparse peer assessment data depends strongly on hand-tuning parameters, called hyperparameters.
1     To solve these problems, this article presents a proposal of a new item response model for peer assessment that incorporates rater parameters to maintain as few rater parameters as possible.
1     Furthermore, this article presents a proposal of a parameter estimation method using a hierarchical Bayes model for the proposed model that can learn the hyperparameters from data.
2     Finally, this article describes the effectiveness of the proposed method using results obtained from a simulation and actual data experiments.


### 137
##### doi: 10.1109/TLT.2015.249067
#### Creating Engaging Online Learning Material with the JSAV JavaScript Algorithm Visualization Library


0	  Data Structures and Algorithms are a central part of Computer Science.
0	  Due to their abstract and dynamic nature, they are a difficult topic to learn for many students.
0	  To alleviate these learning difficulties, instructors have turned to algorithm visualizations (AV) and AV systems.
0     Research has shown that especially engaging AVs can have an impact on student learning of DSA topics.
0     Until recently, most AV systems were Java-based systems.
0     But, the popularity of Java has declined and is being supplanted by HTML5 and JavaScript content online.
1     In this paper, we present JSAV: the JavaScript AV development library.
1	  JSAV goes beyond traditional AV library support for displaying standard data structures components, to provide functionality to simplify creation of AVs on many engagement levels including interactive exercises.
2     We describe the growing body of content created with JSAV and summarize our three years of experience and research results from using JSAV to build content that supports CS education.


### 138
##### doi: 10.1109/TLT.2015.250496
#### ToothPIC: An Interactive Application for Teaching Oral Anatomy


0	  This paper describes the development and evaluation of an interactive educational program, ToothPlacement and Identification Coach (ToothPIC).
1	  The program uses a game-based learning paradigm and 3D visualization techniques to allow first year dentistry and hygiene students to get familiar with dental anatomy.
2     It provides an interactive and stimulating learning tool for acquiring basic dental skills outside of the classroom.
1	  Specifically, it uses interactive 3D graphics to teach students to identify, name, number, align, and orient teeth into their proper location in the dental arch.
1     ToothPIC incorporates elements of a game to make learning attractive for the student.
1     In the process, the student learns not only about the 3D features of each tooth but also about the proper placement of the tooth relative to the gingiva and other teeth.
1     ToothPIC has two modules: Module 1 includes 32 permanent upper and lower teeth that are to be identified and placed into the surrounding gingiva.
1     Module 2 only shows the individual teeth, one at a time, to be identified (similar to a “flash-card”).
2     The evaluation results of ToothPIC indicate that students strongly agree that program meets its goals of self-training and self-evaluation, actively involves the students in learning and is a useful supplement to laboratory practices and lectures.


### 139
##### doi: 10.1109/TLT.2015.245397
#### An Approach Based on Social Network Analysis Applied to a Collaborative Learning Experience


0	  The Social Network Analysis (SNA) techniques allow modelling and analysing the interaction among individuals based on their attributes and relationships.
0	  This approach has been used by several researchers in order to measure the social processes in collaborative learning experiences.
0     But oftentimes such measures were calculated at the final state of experiences, what may be hardly representative of students' behaviours during the learning processes.
0	  Therefore, a temporal dimension in SNA metrics may extend and improve the understanding about students' interactions in a collaborative scenario.
1	  In this respect, this paper presents a systematic review about SNA metrics used for analysing CSCL scenarios and proposes to trace the behaviour of such metrics during experiences through the inclusion of a temporal dimension.
1	  In order to expose this approach, a real collaborative learning experience, supported by a platform called SMLearning System, was analysed.
2     We found that social relationships among students tend to be symmetric, i.e., there was a proportional distribution of efforts and contributions of students, which is an expected condition in a collaborative scenario.
2     Such observations are based on the temporal behaviour of the reciprocity metric and the correlation between in- and out- degree centrality metrics measured in time.


### 140
##### doi: 10.1109/TLT.2016.253168
#### A Contextualized System for Supporting Active Learning


0	  The dynamics of the world today demands a change in traditional education paradigms to enable the creation of more efficient learning environments, where students will learn more effectively and will play a more active role in their education.
0	  They should interact with the knowledge at anytime-anywhere.
0	  In order to tackle this problem we should take advantage of mobile communication devices (e.g., smartphones and tablets) which are widely used by students and which have excellent processing storage and connectivity capabilities.
1	  In this research work, a context-aware system stimulating active learning by students was developed.
1	  This system places the student in an intelligent learning environment and is capable of delivering appropriate context-related learning contents, based on location, time, date, interaction of the student, profile of the student, and so on.
1     Within its architecture, the system includes reasoning capability that using context-based ontology is able to deliver efficient learning resources.
2     The experimental results obtained from various learning experiences in nursery, medicine, and systems engineering support the validity of our approach.


### 141
##### doi: 10.1109/TLT.2015.244809
#### Flipping the Flipped Classroom: A Study of the Effectiveness of Video Lectures Versus Constructivist Exploration Using Tangible User Interfaces


0	  In this study, we show results that suggest tangible user interfaces (TUIs) may be used to prepare students for future learning.
0     In a previous study, we found that students who used interactive tabletops before studying a text significantly outperformed participants who read a text first and used tabletops subsequently.
0     These findings demonstrate that discovery-learning approaches are better suited to TUIs than traditional “tell-and-practice” approaches.
0	  In our current effort, we generalize our findings to a different population, a different learning material, and a different topic.
1	  In this study, we employ the tangible interface, Combinatorix (Fig.1), which enables small groups of students to work collaboratively and discover concepts in probability.
1	  Our system supports students' explorations of principles in combinatorics (i.e., permutations and combinations) that serve as foundations for learning about probability.
1	  We describe the design of Combinatorix, as well as an experiment that examined the interaction between focused lectures and free exploration.
2	  We found that students who first explored the topic on a tangible interface and then watched a video lecture significantly outperformed students who watched a lecture first and then completed a hands-on activity.
2     We discuss how the “functional fixedness” induced by the video lecture limited the students' learning of probability, and conclude with guidelines for implementing interactive tabletops in classrooms.


### 142
##### doi: 10.1109/TLT.2015.241925
#### Virtual Engineering Sciences Learning Lab: Giving STEM Education a Second Life


0	  Engineering education in the 21st century faces multiple obstacles including limited accessibility of course resources due, in part, to the costs associated with acquiring and maintaining equipment and staffing laboratories.
0	  Another continuing challenge is the low level of participation of women and other groups historically underrepresented in STEM disciplines.
1	  As a partial remedy for these issues, we established a Virtual Engineering Sciences Learning Lab (VESLL) that provides interactive objects and learning activities, multimedia displays, and instant feedback procedures in a virtual environment to guide students through a series of key quantitative skills and concepts.
1     Developed in the online virtual world Second Life™, VESLL is an interactive environment that supports STEM education, with potential to help reach women and other underrepresented groups.
1	  VESLL exposes students to various quantitative skills and concepts through visualization, collaborative games, and problem solving with realistic learning activities.
2     Initial assessments have demonstrated high student interest in VESLL's potential as a supplementary instructional tool and show that student learning experiences were improved by use of VESLL.
2     Ultimately, the VESLL project contributes to the ongoing body of evidence suggesting that online delivery of course content has remarkable potential when properly deployed by STEM educators.


### 143
##### doi: 10.1109/TLT.2015.243886
#### Low Cost Ubiquitous Context-Aware Wireless Communications Laboratory for Undergraduate Students


0	  Wireless Communication technologies are in continuous evolution.
0	  Around the world, many Universities try to provide innovative laboratory courses to train their students in this field.
1	  In this paper, a ubiquitous laboratory course for wireless communications is described.
1	  The laboratory course has been designed so that the students have to complete six different experiments.
1	  Three of these experiments have been designed to use advanced professional network testing tools in order to provide practical experience in simulation tools.
1     Two additional experiments have been implemented in order to provide hands-on measurements through the student's mobile device.
2     This is a novelty and provides the students with an example of ubiquitous learning.
1	  Finally, in the last experiment, the students manufacture a WiFi antenna.
1	  The laboratory has been designed so that the students develop different practical skills in each experiment.
2     This laboratory course facilitates applied learning and the consolidation of theoretical concepts.


### 144
##### doi: 10.1109/TLT.2015.243968
#### Development and Evaluation of an Active Learning Support System for Context-Aware Ubiquitous Learning


0	  Situating students to learn from the real world has been recognized as an important and challenging issue.
0	  However, in a real-world learning environment, there are usually many physical constraints that affect the learning performance of students, such as the total learning time, the limitation of the number of students who can visit a learning target, and the time needed for moving from one learning location to another.
0     It is essential to guide the students along an efficient learning path to maximize their learning performance according to the current situation.
1     In this paper, an active learning support system (ALESS) for context-aware ubiquitous learning environments is designed and developed.
2     ALESS can provide learning guidance when conducting ubiquitous learning activities.
1     A great deal of context information is used in ALESS, including the location, the current capacity of the learning object, the time available, etc.
2     ALESS is able to actively provide the required learning support to individual students when they approach the corresponding real-world learning targets.
1	  To evaluate the performance of ALESS, an experiment was conducted in the National Science Museum of Taiwan.
2     The experimental results showed that, with the help of ALESS, the students learned more efficiently, and achieved better learning performance.


### 145
##### doi: 10.1109/TLT.2015.244576
#### Support for Augmented Reality Simulation Systems: The Effects of Scaffolding on Learning Outcomes and Behavior Patterns


0	  An AR-based simulation system that integrates background knowledge and experimental support (AR-SaBEr) was designed as a learning tool for teaching basic principles of electricity to ninth-grade students.
0	  The aim of this study was to investigate how supporting the learner focus on meaningful activities affects behavior and learning performance.
1	  The sample was 82 students, who were randomly assigned to two groups.
1	  The control group used AR-SaBEr with no support for recommending activities.
1	  The experimental group had personalized extra support designed to help learners focus on the subject matters that they did not master.
2     The study found that learners from the experimental group showed better learning achievements than those who participated in the control group.
2     Furthermore, learners' behavioral patterns were dependent upon the support received.
2     Learners from the control group were more willing to browse information about activities than to read about the subject before experimenting.
2     Learners from the experimental group browsed information about prior to carrying them out and read about the subject matter prior to experimentation.
2     The observed behavioral patterns and learning achievements suggest that in augmented reality based simulation environments, it is worth providing mechanisms to focus the attention of students on the most relevant topics for them.


### 146
##### doi: 10.1109/TLT.2015.244437
#### Investigating Engagement with In-Video Quiz Questions in a Programming Course


0	  In-video quizzes are common in many distance learning platforms, including those from Coursera and EdX.
0	  However, the effectiveness of in-video quizzes has not previously been assessed.
1	  In this paper, we describe the construction and instrumentation of an Interactive Video Lecture Platform to measure student engagement with in-video quizzes.
1	  We also investigate the use of in-video quizzes as an approach to mitigate the lack of feedback available to students and lecturers in videos and traditional lectures.
1	  Finally, we evaluate the effectiveness of augmenting video with the ability to answer and receive feedback to quiz questions embedded directly within the video.
2     We observed that student engagement with in-video questions was consistently high (71-86 percent) across two cohorts ($N_1$= 81,$N_2$= 84) with a rate of one question per 8.7 minutes of video.
2     We identified three broad levels of engagement with the quiz questions and four motivations, including challenge seeking and completionism, which explain some of the observed behaviour.
2     The results from this investigation demonstrate that in-video quizzes were successful in creating an engaging and interactive mode of content delivery.
2     We recommend that in-video quizzes be used to increase the interactivity of video content as well as supporting formative assessment within a flipped classroom environment.


### 147
##### doi: 10.1109/TLT.2015.243482
#### Learning Object Recommendations for Teachers Based On Elicited ICT Competence Profiles


0	  Recommender systems (RS) offer personalized services for facilitating the process of appropriate item selection.
0	  To perform this task, user profiling mechanisms should be implemented to automatically construct and update meaningful user profiles.
0     These profiles can drive the RS in providing informed recommendations suited to the unique characteristics of each user.
0     In the context of technology enhanced learning (TeL) Recommender Systems, the majority of research focus directly on learners' profiling and ignore the potential benefits of profiling teachers' professional capacities too.
0	  As a result, limited previous works exist on effectively capturing and utilizing individual teachers' particular professional characteristics, such as their Digital Competences (commonly referred to as ICT Competences) and exploiting these in systems that support their teaching preparation and practice, for example in the selection of appropriate educational resources.
1	  This paper proposes a RS which targets to support teachers in selecting learning objects (LO) from existing LO repositories (LORs) in a unified manner, namely by (a) automatically constructing their ICT Competence Profiles based on their actions within these LORs and (b) exploiting these profiles for more efficient LO selection.
2     Experiments with data from three real-life LORs are presented and evaluation results are discussed to demonstrate the benefits of the proposed system.


### 148
##### doi: 10.1109/TLT.2015.243280
#### Reducing Mistakes in Mathematics Problem Solving through Behavioral Training with a Tablet Computer


0	  This paper proposes a mathematics learning system intended to reduce mistakes in problem solving through behavioral training using a tablet computer.
1	  We focused on the case where students' errors were not due to a lack of knowledge but to a simple mistake.
1     Specifically, we consider the context of traditional assessment methods that feature do-it-again feedback that can focus on the simple mistake, as opposed to conceptual knowledge or logic.
1     The proposed scheme aims to identify and visualize measurable features of behavior that leads to mistakes among students engaged in problem-solving activities.
1	  As a pilot study, we placed students in one of two groups: high-scoring and average-scoring students on a national standardized mathematics test in the Republic of Korea.
1	  Then, using a tablet computer, we collected information on the handwriting and navigation behavior of students during problem solving with millisecond precision and determined its meaningful features.
1	  During the experiments, 15 of the 45 participants were trained on certain features of problem-solving behavior, identified in the pilot study.
1     Three problem-solving assessments were performed, and two training sessions were provided.
2     The results showed that students who trained in problem-solving behaviors achieved an improvement of approximately 14 percent, without additional knowledge training.


### 149
##### doi: 10.1109/TLT.2015.243886
#### Evaluating Recommender Systems for Technology Enhanced Learning: A Quantitative Survey


0	  The increasing number of publications on recommender systems for Technology Enhanced Learning (TEL) evidence a growing interest in their development and deployment.
0	  In order to support learning, recommender systems for TEL need to consider specific requirements, which differ from the requirements for recommender systems in other domains like e-commerce.
0     Consequently, these particular requirements motivate the incorporation of specific goals and methods in the evaluation process for TEL recommender systems.
1	  In this article, the diverse evaluation methods that have been applied to evaluate TEL recommender systems are investigated.
1	  A total of 235 articles are selected from major conferences, workshops, journals, and books where relevant work have been published between 2000 and 2014.
1	  These articles are quantitatively analysed and classified according to the following criteria: type of evaluation methodology, subject of evaluation, and effects measured by the evaluation.
2     Results from the survey suggest that there is a growing awareness in the research community of the necessity for more elaborate evaluations.
2     At the same time, there is still substantial potential for further improvements.
2     This survey highlights trends and discusses strengths and shortcomings of the evaluation of TEL recommender systems thus far, thereby aiming to stimulate researchers to contemplate novel evaluation approaches.


### 150
##### doi: 10.1109/TLT.2015.241926
#### A Hybrid Trust-Based Recommender System for Online Communities of Practice


0	  The needs for life-long learning and the rapid development of information technologies promote the development of various types of online Community of Practices (CoPs).
0	  In online CoPs, bounded rationality and metacognition are two major issues, especially when learners face information overload and there is no knowledge authority within the learning environment.
1	  This study proposes a hybrid, trust-based recommender system to mitigate above learning issues in online CoPs.
1	  A case study was conducted using Stack Overflow data to test the recommender system.
2     Important findings include: (1) comparing with other social community platforms, learners in online CoPs have stronger social relations and tend to interact with a smaller group of people only; (2) the hybrid algorithm can provide more accurate recommendations than celebrity-based and content-based algorithm and; (3) the proposed recommender system can facilitate the formation of personalized learning communities.


###151
#####doi: 10.1109/TLT.2015.238921
#### Characterizing Learning Mediated by Mobile Technologies: A Cultural-Historical Activity Theoretical Analysis


0 	Mobile technologies have not yet triggered the knowledge revolution in schools anticipated, in particular, by the telecommunications industry.
0 	On the contrary, mobile technologies remain extensively used outside the frontiers of formal education.
0 	The reasons for this are many and varied.
0 	In this paper, we concentrate on those associated with the prevalent methodological weakness in the study of innovative educational interventions with mobile technologies.
1 	In this context, the paper investigates the following question: what is the potential of second-generation cultural-historical activity theory (CHAT) for characterizing learning activities mediated by mobile technologies?
1 	To this end, an empirical study was designed with the goal of examining five small groups of students (fifth grade, age 12) who were using mobile devices in authentic educational settings, within a natural science inquiry-based learning activity outdoors.
1 	Second-generation CHAT was operationalized as an analytical and dialectic methodological framework for understanding learning activities mediated by mobile devices.
2 	The study contributes a characterization of mobile learning and identification of constraints and transformations introduced by mobile technology into students' tasks.



### 41
##### 10.1109/TPAMI.2019.2941941
#### MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement


0	  Motion estimation (ME) and motion compensation (MC) have been widely used for classical video frame interpolation systems over the past decades.
0	  Recently, a number of data-driven frame interpolation methods based on convolutional neural networks have been proposed.
0	  However, existing learning based methods typically estimate either flow or compensation kernels, thereby limiting performance on both computational efficiency and interpolation accuracy.
1	  In this work, we propose a motion estimation and compensation driven neural network for video frame interpolation.
1	  A novel adaptive warping layer is developed to integrate both optical flow and interpolation kernels to synthesize target frame pixels.
1	  This layer is fully differentiable such that both the flow and kernel estimation networks can be optimized jointly.
1	  The proposed model benefits from the advantages of motion estimation and compensation methods without using hand-crafted features.
2	  Compared to existing methods, our approach is computationally efficient and able to generate more visually appealing results.
2	  Furthermore, the proposed MEMC-Net can be seamlessly adapted to several video enhancement tasks, e.g., super-resolution, denoising, and deblocking.
2	  Extensive quantitative and qualitative evaluations demonstrate that the proposed method performs favorably against the state-of-the-art video frame interpolation and enhancement algorithms on a wide range of datasets.


### 42
##### 10.1109/TPAMI.2019.2942028
#### Harmonized Multimodal Learning with Gaussian Process Latent Variable Models


0	  Multimodal learning aims to discover the relationship between multiple modalities.
0	  It has become an important research topic due to extensive multimodal applications such as cross-modal retrieval.
1	  This paper attempts to address the modality heterogeneity problem based on Gaussian process latent variable models (GPLVMs) to represent multimodal data in a common space.
0	  Previous multimodal GPLVM extensions generally adopt individual learning schemes on latent representations and kernel hyperparameters, which ignore their intrinsic relationship.
1	  To exploit strong complementarity among different modalities and GPLVM components, we develop a novel learning scheme called Harmonization, where latent model parameters are jointly learned from each other.
1	  Beyond the correlation fitting or intra-modal structure preservation paradigms widely used in existing studies, the harmonization is derived in a model-driven manner to encourage the agreement between modality-specific GP kernels and the similarity of latent representations.
1	  We present a range of multimodal learning models by incorporating the harmonization mechanism into several representative GPLVM-based approaches.
2	  Experimental results on four benchmark datasets show that the proposed models outperform the strong baselines for cross-modal retrieval tasks, and that the harmonized multimodal learning method is superior in discovering semantically consistent latent representation.


### 43
##### 10.1109/TPAMI.2019.2942030
#### Hierarchical Long Short-Term Concurrent Memory for Human Interaction Recognition


0	  In this work, we aim to address the problem of human interaction recognition in videos by exploring the long-term inter-related dynamics among multiple persons.
0	  Recently, Long Short-Term Memory (LSTM) has become a popular choice to model individual dynamic for single-person action recognition due to its ability to capture the temporal motion information in a range.
0	  However, most existing LSTM-based methods focus only on capturing the dynamics of human interaction by simply combining all dynamics of individuals or modeling them as a whole.
0	  Such methods neglect the inter-related dynamics of how human interactions change over time.
1	  To this end, we propose a novel Hierarchical Long Short-Term Concurrent Memory (H-LSTCM) to model the long-term inter-related dynamics among a group of persons for recognizing human interactions.
1	  Specifically, we first feed each person's static features into a Single-Person LSTM to model the single-person dynamic.
1	  Subsequently, at one time step, the outputs of all Single-Person LSTM units are fed into a novel Concurrent LSTM (Co-LSTM) unit, which mainly consists of multiple sub-memory units, a new cell gate, and a new co-memory cell.
1	  In the Co-LSTM unit, each sub-memory unit stores individual motion information, while this Co-LSTM unit selectively integrates and stores inter-related motion information between multiple interacting persons from multiple sub-memory units via the cell gate and co-memory cell, respectively.
2	  Extensive experiments on several public datasets validate the effectiveness of the proposed H-LSTCM by comparing against baseline and state-of-the-art methods.


### 44
##### 10.1109/TPAMI.2019.2941876
#### Are Large-Scale 3D Models Really Necessary for Accurate Visual Localization?


0	  Accurate visual localization is a key technology for autonomous navigation.
0	  3D structure-based methods employ 3D models of the scene to estimate the full 6 degree-of-freedom (DOF) pose of a camera very accurately.
0	  However, constructing (and extending) large-scale 3D models is still a significant challenge.
0	  In contrast, 2D image retrieval-based methods only require a database of geo-tagged images, which is trivial to construct and to maintain.
0	  They are often considered inaccurate since they only approximate the positions of the cameras.
0	  Yet, the exact camera pose can theoretically be recovered when enough relevant database images are retrieved.
1	  In this paper, we demonstrate experimentally that large-scale 3D models are not strictly necessary for accurate visual localization.
1	  We create reference poses for a large and challenging urban dataset.
2	  Using these poses, we show that combining image-based methods with local reconstructions results in a pose accuracy similar to the state-of-the-art structure-based methods.
2	  Our results suggest that we might want to reconsider the current approach for accurate large-scale localization.


### 45
##### 10.1109/TPAMI.2019.2941472
#### Surface-aware Blind Image Deblurring


0	  Blind image deblurring is a conundrum because there are infinitely many pairs of latent images and blur kernels.
0	  To get a stable and reasonable deblurred image, proper prior knowledge of the latent image and the blur kernel is required.
1	  Different from recent works on the statistical observations of the difference between the blurred image and the clean one, our method is based on the surface-aware strategy from the intrinsic geometrical consideration.
1	  This approach facilitates the blur kernel estimation due to the preserved sharp edges in the intermediate latent images.
2	  Extensive experiments demonstrate that our method outperforms state-of-the-art methods on deblurring the text and natural image.
2	  Moreover, our method can achieve attractive results in some challenging cases, such as low-illumination images with large saturated regions and impulse noise.
2	  A direct extension of our method to the non-uniform deblurring problem also validates the effectiveness of the surface-aware prior.


### 46
##### 10.1109/TPAMI.2019.2941684
#### Loss Decomposition and Centroid Estimation for Positive and Unlabeled Learning


1	  This paper studies Positive and Unlabeled learning (PU learning), of which the target is to build a binary classifier where only positive data and unlabeled data are available for classifier training.
1	  To deal with the absence of negative training data, we first regard all unlabeled data as negative examples with false negative labels, and then convert PU learning into the risk minimization problem in the presence of such one-side label noise.
1	  Specifically, we propose a novel PU learning algorithm dubbed "Loss Decomposition and Centroid Estimation" (LDCE).
1	  By decomposing the loss function of corrupted negative examples into two parts, we show that only the second part is affected by the noisy labels.
1	  Thereby, we may estimate the centroid of corrupted negative set via an unbiased way to reduce the adverse impact of such label noise.
1	  Furthermore, we propose the "Kernelized LDCE" (KLDCE) by introducing the kernel trick, and show that KLDCE can be easily solved by combining Alternative Convex Search (ACS) and Sequential Minimal Optimization (SMO).
2	  Theoretically, we derive the generalization error bound which suggests that the generalization risk of our model converges to the empirical risk with the order of $\mathcal{O}(1/ \sqrt k + 1 /{\sqrt {n-k}} + 1/ \sqrt n)$ ($n$ and $k$ are the amounts of training data and positive data correspondingly).
2	  Experimentally, we conduct intensive experiments on synthetic dataset, UCI benchmark datasets and real-world datasets, and the results demonstrate that our approaches (LDCE and KLDCE) achieve the top-level performance when compared with both classic and state-of-the-art PU learning methods.


### 47
##### 10.1109/TPAMI.2019.2939530
#### Bound and Conquer: Improving Triangulation by Enforcing Consistency


0	  We study the accuracy of triangulation in multi-camera systems with respect to the number of cameras.
2	  We show that, under certain conditions, the optimal achievable reconstruction error decays quadratically as more cameras are added to the system.
1	  Furthermore, we analyse the error decay-rate of major state-of-the-art algorithms with respect to the number of cameras.
1	  To this end, we introduce the notion of consistency for triangulation, and show that consistent reconstruction algorithms achieve the optimal quadratic decay, which is asymptotically faster than some other methods.
2	  Finally, we present simulations results supporting our findings.
#	  Our simulations have been implemented in MATLAB and the resulting code is available in the supplementary material.


### 48
##### 10.1109/TPAMI.2019.2940948
#### Unsupervised Domain Adaptation for Depth Prediction from Images


0	  State-of-the-art methods to infer dense and accurate depth measurements from images rely on deep CNN models trained in an end-to-end fashion on a significant amount of data.
0	  However, despite the outstanding performance achieved, these frameworks suffer a drastic drop in accuracy when dealing with unseen environments much different, concerning appearance (e.g., synthetic vs. real) or context (e.g., indoor vs. outdoor), from those observed during the training phase.
0	  Such domain shift issue is usually softened by fine-tuning on smaller sets of images with depth labels acquired in the target domain with active sensors (e.g., LiDAR).
0	  However, relying on such supervised labeled data is seldom feasible in practical applications.
1	  Therefore, we propose an effective unsupervised domain adaptation technique enabling to overcome the domain shift problem without requiring any groundtruth label.
2	  Our method, deploying much more accessible to obtain stereo pairs, leverages traditional and not learning-based stereo algorithms to produce disparity/depth labels and on confidence measures to assess their degree of reliability.
2	  With these cues, we can fine-tune deep models through a novel confidence-guided loss function, neglecting the effect of outliers gathered from the output of conventional stereo algorithms.


### 49
##### 10.1109/TPAMI.2019.2940225
#### Sequence-to-Segments Networks for Detecting Segments in Videos


0	  Detecting segments of interest from videos is a common problem for many applications.
0	  And yet it is a challenging problem as it often requires not only knowledge of individual target segments, but also contextual understanding of the entire video and the relationships between the target segments.
1	  To address this problem, we propose the Sequence-to-Segments Network (S2N), a novel and general end-to-end sequential encoder-decoder architecture.
1	  S2N first encodes the input video into a sequence of hidden states that capture information progressively, as it appears in the video.
1	  It then employs the Segment Detection Unit (SDU), a novel decoding architecture, that sequentially detects segments.
1	  At each decoding step, the SDU integrates the decoder state and encoder hidden states to detect a target segment.
1	  During training, we address the problem of finding the best assignment of predicted segments to ground truth using the Hungarian Matching Algorithm with Lexicographic Cost.
1	  Additionally, we propose to use the squared Earth Mover's Distance to optimize the localization errors of the segments.
2	  We show the state-of-the-art performance of S2N across numerous tasks, including video highlighting, video summarization, and human action proposal generation.


### 50
##### 10.1109/TPAMI.2019.2940655
#### Topology-Aware Non-Rigid Point Cloud Registration


1	  In this paper, we introduce a non-rigid registration pipeline for unorganized point clouds that may be topologically different.
1	  Standard warp field estimation algorithms, even under robust, discontinuity-preserving regularization, produce erratic motion estimates on boundaries associated with ‘close-to-open’ topology changes.
1	  We overcome this limitation by exploiting backward motion: in the opposite direction, a ‘close-to-open’ event becomes ‘open-to-close’, which is by default handled correctly.
1	  Our approach relies on a general, topology-agnostic warp field estimation algorithm, similar to those employed in recent dynamic reconstruction systems from RGB-D input.
1	  We improve motion estimation on boundaries associated with topology changes in an efficient post-processing phase.
1	  Based on both forward and (inverted) backward warp hypotheses, we explicitly detect regions of the deformed geometry that undergo topological changes by means of local deformation criteria and broadly classify them as ‘contacts’ or ‘separations’.
1	  Subsequently, the two motion hypotheses are seamlessly blended on a local basis, according to the type and proximity of detected events.
2	  Our method achieves state-of-the-art motion estimation accuracy on the MPI Sintel dataset.
2	  Experiments on a custom dataset with topological event annotations demonstrate the effectiveness of our pipeline in estimating motion on event boundaries, as well as promising performance in explicit topological event detection.


### 51
##### 10.1109/TPAMI.2019.2940446
#### MTFH: A Matrix Tri-Factorization Hashing Framework for Efficient Cross-Modal Retrieval


0	  Hashing has recently sparked a great revolution in cross-modal retrieval because of its low storage cost and high query speed.
0	  Recent cross-modal hashing methods often learn unified or equal-length hash codes to represent the multi-modal data and make them intuitively comparable.
0	  However, such representations could inherently sacrifice their representation scalability because the data from different modalities may not have one-to-one correspondence and could be encoded more efficiently by different hash codes of unequal lengths.
1	  To mitigate these problems, this paper exploits a related and relatively unexplored problem: encode the heterogeneous data with varying hash lengths and generalize the cross-modal retrieval in various challenging scenarios.
1	  To this end, a generalized and flexible cross-modal hashing framework, termed Matrix Tri-Factorization Hashing (MTFH), is proposed to work seamlessly in various settings including paired or unpaired multi-modal data, and equal or varying hash length encoding scenarios.
1	  MTFH exploits an efficient objective function to flexibly learn modality-specific hash codes with different length settings, while synchronously learning two semantic correlation matrices for heterogeneous data comparable.
2	  As a result, the derived hash codes are more semantically meaningful for various challenging cross-modal retrieval tasks.
2	  Extensive experiments evaluated on public benchmark datasets highlight the superiority of MTFH under various retrieval scenarios and show its competitive performance with the state-of-the-arts.


### 52
##### 10.1109/TPAMI.2019.2938523
#### Learning Part-based Convolutional Features for Person Re-identification


0	  Part-level features offers fine granularity for pedestrian image description.
0	  In this article, we generally aim to learn discriminative part-informed features for person re-identification.
1	  First, we introduce a general part-level feature learning method, named Part-based Convolutional Baseline (PCB).
1	  Given an image, it outputs a convolutional descriptor consisting of several part-level features.
1	  PCB is general in that it is able to accommodate several part partitioning strategies.
2	  In experiment, we show that the learned descriptor maintains a significantly higher discriminative ability than the global descriptor.
1	  Second, Based on PCB, we propose refined part pooling (RPP) to improve the original partition.
1	  Our idea is that pixels within a well-located part should be similar to each other while being dissimilar with pixels from other parts.
1	  We call it within-part consistency.
1	  When a pixel-wise feature vector in a part is more similar to some other part, it is then an outlier, indicating inappropriate partitioning.
1	  RPP re-assigns these outliers to the parts they are closest to, resulting in refined parts with enhanced within-part consistency.
2	  Experiment confirms that RPP gains another round of performance boost over PCB.
2	  For instance, on the Market-1501 dataset, we achieve (77.4+4.2)% mAP and (92.3+1.5)% rank-1 accuracy, a competitive performance with the state of the art.


### 53
##### 10.1109/TPAMI.2019.2939237
#### On the Global Geometry of Sphere-Constrained Sparse Blind Deconvolution


0	  Blind deconvolution is the problem of recovering a convolutional kernel $a_0$ and an activation signal $x_0$ from their convolution $y = a_{0} ❂ x_{0}$.
0	  This problem is ill-posed without further constraints or priors.
1	  This paper studies the situation where the nonzero entries in the activation signal are sparsely and randomly populated.
1	  We normalize the convolution kernel to have unit Frobenius norm and cast the sparse blind deconvolution problem as a nonconvex optimization problem over the sphere.
1	  With this spherical constraint, every spurious local minimum turns out to be close to some signed shift truncation of the ground truth, under certain hypotheses.
1	  This benign property motivates an effective two stage algorithm that recovers the ground truth from the partial information offered by a suboptimal local minimum.
2	  This geometry-inspired algorithm recovers the ground truth for certain microscopy problems, also exhibits promising performance in the more challenging image deblurring problem.
2	  Our insights into the global geometry and the two stage algorithm extend to the convolutional dictionary learning problem, where a superposition of multiple convolution signals is observed.


### 54
##### 10.1109/TPAMI.2019.2939307
#### Deterministic Approximate Methods for Maximum Consensus Robust Fitting


0	  Maximum consensus estimation plays a critically important role in robust fitting problems in computer vision.
0	  Currently, the most prevalent algorithms for consensus maximization draw from the class of randomized hypothesize-and-verify algorithms, which are cheap but can usually deliver only rough approximate solutions.
0	  On the other extreme, there are exact algorithms which are exhaustive search in nature and can be costly for practical-sized inputs.
1	  This paper fills the gap between the two extremes by proposing deterministic algorithms to approximately optimize the maximum consensus criterion.
1	  Our work begins by reformulating consensus maximization with linear complementarity constraints.
1	  Then, we develop two novel algorithms: one based on non-smooth penalty method with a Frank-Wolfe style optimization scheme, the other based on the Alternating Direction Method of Multipliers (ADMM).
1	  Both algorithms solve convex subproblems to efficiently perform the optimization.
1	  We demonstrate the capability of our algorithms to greatly improve a rough initial estimate, such as those obtained using least squares or a randomized algorithm.
2	  Compared to the exact algorithms, our approach is much more practical on realistic input sizes.
2	  Further, our approach is naturally applicable to estimation problems with geometric residuals.
#	  Matlab code and demo program for our methods can be downloaded from https://goo.gl/FQcxpi.


### 55
##### 10.1109/TPAMI.2019.2938758
#### Res2Net: A New Multi-scale Backbone Architecture


0	  Representing features at multiple scales is of great importance for numerous vision tasks.
0	  Recent advances in backbone convolutional neural networks (CNNs) continually demonstrate stronger multi-scale representation ability, leading to consistent performance gains on a wide range of applications.
0	  However, most existing methods represent the multi-scale features in a layer-wise manner.
1	  In this paper, we propose a novel building block for CNNs, namely Res2Net, by constructing hierarchical residual-like connections within one single residual block.
1	  The Res2Net represents multi-scale features at a granular level and increases the range of receptive fields for each network layer.
1	  The proposed Res2Net block can be plugged into the state-of-the-art backbone CNN models, e.g., ResNet, ResNeXt, and DLA.
2	  We evaluate the Res2Net block on all these models and demonstrate consistent performance gains over baseline models on widely-used datasets, e.g., CIFAR-100 and ImageNet.
2	  Further ablation studies and experimental results on representative computer vision tasks, i.e., object detection, class activation mapping, and salient object detection, further verify the superiority of the Res2Net over the state-of-the-art baseline methods.
#	  The source code and trained models are available on https://mmcheng.net/res2net/.


### 56
##### 10.1109/TPAMI.2019.2937869
#### Matrix Completion with Deterministic Sampling: Theories and Methods


0	  In some significant applications such as data forecasting, the locations of missing entries cannot obey any non-degenerate distributions, questioning the validity of the prevalent assumption that the missing data is randomly chosen according to some probabilistic model.
1	  To break through the limits of random sampling, we explore in this paper the problem of real-valued matrix completion under the setup of deterministic sampling.
1	  We propose two conditions, isomeric condition and relative well-conditionedness, for guaranteeing an arbitrary matrix to be recoverable from a sampling of the matrix entries.
2	  It is provable that the proposed conditions are weaker than the assumption of uniform sampling and, most importantly, it is also provable that the isomeric condition is necessary for the completions of any partial matrices to be identifiable.
2	  Equipped with these new tools, we prove a collection of theorems for missing data recovery as well as convex/nonconvex matrix completion.
2	  Among other things, we study in detail a Schatten quasi-norm induced method termed isomeric dictionary pursuit (IsoDP), and we show that IsoDP exhibits some distinct behaviors absent in the traditional bilinear programs.


### 57
##### 10.1109/TPAMI.2019.2937294
#### Deep Differentiable Random Forests for Age Estimation


0	  Age estimation from facial images is typically cast as a label distribution learning or regression problem, since aging is a gradual progress.
0	  Its main challenge is the facial feature space w.r.t. ages is inhomogeneous, due to the large variation in facial appearance across different persons of the same age and the non-stationary property of aging.
1	  In this paper, we propose two Deep Differentiable Random Forests methods, Deep Label Distribution Learning Forest (DLDLF) and Deep Regression Forest (DRF), for age estimation.
1	  Both of them connect split nodes to the top layer of convolutional neural networks (CNNs) and deal with inhomogeneous data by jointly learning input-dependent data partitions at the split nodes and age distributions at the leaf nodes.
1	  This joint learning follows an alternating strategy: (1) Fixing the leaf nodes and optimizing the split nodes and the CNN parameters by Back-propagation; (2) Fixing the split nodes and optimizing the leaf nodes by Variational Bounding.
2	  Two Deterministic Annealing processes are introduced into the learning of the split and leaf nodes, respectively, to avoid poor local optima and obtain better estimates of tree parameters free of initial values.
2	  Experimental results show that DLDLF and DRF achieve state-of-the-art results on three age estimation datasets.


### 58
##### 10.1109/TPAMI.2019.2937515
#### Reconstruction Geometric and Optical Parameters of Non-Planar Objects with Thin Film


0	  Here, we propose a novel method to estimate the parameters of non-planar objects with thin film surfaces.
0	  Being able to estimate the optical parameters of objects with thin film surfaces has a wide range of applications from industrial inspections to biological and archaeology research.
0	  However, there are many challenging issues that need to be overcome to model such parameters.
0	  The appearance of thin film objects is highly dependent on the surface orientation and optical parameters such as the refractive index and film thickness.
1	  First, we therefore analyzed the optical parameters of non-planar objects with thin film surfaces.
1	  Next, we proposed and implemented an analysis procedure and demonstrated its effectiveness for studying planar objects with thin film surfaces.
1	  Finally, we developed a device to acquire the shapes and optical parameters of objects with thin film surfaces using a camera and demonstrated the effectiveness of our method experimentally.
1	  Then, we surveyed the errors caused by the light source.
1	  We discussed the difference between the theoretically obtained parameters and experimental data obtained using a hyper spectral camera.


### 59
##### 10.1109/TPAMI.2019.2937086
#### Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes


0	  Unifying text detection and text recognition in an end-to-end training fashion has become a new trend for reading text in the wild, as these two tasks are highly relevant and complementary.
0	  In this paper, we investigate the problem of scene text spotting, which aims at simultaneous text detection and recognition in natural images.
1	  An end-to-end trainable neural network named as Mask TextSpotter is presented.
1	  Different from the previous text spotters that follow the pipeline consisting of a proposal generation network and a sequence-to-sequence recognition network, Mask TextSpotter enjoys a simple and smooth end-to-end learning procedure, in which both detection and recognition can be achieved directly from two-dimensional space via semantic segmentation.
1	  Further, a spatial attention module is proposed to enhance the performance and universality.
2	  Benefiting from the proposed two-dimensional representation on both detection and recognition, it easily handles text instances of irregular shapes, for instance, curved text.
2	  We evaluate it on four English datasets and one multi-language dataset, achieving consistently superior performance over state-of-the-art methods in both detection and end-to-end text recognition tasks.
2	  Moreover, we further investigate the recognition module of our method separately, which significantly outperforms state-of-the-art methods on both regular and irregular text datasets for scene text recognition.


### 60
##### 10.1109/TPAMI.2019.2937292
#### Discriminative Video Representation Learning Using Support Vector Classifiers


0	  Most popular deep models for action recognition in videos generate independent predictions for short clips, which are then pooled heuristically to assign an action label to the full video segment.
0	  As not all frames may characterize the underlying action, pooling schemes that impose equal importance on all frames might be unfavorable.
1	  To tackle this problem, we propose discriminative pooling, based on the notion that among the features generated on all short clips, there is at least one that characterizes the action.
1	  To identify useful features, we resort to a negative bag consisting of features that are known to be irrelevant.
1	  With the features from the video as a positive bag and the irrelevant features as the negative bag, we cast an objective to learn a (nonlinear) hyperplane that separates the unknown useful feature from the rest in a multiple instance learning formulation within a support vector machine setup.
1	  We use the parameters of this separating hyperplane as descriptors for the video.
1	  Since these parameters are directly related to the support vectors in a max-margin framework, they can be treated as weighted-average-pooling of the features from the bags.
2	  We report results from experiments on eight computer vision benchmarks demonstrating state-of-the-art performance across these tasks.


### 61
##### 10.1109/TPAMI.2019.2936841
#### Neural Image Compression for Gigapixel Histopathology Image Analysis


1	  We propose Neural Image Compression (NIC), a two-step method to build convolutional neural networks for gigapixel image analysis solely using weak image-level labels.
1	  First, gigapixel images are compressed using a neural network trained in an unsupervised fashion, retaining high-level information while suppressing pixel-level noise.
1	  Second, a convolutional neural network (CNN) is trained on these compressed image representations to predict image-level labels, avoiding the need for fine-grained manual annotations.
1	  We compared several encoding strategies, namely reconstruction error minimization, contrastive training and adversarial feature learning, and evaluated NIC on a synthetic task and two public histopathology datasets.
2	  We found that NIC can exploit visual cues associated with image-level labels successfully, integrating both global and local visual information.
2	  Furthermore, we visualized the regions of the input gigapixel images where the CNN attended to, and confirmed that they overlapped with annotations from human experts.


### 62
##### 10.1109/TPAMI.2019.2936378
#### Adversarial Attack Type I: Cheat Classifiers by Significant Changes


0	  Despite the great success of deep neural networks, the adversarial attack can cheat some well-trained classifiers by small permutations.
0	  In this paper, we propose another type of adversarial attack that can cheat classifiers by significant changes.
0	  For example, we can significantly change a face but well-trained neural networks still recognize the adversarial and the original example as the same person.
0	  Statistically, the existing adversarial attack increases Type II error and the proposed one aims at Type I error, which are hence named as Type II and Type I adversarial attack, respectively.
0	  The two types of attack are equally important but are essentially different, which are intuitively explained and numerically evaluated.
1	  To implement the proposed attack, a supervised variation autoencoder is designed and then the classifier is attacked by updating the latent variables using gradient information.
2	  Experimental results show that our method is practical and effective to generate Type I adversarial examples on large-scale image datasets.
2	  Most of these generated examples can pass detectors designed for defending Type II attack and the strengthening strategy is only efficient with a specific type attack, both implying that the underlying reasons for Type I and Type II attack are different.


### 63
##### 10.1109/TPAMI.2019.2936024
#### Semi-Supervised Adversarial Monocular Depth Estimation


0	  In this paper, we address the problem of monocular depth estimation when only a limited amount of training image-depth pairs are available.
0	  To achieve high regression accuracy, state-of-the-art estimation methods rely on CNNs trained with a vast amount of image-depth pairs, which are prohibitively costly or even infeasible to acquire.
1	  Aiming to break the bottleneck of such expensive data collections, in this paper, we propose a semi-supervised adversarial learning framework, which only utilizes a small amount of image-depth pairs with a large amount of cheaply-available monocular images to pursuit high accuracy.
1	  In particular, we use one generator to regress the depth and two discriminators to evaluate the predicted depth.
2	  These two discriminators provide their feedbacks to the generator as the loss to generate more realistic and accurate depth predictions.
2	  Experiments show that the proposed approach can (1) improve most state-of-the-art models on NYUD v2 dataset by effectively leveraging additional unlabeled data sources; (2) reach state-of-the-art accuracy when the training set is small, e.g., on Make3D dataset; (3) adapts well to an unseen new dataset (Make3D in our case) after training on an annotated dataset (KITTI in our case).


### 64
##### 10.1109/TPAMI.2019.2935715
#### Saliency Prediction in the Deep Learning Era: Successes and Limitations


0	  Visual saliency models have enjoyed a big leap in performance in recent years, thanks to advances in deep learning and large scale annotated data.
0	  Despite enormous effort and huge breakthroughs, however, models still fall short in reaching human-level accuracy.
0	  In this work, I explore the landscape of the field emphasizing on new deep saliency models, benchmarks, and datasets.
1	  A large number of image and video saliency models are reviewed and compared over two image benchmarks and two large scale video datasets.
2	  Further, I identify factors that contribute to the gap between models and humans and discuss remaining issues that need to be addressed to build the next generation of more powerful saliency models.
2	  Some specific questions that are addressed include: in what ways current models fail, how to remedy them, what can be learned from cognitive studies of attention, how explicit saliency judgments relate to fixations, how to conduct fair model comparison, and what are the emerging applications of saliency models.


### 65
##### 10.1109/TPAMI.2019.2934852
#### Learning Energy-based Spatial-Temporal Generative ConvNets for Dynamic Patterns


0	  Video sequences contain rich dynamic patterns, such as dynamic texture patterns that exhibit stationarity in the temporal domain, and action patterns that are non-stationary in either spatial or temporal domain.
2	  We show that an energy-based spatial-temporal generative ConvNet can be used to model and synthesize dynamic patterns.
1	  The model defines a probability distribution on the video sequence, and the log probability is defined by a spatial-temporal ConvNet that consists of multiple layers of spatial-temporal filters to capture spatial-temporal patterns of different scales.
1	  The model can be learned from the training video sequences by an "analysis by synthesis" learning algorithm that iterates the following two steps.
1	  Step 1 synthesizes video sequences from the currently learned model.
1	  Step 2 then updates the model parameters based on the difference between the synthesized video sequences and the observed training sequences.
2	  We show that the learning algorithm can synthesize realistic dynamic patterns.
2	  We also show that it is possible to learn the model from incomplete training sequences with either occluded pixels or missing frames, so that model learning and pattern completion can be accomplished simultaneously.


### 66
##### 10.1109/TPAMI.2019.2934455
#### Polyhedral Conic Classifiers for Computer Vision Applications and Open Set Recognition


0	  This paper introduces a family of quasi-linear discriminants that outperform current large-margin methods in sliding window visual object detection and open set recognition tasks.
0	  In these applications, the classification problems are both numerically imbalanced -- positive training and test windows are much rarer than negative ones -- and geometrically asymmetric -- the positive samples typically form compact, visually-coherent groups while negatives are much more diverse, including anything at all that is not a well-centered sample from the target class.
0	  For such tasks, there is a need for discriminants whose decision regions focus on tightly circumscribing the positive class, while still taking account of negatives in zones where the two classes overlap.
1	  To this end, we propose a family of quasi-linear polyhedral conic discriminants whose positive regions are distorted L1 or L2 balls.
1	  In addition, we also integrated the proposed classification loss into deep neural networks so that both the features and classifier can be learned simultaneously end-to-end fashion to improve the classification accuracies.
1	  The methods can be trained from either binary or positive-only samples using constrained quadratic programs related to SVMs.
2	  Our experiments show that they significantly outperform linear SVMs, deep neural networks using softmax loss function and existing one-class discriminants.


### 67
##### 10.1109/TPAMI.2019.2934052
#### Matching Seqlets: An Unsupervised Approach for Locality Preserving Sequence Matching


1	  In this paper, we propose a novel unsupervised approach for sequence matching by explicitly accounting for the locality properties in the sequences.
0	  In contrast to conventional approaches that rely on frame-to-frame matching, we conduct matching using sequencelet or seqlet, a sub-sequence wherein the frames share strong similarities and are thus grouped together.
1	  The optimal seqlets and matching between them are learned jointly, without any supervision from users.
1	  The learned seqlets preserve the locality information at the scale of interest and resolve the ambiguities during matching, which are omitted by frame-based matching methods.
2	  We show that our proposed approach outperforms the state-of-the-art ones on datasets of different domains including human actions, facial expressions, speech, and character strokes.


### 68
##### 10.1109/TPAMI.2019.2933829
#### Inferring Latent Domains for Unsupervised Deep Domain Adaptation


0	  Unsupervised Domain Adaptation (UDA) refers to the problem of learning a model in a target domain where labeled data are not available by leveraging information from annotated data in a source domain.
0	  Most deep UDA approaches operate in a single-source, single-target scenario, i.e.
0	  they assume that the source and the target samples arise from a single distribution.
0	  However, in practice most datasets can be regarded as mixtures of multiple domains.
0	  In these cases, exploiting traditional single-source, single-target methods for learning classification models may lead to poor results.
0	  Furthermore, it is often difficult to provide the domain labels for all data points, i.e. latent domains should be automatically discovered.
1	  This paper introduces a novel deep architecture which addresses the problem of UDA by automatically discovering latent domains in visual datasets and exploiting this information to learn robust target classifiers.
1	  Specifically, our architecture is based on two main components, i.e. a side branch that automatically computes the assignment of each sample to its latent domain and novel layers that exploit domain membership information to appropriately align the distribution of the CNN internal feature representations to a reference distribution.
2	  We evaluate our approach on publicly available benchmarks, showing that it outperforms state-of-the-art domain adaptation methods.


### 69
##### 10.1109/TPAMI.2019.2933841
#### Faster First-Order Methods for Stochastic Non-Convex Optimization on Riemannian Manifolds


0	  First-order non-convex Riemannian optimization algorithms have gained recent popularity in structured machine learning problems including principal component analysis and low-rank matrix completion.
1	  The current paper presents an efficient Riemannian Stochastic Path Integrated Differential EstimatoR (R-SPIDER) algorithm to solve the finite-sum and online Riemannian non-convex minimization problems.
1	  At the core of R-SPIDER is a recursive semi-stochastic gradient estimator that can accurately estimate Riemannian gradient under not only exponential mapping and parallel transport, but also general retraction and vector transport operations.
2	  Compared with prior Riemannian algorithms, such a recursive gradient estimation mechanism endows R-SPIDER with lower computational cost in first-order oracle complexity.
2	  Specifically, for finite-sum problems with $n$ components, R-SPIDER is proved to converge to an $\epsilon$-approximate stationary point within $\mathcal{O}\big(\min\big(n+\frac{\sqrt{n}}{\epsilon^2},\frac{1}{\epsilon^3}\big)\big)$ stochastic gradient evaluations, beating the best-known complexity $\mathcal{O}\big(n+\frac{1}{\epsilon^4}\big)$; for online optimization, R-SPIDER is shown to converge with $\mathcal{O}\big(\frac{1}{\epsilon^3}\big)$ complexity which is, to the best of our knowledge, the first non-asymptotic result for online Riemannian optimization.
1	  For the special case of gradient dominated functions, we further develop a variant of R-SPIDER with improved linear rate of convergence.
2	  Extensive experimental results demonstrate the advantage of the proposed algorithms over the state-of-the-art Riemannian non-convex optimization methods.


### 70
##### 10.1109/TPAMI.2019.2933818
#### Virtual Point Removal for Large-Scale 3D Point Clouds With Multiple Glass Planes


0	  Large-scale 3D point clouds (LS3DPCs) captured by terrestrial LiDAR scanners often include virtual points which are generated by glass reflection.
0	  The virtual points may degrade the performance of various computer vision techniques when applied to LS3DPCs.
1	  In this paper, we propose a virtual point removal algorithm for LS3DPCs with multiple glass planes.
1	  We first estimate multiple glass regions by modeling the reliability with respect to each glass plane, respectively, such that the regions are assigned high reliability when they have multiple echo pulses for each emitted laser pulse.
1	  Then we detect each point whether it is a virtual point or not.
1	  For a given point, we recursively traverse all the possible trajectories of reflection, and select the optimal trajectory which provides a point with a similar geometric feature to a given point at the symmetric location.
1	  We evaluate the performance of the proposed algorithm on various LS3DPC models with diverse numbers of glass planes.
2	  Experimental results show that the proposed algorithm estimates multiple glass regions faithfully and detects the virtual points successfully.
2	  Moreover, we also show that the proposed algorithm yields a much better performance of reflection artifact removal compared with the existing method qualitatively and quantitatively.



### 71
##### 10.1109/TPAMI.2019.2933510
#### P-CNN: Part-Based Convolutional Neural Networks for Fine-Grained Visual Categorization


1 	  This paper proposes an end-to-end fine-grained visual categorization system, termed Part-based Convolutional Neural Network (P-CNN), which consists of three modules.
1	  The first module is a Squeeze-and-Excitation (SE) block, which learns to recalibrate channel-wise feature responses by emphasizing informative channels and suppressing less useful ones.
1	  The second module is a Part Localization Network (PLN) used to locate distinctive object parts, through which a bank of convolutional filters are learned as discriminative part detectors.
1	  Thus, a group of informative parts can be discovered by convolving the feature maps with each part detector.
1	  The third module is a Part Classification Network (PCN) that has two streams.
1	  The first stream classifies each individual object part into image-level categories.
1	  The second stream concatenates part features and global feature into a joint feature for the final classification.
1	  In order to learn powerful part features and boost the joint feature capability, we propose a Duplex Focal Loss used for metric learning and part classification, which focuses on training hard examples.
1	  We further merge PLN and PCN into a unified network for an end-to-end training process via a simple training technique.
2	  Comprehensive experiments and comparisons with state-of-the-art methods on three benchmark datasets demonstrate the effectiveness of our proposed method.


### 72
##### 10.1109/TPAMI.2019.2933209
#### Parallel and Scalable Heat Methods for Geodesic Distance Computation


0	  In this paper, we propose a parallel and scalable approach for geodesic distance computation on triangle meshes.
2	  Our key observation is that the recovery of geodesic distance in the heat method can be reformulated as an optimization of its gradients subject to integrability, which can be solved using an efficient fixed-order method that requires no linear system solving and converges quickly.
1	  Afterwards, the geodesic distance is efficiently recovered by parallel integration of the optimized gradients in breadth-first order.
1	  Moreover, we employ a similar breadth-first strategy to derive a parallel Gauss-Seidel solver for the diffusion step in the heat method.
1	  To further lower the memory consumption from gradient optimization on faces, we also propose a formulation that optimizes the projected gradients on edges, further reducing the memory footprint by about 50%.
2	  Our approach is trivially parallelizable, with a low memory footprint that grows linearly with respect to the model size.
2	  This makes it particularly suitable for handling large models.
2	  Experimental results show that it can efficiently compute geodesic distance on meshes with more than 200 million vertices on a desktop PC with 128GB RAM, outperforming the original heat method and other state-of-the-art geodesic distance solvers.


### 73
##### 10.1109/TPAMI.2019.2932979
#### Sparse Coding of Shape Trajectories for Facial Expression and Action Recognition


0	  The detection and tracking of human landmarks in video streams has gained in reliability partly due to the availability of affordable RGB-D sensors.
0	  The analysis of such time-varying geometric data is playing an important role in automatic human behavior understanding.
0	  However, suitable shape representations as well as their temporal evolution, termed trajectories, often lie to nonlinear manifolds.
0	  This puts an additional constraint (i.e., nonlinearity) in using conventional Machine Learning techniques.
1	  As a solution, this paper accommodates the well-known Sparse Coding and Dictionary Learning approach to study time-varying shapes on the Kendall shape spaces of 2D and 3D landmarks.
1	  We illustrate effective coding of 3D skeletal sequences for action recognition and 2D facial landmark sequences for macro- and micro-expression recognition.
1	  To overcome the inherent nonlinearity of the shape spaces, intrinsic and extrinsic solutions were explored.
2	  As main results, shape trajectories give rise to more discriminative time-series with suitable computational properties, including sparsity and vector space structure.
2	  Extensive experiments conducted on commonly-used datasets demonstrate the competitiveness of the proposed approaches with respect to state-of-the-art.


### 74
##### 10.1109/TPAMI.2019.2932429
#### DAC-SDC Low Power Object Detection Challenge for UAV Applications


0	  The 55th Design Automation Conference (DAC) held its first System Design Contest (SDC) in 2018.
1	  SDC'18 features a lower power object detection challenge (LPODC) on designing and implementing novel algorithms based object detection in images taken from unmanned aerial vehicles (UAV).
1	  The dataset includes 95 categories and 150k images, and the hardware platforms include Nvidia's TX2 and Xilinx's PYNQ Z1.
1	  DAC-SDC'18 attracted more than 110 entries from 12 countries.
1	  This paper presents in detail the dataset and evaluation procedure.
2	  It further discusses the methods developed by some of the entries as well as representative results.
2	  The paper concludes with directions for future improvements.


### 75
##### 10.1109/TPAMI.2019.2932976
#### Multivariate Extension of Matrix-based Renyi's α-order Entropy Functional


0	  The matrix-based Renyi's α-order entropy functional was recently introduced using the normalized eigenspectrum of a Hermitian matrix of the projected data in a reproducing kernel Hilbert space (RKHS).
0	  However, the current theory in the matrix-based Renyi's α-order entropy functional only defines the entropy of a single variable or mutual information between two random variables.
0	  In information theory and machine learning communities, one is also frequently interested in multivariate information quantities, such as the multivariate joint entropy and different interactive quantities among multiple variables.
1	  In this paper, we first define the matrix-based Renyi's α-order joint entropy among multiple variables.
1	  We then show how this definition can ease the estimation of various information quantities that measure the interactions among multiple variables, such as interactive information and total correlation.
1	  We finally present an application to feature selection to show how our definition provides a simple yet powerful way to estimate a widely-acknowledged intractable quantity from data.
2	  A real example on hyperspectral image (HSI) band selection is also provided.


### 76
##### 10.1109/TPAMI.2019.2932415
#### SafePredict: A Meta-Algorithm for Machine Learning That Uses Refusals to Guarantee Correctness


0	  SafePredict is a novel meta-algorithm that works with any base prediction algorithm for online data to guarantee an arbitrarily chosen correctness rate, $1-\in$, by allowing refusals.
0	  Allowing refusals means that the meta-algorithm may refuse to emit a prediction produced by the base algorithm on occasion so that the error rate on non-refused predictions does not exceed $\in$.
1	  The SafePredict error bound does not rely on any assumptions on the data distribution or the base predictor.
1	  When the base predictor happens not to exceed the target error rate $\in$, SafePredict refuses only a finite number of times.
1	  When the error rate of the base predictor changes through time SafePredict makes use of a weight-shifting heuristic that adapts to these changes without knowing when the changes occur yet still maintains the correctness guarantee.
2	  Empirical results show that (i) SafePredict compares favorably with state-of-the art confidence based refusal mechanisms which fail to offer robust error guarantees; and (ii) combining SafePredict with such refusal mechanisms can in many cases further reduce the number of refusals.
#	  Our software is included in the supplementary material.


### 77
##### 10.1109/TPAMI.2019.2930192
#### Pattern of Local Gravitational Force(PLGF): A novel Local Image Descriptor


1	  This paper presents a novel local image descriptor called Pattern of Local Gravitational Force (PLGF).
1	  It is inspired by Law of Universal Gravitation.
1	  PLGF is a hybrid descriptor, which is a combination of two feature components: one is the Pattern of Local Gravitational Force Magnitude (PLGFM), and another is Pattern of Local Gravitational Force Angle (PLGFA).
1	  PLGFM encodes the local gravitational force magnitude, and PLGFA encodes the local gravitational force angle that the center pixel exerts on all other pixels within a local neighborhood.
1	  We propose a novel noise resistance and the edge-preserving binary pattern called neighbors to center difference binary pattern (NCDBP) for gravitational force magnitude encoding.
2	  Finally, the histograms of the two components are concatenated to construct the PLGF descriptor.
2	  Experimental results on the existing face recognition databases, texture database, and biomedical image database show that PLGF is an effective image descriptor, and it outperforms other widely used existing descriptors.
2	  Even if in complicated variations like noise, and illumination with smaller databases, a combination of PLGF and convolutional neural network (CNN) performs consistently better than other state-of-the-art techniques.


### 78
##### 10.1109/TPAMI.2019.2932058
#### Hierarchical Deep Click Feature Prediction for Fine-grained Image Recognition


0	  The click feature of an image, defined as the user-click-frequency vector of the image on a pre-defined word vocabulary, is known to effectively reduce the semantic gap for fine-grained image recognition.
0	  Unfortunately, user-click-frequency data are usually absent in practice.
0	  It remains challenging to predict the click feature from the visual feature, because the user-click-frequency vector of an image is always noisy and sparse.
1	  In this paper, we devise a Hierarchical Deep Word Embedding (HDWE) model by integrating sparse constraints and an improved RELU operator to address click feature prediction from visual features.
1	  HDWE is a coarse-to-fine click feature predictor that is learned with the help of an auxiliary image dataset containing click information.
1	  It can therefore discover the hierarchy of word semantics.
2	  We evaluate HDWE on three dog and one bird image datasets, in which Clickture-Dog and Clickture-Bird are respectively utilized as auxiliary datasets to provide click data.
2	  Our empirical studies show that HDWE has 1) higher recognition accuracy, 2) a larger compression ratio, and 3) good one-shot learning ability and scalability to unseen categories.


### 79
##### 10.1109/TPAMI.2019.2931897
#### Selfie Video Stabilization


0	  We propose a novel algorithm for stabilizing selfie videos.
0	  Our goal is to automatically generate stabilized video that has optimal smooth motion in the sense of both foreground and background.
0	  The key insight is that non-rigid foreground motion in selfie videos can be analyzed using a 3D face model, and background motion can be analyzed using optical flow.
1	  We use second derivative of temporal trajectory of selected pixels as the measure of smoothness.
2	  Our algorithm stabilizes selfie videos by minimizing the smoothness measure of the background, regularized by the motion of the foreground.
2	  Experiments show that our method outperforms state-of-the-art general video stabilization techniques in selfie videos.


### 80
##### 10.1109/TPAMI.2019.2932062
#### Switchable Normalization for Learning-to-Normalize Deep Representation


1	  We address a learning-to-normalize problem by proposing Switchable Normalization (SN), which learns to select different normalizers for different normalization layers of a deep neural network.
1	  SN employs three distinct scopes to compute statistics (means and variances) including a channel, a layer, and a minibatch.
1	  SN switches between them by learning their importance weights in an end-to-end manner.
1	  It has several good properties.
1	  First, it adapts to various network architectures and tasks.
1	  Second, it is robust to a wide range of batch sizes, maintaining high performance even when small minibatch is presented (eg 2 images/GPU).
1	  Third, SN does not have sensitive hyper-parameter, unlike group normalization that searches the number of groups as a hyper-parameter.
1	  Without bells and whistles, SN outperforms its counterparts on various challenging benchmarks, such as ImageNet, COCO, CityScapes, ADE20K, MegaFace and Kinetics.
2	  Analyses of SN are also presented to answer the following three questions: 
2     (a) Is it useful to allow each normalization layer to select its own normalizer?
2	  (b) What impacts the choices of normalizers?
2	  (c) Do different tasks and datasets prefer different normalizers?
2	  We hope SN will help ease the usage and understand the normalization techniques in deep learning.
#	  The code of SN has been released at https://github.com/switchablenorms.


### 81
##### 10.1109/TPAMI.2019.2931577
#### Absolute Pose Estimation of Central Cameras Using Planar Regions


1	  A novel method is proposed for the absolute pose estimation of a central 2D camera with respect to 3D depth data without the use of any dedicated calibration pattern or explicit point correspondences.
1	  The proposed method has no specific assumption about the data source: plain depth information is expected from the 3D sensing device and a central camera is used to capture the 2D images.
1	  Both the perspective and omnidirectional central cameras are handled within a single generic camera model.
1	  Pose estimation is formulated as a 2D-3D nonlinear shape registration task which is solved without point correspondences or complex similarity metrics.
1	  It relies on a set of corresponding planar regions, and the pose parameters are obtained by solving an overdetermined system of nonlinear equations.
2	  The efficiency and robustness of the proposed method were confirmed on both large scale synthetic data and on real data acquired from various types of sensors.


### 82
##### 10.1109/TPAMI.2019.2931569
#### Dual Adversarial Transfer for Sequence Labeling


0	  We propose a new architecture for addressing sequence labeling, termed Dual Adversarial Transfer Network (DATNet).
1	  Specifically, the proposed DATNet includes two variants, i.e., DATNet-F and DATNet-P, which are proposed to explore effective feature fusion between high and low resource.
1	  To address the noisy and imbalanced training data, we propose a novel Generalized Resource-Adversarial Discriminator (GRAD) and adopt adversarial training to boost model generalization.
2	  We investigate the effects of different components of DATNet across different domains and languages, and show that significant improvement can be obtained especially for low-resource data.
2	  Without augmenting any additional hand-crafted features, we achieve state-of-the-art performances on CoNLL, Twitter, PTB-WSJ, OntoNotes and Universal Dependencies with three popular sequence labeling tasks, i.e. Named entity recognition (NER), Part-of-Speech (POS) Tagging and Chunking.


### 83
##### 10.1109/TPAMI.2019.2929519
#### Graph Embedding Using Frequency Filtering


0	  The target of graph embedding is to embed graphs in vector space such that the embedded feature vectors follow the differences and similarities of the source graphs.
1	  In this paper, a novel method named Frequency Filtering Embedding (FFE) is proposed which uses graph Fourier transform and Frequency filtering as a graph Fourier domain operator for graph feature extraction.
0	  Frequency filtering amplifies or attenuates selected frequencies using appropriate filter functions.
1	  Here, heat, anti-heat, part-sine and identity filter sets are proposed as the filter functions.
1	  A generalized version of FFE named GeFFE is also proposed by defining pseudo-Fourier operators.
1	  This method can be considered as a general framework for formulating some previously defined invariants in other works by choosing a suitable filter bank and defining suitable pseudo-Fourier operators.
1	  This flexibility empowers GeFFE to adapt itself to the properties of each graph dataset unlike the previous spectral embedding methods and leads to superior classification accuracy relative to the others.
2	  Utilizing the proposed part-sine filter set which its members filter different parts of the spectrum in turn improves the classification accuracy of GeFFE method.
2	  Additionally GeFFE resolves the cospectrality problem entirely in tested datasets.


### 84
##### 10.1109/TPAMI.2019.2931317
#### Reconstruct as Far as You Can: Consensus of Non-Rigid Reconstruction from Feasible Regions


0	  Much progress has been made for non-rigid structure from motion during the last two decades, which made it possible to provide reasonable solutions for benchmark data.
0	  In order to utilize NRSfM techniques in realistic situations, however, we are facing two problems that must be solved: First, general scenes contain complex deformations as well as multiple objects, which violates usual assumptions of previous proposals.
0	  Second, there are many unreconstructable regions in the video, either because of discontinued tracks of 2D trajectories or those regions static towards camera, which require careful manipulations.
1	  In this paper, we show that a consensus-based reconstruction framework can handle these issues effectively.
1	  Even though the entire scene is complex, its parts usually have simpler deformations, and even though there are some unreconstructable parts, they can be weeded out to reduce harmful effect on the entire reconstruction.
1	  The main difficulty lies in identifying appropriate parts, however, it can be effectively avoided by sampling parts stochastically and then aggregate their reconstructions afterwards.
2	  Experimental results show that the proposed method renews the state-of-the-art for popular benchmark data under much harsher environments, i.e, narrow camera view ranges, and it can reconstruct real-word videos effectively for as many areas as it can.


### 85
##### 10.1109/TPAMI.2019.2930985
#### Learning Continuous Face Age Progression: A Pyramid of GANs


0	  The two underlying requirements of face age progression, i.e., aging accuracy and identity permanence, are not well studied in the literature.
1	  This paper presents a novel generative adversarial network based approach to address the issues in a coupled manner.
1	  It separately models the constraints for intrinsic subject-specific characteristics and age-specific facial changes w.r.t. the elapsed time, ensuring that the generated faces present desired aging effects while keeping personalized properties stable.
1	  To render photo-realistic facial details, high-level age-specific features conveyed by the synthesized face are estimated by a pyramidal adversarial discriminator at multiple scales, which simulates aging effects in a finer way.
1	  Further, an adversarial learning scheme is introduced to simultaneously train a single generator and multiple parallel discriminators, resulting in smooth continuous face aging sequences.
2	  Our method is applicable even in the presence of variations in pose, expression, makeup, etc., achieving remarkably vivid aging effects.
2	  Quantitative evaluations by a COTS face recognition system demonstrate that the target age distributions are accurately recovered, and 99.88% and 99.98% age progressed faces are correctly verified at 0.001% FAR after transformations of approximately 28 and 23 years on MORPH and CACD, respectively.
2	  Both visual and quantitative assessments show that the approach advances the state-of-the-art.


### 86
##### 10.1109/TPAMI.2019.2929034
#### Visual Tracking via Dynamic Memory Networks


0	  Template-matching methods for visual tracking have gained popularity recently due to their good performance and fast speed.
0	  However, they lack effective ways to adapt to changes in the target object's appearance, making their tracking accuracy still far from state-of-the-art.
1	  In this paper, we propose a dynamic memory network to adapt the template to the target's appearance variations during tracking.
1	  The reading and writing process of the external memory is controlled by an LSTM network with the search feature map as input.
1	  A spatial attention mechanism is applied to concentrate the LSTM input on the potential target as the location of the target is at first unknown.
1	  To prevent aggressive model adaptivity, we apply gated residual template learning to control the amount of retrieved memory that is used to combine with the initial template.
1	  In order to alleviate the drift problem, we also design a "negative" memory unit that stores templates for distractors, which are used to cancel out wrong responses from the object template.
1	  To further boost the tracking performance, an auxiliary classification loss is added after the feature extractor part.
1	  Unlike tracking-by-detection methods where the object's information is maintained by the weight parameters of neural networks, which requires expensive online fine-tuning to be adaptable, our tracker runs completely feed-forward and adapts to the target's appearance changes by updating the external memory.
2	  Moreover, the capacity of our model is not determined by the network size as with other trackers - the capacity can be easily enlarged as the memory requirements of a task increase, which is favorable for memorizing long-term object information.
2	  Extensive experiments on the OTB and VOT datasets demonstrate that our trackers perform favorably against state-of-the-art tracking methods while retaining real-time speed.


### 87
##### 10.1109/TPAMI.2019.2930051
#### Rotation Averaging with the Chordal Distance: Global Minimizers and Strong Duality


0	  In this paper we explore the role of duality principles within the problem of rotation averaging, a fundamental task in a wide range of applications.
0	  In its conventional form, rotation averaging is stated as a minimization over multiple rotation constraints.
0	  As these constraints are non-convex, this problem is generally considered challenging to solve globally.
1	  We show how to circumvent this difficulty through the use of Lagrangian duality.
1	  While such an approach is well-known it is normally not guaranteed to provide a tight relaxation.
1	  Based on spectral graph theory, we analytically prove that in many cases there is no duality gap unless the noise levels are severe.
1	  This allows us to obtain certifiably global solutions to a class of important non-convex problems in polynomial time.
2	  We also propose an efficient, scalable algorithm that outperforms general purpose numerical solvers by a large margin and compares favourably to current state-of-the-art.
2	  Further, our approach is able to handle the large problem instances commonly occurring in structure from motion settings and it is trivially parallelizable.
2	  Experiments are presented for a number of different instances of both synthetic and real-world data.


### 88
##### 10.1109/TPAMI.2019.2930258
#### Every Pixel Counts ++: Joint Learning of Geometry and Motion with 3D Holistic Understanding


0	  Learning to estimate 3D geometry in a single frame and optical flow from consecutive frames by watching unlabeled videos via deep convolutional network has made significant progress recently.
0	  Current state-of-the-art (SoTA) methods treat the two tasks independently.
0	  One important assumption of the existing depth estimation methods is that the scenes contain no moving object.
1	  In this paper, we propose to address the two tasks as a whole, i.e. to jointly understand per-pixel 3D geometry and motion.
1	  This eliminates the need of static scene assumption and enforces the inherent geometrical consistency during the learning process, yielding significantly improved results for both tasks.
1	  We call our method as "Every Pixel Counts++" or "EPC++".
1	  Various loss terms are formulated to jointly supervise the learning across geometrical cues and effective adaptive training strategy is proposed to achieve better performance.
2	  Comprehensive experiments were conducted on datasets with different scenes, including driving scenario (KITTI 2012 and KITTI 2015 datasets), mixed outdoor/indoor scenes (Make3D) and synthetic animation (MPI Sintel dataset).
2	  Performance on the five tasks of depth estimation, optical flow estimation, odometry, moving object segmentation and scene flow estimation shows that our approach outperforms other SoTA methods, demonstrating the effectiveness of each module of our proposed method.


### 89
##### 10.1109/TPAMI.2019.2930501
#### Fast Exact Evaluation of Univariate Kernel Sums


1	  This paper presents new methodology for computationally efficient evaluation of univariate kernel sums.
1	  It is shown that a rich class of kernels allows for exact evaluation of functions expressed as a sum of kernels using simple recursions.
1	  Given an ordered sample the computational complexity is linear in the sample size.
2	  Direct applications to the estimation of denisties and their derivatives shows that the proposed approach is competitive with the state-of-the-art.
2	  Extensions to multivariate problems including independent component analysis and spatial smoothing illustrate the versatility of univariate kernel estimators, and highlight the efficiency and accuracy of the proposed approach.
2	  Multiple applications in image processing, including image deconvolution; denoising; and reconstruction are considered, showing that the proposed approach offers very promising potential in these fields.


### 90
##### 10.1109/TPAMI.2019.2929520
#### Deep Affinity Network for Multiple Object Tracking


0	  Multiple Object Tracking (MOT) plays an important role in solving many fundamental problems in video analysis and computer vision.
0	  Most MOT methods employ two steps: Object Detection and Data Association.
0	  The first step detects objects of interest in every frame of a video, and the second establishes correspondence between the detected objects in different frames to obtain their tracks.
0	  Object detection has made tremendous progress in the last few years due to deep learning.
0	  However, data association for tracking still relies on hand crafted constraints such as appearance, motion, spatial proximity, grouping etc. to compute affinities between the objects in different frames.
1	  In this paper, we harness the power of deep learning for data association in tracking by jointly modeling object appearances and their affinities between different frames in an end-to-end fashion.
1	  The proposed Deep Affinity Network (DAN) learns compact, yet comprehensive features of pre-detected objects at several levels of abstraction, and performs exhaustive pairing permutations of those features in any two frames to infer object affinities.
1	  DAN also accounts for multiple objects appearing and disappearing between video frames.
1	  We exploit the resulting efficient affinity computations to associate objects in the current frame deep into the previous frames for reliable on-line tracking.
2	  Our technique is evaluated on popular multiple object tracking challenges MOT15, MOT17 and UA-DETRAC.
2	  Comprehensive benchmarking under twelve evaluation metrics demonstrates that our approach is among the best performing techniques on the leader board for these challenges.
#	  The open source implementation of our work is available at https://github.com/shijieS/SST.git.


### 91
##### 10.1109/TPAMI.2019.2928806
#### Distributed Variational Representation Learning


0	  The problem of distributed representation learning is one in which multiple observations $X_1,\ldots,X_K$ are processed separately to learn as much information as possible about some source $Y$.
1	  We investigate this problem from information-theoretic grounds, through a generalization of Tishby's centralized Information Bottleneck (IB) method to the distributed setting.
1	  Specifically, $K\geq 2$ encoders, compress their observations $X_1,\ldots,X_K$ separately such that, collectively, the produced representations preserve as much information as possible about $Y$.
1	  We study both discrete memoryless (DM) and vector Gaussian data models.
1	  For the discrete model, we establish a single-letter characterization of the optimal tradeoff for a class of memoryless sources.
1	  For the vector Gaussian model, we provide an explicit characterization of the optimal complexity-relevance tradeoff.
1	  Furthermore, we develop a variational bound on the complexity-relevance tradeoff which generalizes the evidence lower bound (ELBO) to the distributed setting.
1	  We provide two algorithms to compute this bound: i) a Blahut-Arimoto type iterative algorithm which computes optimal complexity-relevance mappings by iterating over a set of self-consistent equations, and ii) a variational inference type algorithm in which the encoding mappings are parametrized by neural networks, the bound approximated by Markov sampling and optimized with stochastic gradient descent.
2	  Numerical results on synthetic and real datasets are provided to support the efficiency of the approaches and algorithms developed in this paper.


### 92
##### 10.1109/TPAMI.2019.2928550
#### Stereo Matching Using Multi-level Cost Volume and Multi-scale Feature Constancy


0	  For CNNs based stereo matching methods, cost volumes play an important role in achieving good matching accuracy.
1	  In this paper, we present an end-to-end trainable convolution neural network to fully use cost volumes for stereo matching.
1	  Our network consists of three sub-modules, i.e., shared feature extraction, initial disparity estimation, and disparity refinement.
1	  These sub-modules of our network are tightly-coupled, making it compact and easy to train.
1	  Moreover, we investigate the problem of developing a robust model to perform well across multiple datasets with different characteristics.
1	  We achieve this by introducing a two-stage finetuning scheme to gently transfer the model to target datasets.
1	  Specifically, in the first stage, the model is finetuned using both a large synthetic dataset and the target datasets with a relatively large learning rate, while in the second stage the model is trained using only the target datasets with a small learning rate.
2	  The proposed method is tested on several benchmarks including the Middlebury 2014, KITTI 2015, ETH3D 2017, and SceneFlow datasets.
2	  Experimental results show that our method achieves the state-of-the-art performance on all the datasets.
2	  The proposed method also won the 1st prize on the Stereo task of Robust Vision Challenge 2018.


### 93
##### 10.1109/TPAMI.2019.2929170
#### Confidence Propagation through CNNs for Guided Sparse Depth Regression


0	  Generally, convolutional neural networks (CNNs) process data on a regular grid, e.g. data generated by ordinary cameras.
0	  Designing CNNs for sparse and irregularly spaced input data is still an open research problem with numerous applications in autonomous driving, robotics, and surveillance.
1	  In this paper, we propose an algebraically-constrained normalized convolution layer for CNNs with highly sparse input that has a smaller number of network parameters compared to related work.
1	  We propose novel strategies for determining the confidence from the convolution operation and propagating it to consecutive layers.
1	  We also propose an objective function that simultaneously minimizes the data error while maximizing the output confidence.
1	  To integrate structural information, we also investigate fusion strategies to combine depth and RGB information in our normalized convolution network framework.
1	  In addition, we introduce the use of output confidence as an auxiliary information to improve the results.
2	  The capabilities of our normalized convolution network framework are demonstrated for the problem of scene depth completion.
2	  Comprehensive experiments are performed on the KITTI-Depth and the NYU-Depth-v2 datasets.
2	  The results clearly demonstrate that the proposed approach achieves superior performance while requiring only about 1-5% of the number of parameters compared to the state-of-the-art methods.


### 94
##### 10.1109/TPAMI.2019.2929166
#### Multiset Feature Learning for Highly Imbalanced Data Classification


0	  With the expansion of data, increasing imbalanced data has emerged.
0	  When the imbalance ratio (IR) of data is high, most existing imbalanced learning methods decline seriously in classification performance.
1	  In this paper, we systematically investigate the highly imbalanced data classification problem, and propose an uncorrelated cost-sensitive multiset learning (UCML) approach for it.
1	  Specifically, UCML first constructs multiple balanced subsets through random partition, and then employs the multiset feature learning (MFL) to learn discriminant features from the constructed multiset.
1	  To enhance the usability of each subset and deal with the non-linearity issue existed in each subset, we further propose a deep metric based UCML (DM-UCML) approach.
1	  DM-UCML introduces the generative adversarial network technique into the multiset constructing process, such that each subset can own similar distribution with the original dataset.
1	  To cope with the non-linearity issue, DM-UCML integrates deep metric learning with MFL, such that more favorable performance can be achieved.
1	  In addition, DM-UCML designs a new discriminant term to enhance the discriminability of learned metrics.
2	  Experiments on eight traditional highly class-imbalanced datasets and two large-scale datasets indicate that: the proposed approaches outperform state-of-the-art highly imbalanced learning methods and are more robust to high IR.


### 95
##### 10.1109/TPAMI.2019.2929257
#### OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields


0	  Realtime multi-person 2D pose estimation is a key component in enabling machines to have an understanding of people in images and videos.
1	  In this work, we present a realtime approach to detect the 2D pose of multiple people in an image.
1	  The proposed method uses a nonparametric representation, which we refer to as Part Affinity Fields (PAFs), to learn to associate body parts with individuals in the image.
2	  This bottom-up system achieves high accuracy and realtime performance, regardless of the number of people in the image.
0	  In previous work, PAFs and body part location estimation were refined simultaneously across training stages.
2	  We demonstrate that using a PAF-only refinement is able to achieve a substantial increase in both runtime performance and accuracy.
2	  We also present the first combined body and foot keypoint detector, based on an annotated foot dataset that we have publicly released.
2	  We show that the combined detector not only reduces the inference time compared to running them sequentially, but also maintains the accuracy of each component individually.
2	  This work has culminated in the release of OpenPose, the first open-source realtime system for multi-person 2D pose detection, including body, foot, hand, and facial keypoints.


### 96
##### 10.1109/TPAMI.2019.2929146
#### 3D Rigid Motion Segmentation with Mixed and Unknown Number of Models


0	  Many real-world video sequences cannot be conveniently categorized as general or degenerate; in such cases, imposing a false dichotomy in using the fundamental matrix or homography model for motion segmentation on video sequences would lead to difficulty.
0	  Even when we are confronted with a general scene-motion, the fundamental matrix approach as a model for motion segmentation still suffers from several defects, which we discuss in this paper.
0	  The full potential of the fundamental matrix approach could only be realized if we judiciously harness information from the simpler homography model.
1	  From these considerations, we propose a multi-model spectral clustering framework that synergistically combines multiple models (homography and fundamental matrix) together.
1	  We show that the performance can be substantially improved in this way.
0	  For general motion segmentation tasks, the number of independently moving objects is often unknown a priori and needs to be estimated from the observations.
0	  This is referred to as model selection and it is essentially still an open research problem.
1	  In this work, we propose a set of model selection criteria balancing data fidelity and model complexity.
2	  We perform extensive testing on existing motion segmentation datasets with both segmentation and model selection tasks, achieving state-of-the-art performance on all of them; we also put forth a more realistic and challenging dataset adapted from the KITTI benchmark, containing real-world effects such as strong perspectives and strong forward translations not seen in the traditional datasets.


### 97
##### 10.1109/TPAMI.2019.2929038
#### Learning with privileged information via adversarial discriminative modality distillation


0	  Heterogeneous data modalities can provide complementary cues for several tasks, usually leading to more robust algorithms and better performance.
0	  However, while training data can be accurately collected to include a variety of sensory modalities, it is often the case that not all of them are available in real life (testing) scenarios, where a model has to be deployed.
0	  This raises the challenge of how to extract information from multimodal data in the training stage, in a form that can be exploited at test time, considering limitations such as noisy or missing modalities.
1	  This paper presents a new approach in this direction for RGB-D vision tasks, developed within the adversarial learning and privileged information frameworks.
1	  We consider the practical case of learning representations from depth and RGB videos, while relying only on RGB data at test time.
1	  We propose a new approach to train a hallucination network that learns to distill depth information via adversarial learning, resulting in a clean approach without several losses to balance or hyperparameters.
2	  We report state-of-the-art results for object classification on the NYUD dataset, and video action recognition on the largest multimodal dataset available for this task, the NTU RGB+D, as well as on the Northwestern-UCLA.


### 98
##### 10.1109/TPAMI.2019.2929036
#### Pose-Guided Representation Learning for Person Re-Identification


0	  The large pose variations and misalignment errors exhibited by person images significantly increase the difficulty of person Re-Identification (ReID).
0	  Existing works commonly apply extra operations like pose estimation, part segmentation, etc., to alleviate those issues and improve the robustness of pedestrian representations.
0	  While boosting the ReID accuracy, those operations introduce considerable computational overheads and make the deep models complex and hard to tune.
1	  To chase a more efficient solution, we propose a Part-Guided Representation (PGR) composed of Pose Invariant Feature (PIF) and Local Descriptive Feature (LDF), respectively.
1	  We call PGR "Part-Guided" because it is trained and supervised by local part cues.
1	  Specifically, PIF approximates a pose invariant representation inferred by pose estimation and pose normalization.
1	  LDF focuses on discriminative body parts by approximating a representation learned with body region segmentation.
1	  In this way, extra pose extraction is only introduced during the training stage to supervise the learning of PGR, but is not required during the testing stage for feature extraction.
2	  Extensive comparisons with recent works on five widely used datasets demonstrate the competitive accuracy and efficiency of PGR.


### 99
##### 10.1109/TPAMI.2019.2929043
#### Robust Low-Rank Tensor Recovery with Rectification and Alignment


0	  Low-rank tensor recovery in the presence of sparse but arbitrary errors is an important problem with many practical applications.
1	  In this work, we propose a general framework that recovers low-rank tensors, in which the data can be deformed by some unknown transformations and corrupted by arbitrary sparse errors.
1	  We give a unified presentation of the surrogate-based formulations that incorporate the features of rectification and alignment simultaneously, and establish worst-case error bounds of the recovered tensor.
0	  In this context, the state-of-the-art methods ‘RASL’ and ‘TILT’ can be viewed as two special cases of our work, and yet each only performs part of the function of our method.
1	  Subsequently, we study the optimization aspects of the problem in detail by deriving two algorithms, one based on the alternating direction method of multipliers (ADMM) and the other based on proximal gradient.
1	  We provide convergence guarantees for the latter algorithm, and demonstrate the performance of the former through in-depth simulations.
2	  Finally, we present extensive experimental results on public datasets to demonstrate the effectiveness and efficiency of the proposed framework and algorithms.


### 100
##### 10.1109/TPAMI.2019.2927975
#### On Learning 3D Face Morphable Model from In-the-wild Images


0	  As a classic statistical model of 3D facial shape and albedo, 3D Morphable Model (3DMM) is widely used in facial analysis, e.g., model fitting, image synthesis.
0	  Conventional 3DMM is learned from a set of well-controlled 2D face images with associated 3D face scans, and represented by two sets of PCA basis functions.
0	  Due to the type and amount of training data, as well as, the linear bases, the representation power of 3DMM can be limited.
1	  To address these problems, this paper proposes an innovative framework to learn a nonlinear 3DMM model from a large set of unconstrained face images, without collecting 3D face scans.
1	  Specifically, given a face image as input, a network encoder estimates the projection, illumination, shape and albedo parameters.
1	  Two decoders serve as the nonlinear 3DMM to map from the shape and albedo parameters to the 3D shape and albedo, respectively.
1	  With the projection parameter, lighting, 3D shape, and albedo, a novel analytically-differentiable rendering layer is designed to reconstruct the original input face.
1	  The entire network is end-to-end trainable with only weak supervision.
2	  We demonstrate the superior representation power of our nonlinear 3DMM over its linear counterpart, and its contribution to face alignment and 3D reconstruction.


### 101
##### 10.1109/TPAMI.2019.2928294
#### Leader-based Multi-Scale Attention Deep Architecture for Person Re-identification


0	  Person Re-identification (re-id) aims to match people across non-overlapping camera views in a public space.
0	  It is a challenging problem because many people captured in surveillance videos often wear similar clothes.
0	  Consequently, the differences in their appearance are typically subtle and only detectable at the right locations and scales.
1	  In this paper, a deep re-id network is proposed consisting of two novel components: a multi-scale deep learning layer and a leader-based attention learning layer.
1	  With these components, our model is able to learn deep discriminative feature representations at different scales and automatically determine the optimal weightings for each scale when combining them.
1	  The importance of different spatial locations for extracting discriminative features is also learned explicitly via our leader-based attention module.
2	  Extensive experiments are carried out to demonstrate that the proposed model outperforms the state-of-the-art on a number of benchmarks, and has a better generalization ability under a domain generalization setting.


### 102
##### 10.1109/TPAMI.2019.2928296
#### DoubleFusion: Real-time Capture of Human Performances with Inner Body Shapes from a Single Depth Sensor


1	  We propose DoubleFusion, a new real-time system that combines volumetric non-rigid reconstruction with data-driven template fitting to simultaneously reconstruct detailed surface geometry, large non-rigid motion, and the optimized human body shape from a single depth camera.
1	  One of the key contributions of this method is a double-layer representation consisting of a complete parametric body model inside, and a gradually fused detailed surface outside.
2	  A pre-defined node graph on the body parameterizes the non-rigid deformations near the body, and a free-form dynamically changing graph parameterizes the outer surface layer far from the body, which allows more general reconstruction.
1	  We further propose a joint motion tracking method based on the double-layer representation to enable robust and fast motion tracking performance.
1	  Moreover, the inner parametric body is optimized online and forced to fit inside the outer surface layer as well as the live depth input.
2	  Overall, our method enables increasingly denoised, detailed and complete surface reconstructions, fast motion tracking performance and plausible inner body shape reconstruction in real-time.
2	  Experiments and comparisons show improved fast motion tracking and loop closure performance on more challenging scenarios.
2	  Two extended applications including body measurement and shape retargeting show the potential of our system in terms of practical use.


### 103
##### 10.1109/TPAMI.2019.2928540
#### Coherence Constrained Graph LSTM for Group Activity Recognition


0	  This work aims to address the group activity recognition problem by exploring human motion characteristics.
0	  Traditional methods hold that the motions of all persons contribute equally to the group activity, which suppresses the contributions of some relevant motions to the whole activity while overstates some irrelevant motions.
1	  To handle this problem, we present a Spatio-Temporal Context Coherence (STCC) constraint and a Global Context Coherence (GCC) constraint to capture the relevant motions and quantify their contributions to the group activity, respectively.
1	  Based on this, we propose a novel Coherence Constrained Graph LSTM (CCG-LSTM) with STCC and GCC to effectively recognize group activity, by modeling the relevant motions of individuals while suppressing the irrelevant motions.
1	  Specifically, to capture the relevant motions, we build the CCG-LSTM with a temporal confidence gate and a spatial confidence gate to control the memory state updating in terms of the temporally previous state and the spatially neighboring states, respectively.
1	  Besides, an attention mechanism is employed to quantify the contribution of a certain motion by measuring the consistency between itself and the whole activity at each time step.
2	  Finally, we conduct experiments on two widely-used datasets to illustrate the effectiveness of the proposed CCG-LSTM compared with the state-of-the-arts methods.


### 104
##### 10.1109/TPAMI.2019.2926728
#### Joint Task-Recursive Learning for RGB-D Scene Understanding


0	  RGB-D scene understanding under monocular camera is an emerging and challenging topic with many potential applications.
1	  In this paper, we propose a novel Task-Recursive Learning (TRL) framework to jointly and recurrently conduct three representative tasks therein containing depth estimation, surface normal prediction and semantic segmentation.
1	  TRL recursively refines the prediction results through a series of task-level interactions, where one-time cross-task interaction is abstracted as one network block of one time stage.
1	  In each stage, we serialize multiple tasks into a sequence and then recursively perform their interactions.
1	  To adaptively enhance counterpart patterns, we encapsulate interactions into a specific Task-Attentional Module (TAM) to mutually-boost the tasks from each other.
1	  Across stages, the historical experiences of previous states of tasks are selectively propagated into the next stages by using Feature-Selection unit (FS-Unit), which takes advantage of complementary information across tasks.
2	  The sequence of task-level interactions are also evolved along a coarse-to-fine scale space such that the required details may be refined progressively.
2	  Finally the task-abstracted sequence problem of multi-task prediction is framed into a recursive network.
2	  Extensive experiments on NYU-Depth v2 and SUN RGB-D datasets demonstrate that our method can recursively refines the results of the triple tasks and achieves state-of-the-art performance.


### 105
##### 10.1109/TPAMI.2019.2927909
#### A Microfacet-based Model for Photometric Stereo with General Isotropic Reflectance


1	  This paper presents a precise, stable, and invertible reflectance model for photometric stereo.
1	  This microfacet-based model is applicable to all types of isotropic surface reflectance, covering cases from diffusion to specular reflections.
1	  We introduce a single variable to physically quantify the surface smoothness, and by monotonically sliding this variable between 0 and 1, our model enables a versatile representation that can smoothly transform between an ellipsoid of revolution and the equation for Lambertian reflectance.
1	  In the inverse domain, this model offers a compact and physically interpretable formulation, for which we introduce a fast and lightweight solver that allows accurate estimations for both surface smoothness and surface shape.
2	  Finally, extensive experiments on the appearances of synthesized and real objects evidence that this model is state-of-the-art in our off-the-shelf solution.


### 106
##### 10.1109/TPAMI.2019.2927476
#### Recipe1M+: A Dataset for Learning Cross-Modal Embeddings for Cooking Recipes and Food Images


1	  In this paper, we introduce Recipe1M+, a new large-scale, structured corpus of over one million cooking recipes and 13 million food images.
1	  As the largest publicly available collection of recipe data, Recipe1M+ affords the ability to train high-capacity models on aligned, multi-modal data.
1	  Using these data, we train a neural network to learn a joint embedding of recipes and images that yields impressive results on an image-recipe retrieval task.
2	  Moreover, we demonstrate that regularization via the addition of a high-level classification objective both improves retrieval performance to rival that of humans and enables semantic vector arithmetic.
2	  We postulate that these embeddings will provide a basis for further exploration of the Recipe1M+ dataset and food and cooking in general.
#	  Code, data and models are publicly available.


### 107
##### 10.1109/TPAMI.2019.2927311
#### Blind Deblurring of Barcodes via Kullback-Leibler Divergence


0	  Barcode encoding schemes impose symbolic constraints which fix certain segments of the image.
1	  We present, implement, and assess a method for blind deblurring and denoising based entirely on Kullback-Leibler divergence.
1	  The method is designed to incorporate and exploit the full strength of barcode symbologies.
1	  Via both standard barcode reading software and smartphone apps, we demonstrate the remarkable ability of our method to blindly recover simulated images of highly blurred and noisy barcodes.
2	  As proof of concept, we present one application on a real-life out of focus camera image.


### 108
##### 10.1109/TPAMI.2019.2927203
#### Relative Saliency and Ranking: Models, Metrics, Data and Benchmarks


0	  Salient object detection is a problem that has been considered in detail and many solutions have been proposed.
0	  In this paper, we argue that work to date has addressed a problem that is relatively ill-posed.
0	  Specifically, there is not universal agreement about what constitutes a salient object when multiple observers are queried.
0	  This implies that some objects are more likely to be judged salient than others, and implies a relative rank exists on salient objects.
1	  Initially, we present a novel deep learning solution based on a hierarchical representation of relative saliency and stage-wise refinement.
1	  Further to this, we present data, analysis and baseline benchmark results towards addressing the problem of salient object ranking.
1	  Methods for deriving suitable ranked salient object instances are presented, along with metrics suitable to measuring algorithm performance.
1	  In addition, we show how a derived dataset can be successively refined to provide cleaned results that correlate well with pristine ground truth in its characteristics and value for training and testing models.
2	  Finally, we provide a comparison among prevailing algorithms that address salient object ranking or detection to establish initial baselines providing a basis for comparison with future efforts addressing this problem.
2	  The source code and data are publicly available via our project page: ryersonvisionlab.github.io/cocosalrank


### 109
##### 10.1109/TPAMI.2019.2926266
#### Variational Context: Exploiting Visual and Textual Context for Grounding Referring Expressions


0	  We focus on grounding (i.e., localizing or linking) referring expressions in images, e.g., "largest elephant standing behind baby elephant".
0	  This is a general yet challenging vision-language task since it does not only require the localization of objects, but also the multimodal comprehension of context - visual attributes (e.g., "largest", "baby") and relationships (e.g., "behind") that help to distinguish the referent from other objects, especially those of the same category.
0	  Due to the exponential complexity involved in modeling the context associated with multiple image regions, existing work oversimplifies this task to pairwise region modeling by multiple instance learning.
1	  In this paper, we propose a variational Bayesian method, called Variational Context, to solve the problem of complex context modeling in referring expression grounding.
1	  Our model exploits the reciprocal relation between the referent and context, i.e., either of them influences estimation of the posterior distribution of the other, and thereby the search space of context can be greatly reduced.
2	  In addition, our proposed Variational Context framework can automatically unify both referring expression comprehension and generation.Context-aware referring exrepssion generation helps to evaluate the estimated context and punish false gounding results in the unified framework.


### 110
##### 10.1109/TPAMI.2019.2926459
#### Local LDA: Open-Ended Learning of Latent Topics for 3D Object Recognition


0	  Service robots are expected to be more autonomous and work effectively in human-centric environments.
0	  This implies that robots should have special capabilities, such as learning from past experiences and real-time object category recognition.
1	  This paper proposes an open-ended 3D object recognition system which concurrently learns both the object categories and the statistical features for encoding objects.
1	  In particular, we propose an extension of Latent Dirichlet Allocation to learn structural semantic features (i.e. visual topics), from low-level feature co-occurrences, for each category independently.
1	  Moreover, topics in each category are discovered in an unsupervised fashion and are updated incrementally using new object views.
1	  In this way, the advantages of both the (hand-crafted) local features and the (learned) structural semantic features have been considered and combined in an efficient way.
2	  An extensive set of experiments has been performed to assess the performance of the proposed Local-LDA in terms of descriptiveness, scalability, and computation time.
2	  Experimental results show that the overall classification performance obtained with Local-LDA is clearly better than the best performances obtained with the state-of-the-art approaches.
2	  Moreover, the best scalability, in terms of number of learned categories, was obtained with the proposed Local-LDA approach, closely followed by a Bag-of-Words (BoW) approach.


### 111
##### 10.1109/TPAMI.2019.2926463
#### The ApolloScape Open Dataset for Autonomous Driving and its Application


0	  Autonomous driving has attracted tremendous attention especially in the past few years.
0	  The key techniques for a self-driving car include solving tasks like 3D map construction, self-localization, parsing the driving road and understanding objects, which enable vehicles to reason and act.
0	  However, large scale data set for training and system evaluation is still a bottleneck for developing robust perception models.
1	  In this paper, we present the ApolloScape dataset [1] and its applications for autonomous driving.
1	  Compared with existing public datasets from real scenes, e.g., KITTI [2] or Cityscapes [3], ApolloScape contains much large and richer labelling including holistic semantic dense point cloud for each site, stereo, per-pixel semantic labelling, lanemark labelling, instance segmentation, 3D car instance, high accurate location for every frame in various driving videos from multiple sites, cities and daytimes.
1	  For each task, it contains at lease 15x larger amount of images than SOTA datasets.
1	  To label such a complete dataset, we develop various tools and algorithms specified for each task to accelerate the labelling process, such as joint 3D-2D segment labeling, active labelling in videos etc.
1	  Depend on ApolloScape, we are able to develop algorithms jointly consider the learning and inference of multiple tasks.
1	  In this paper, we provide a sensor fusion scheme integrating camera videos, consumer-grade motion sensors (GPS/IMU), and a 3D semantic map in order to achieve robust self-localization and semantic segmentation for autonomous driving.
2	  We show that practically, sensor fusion and joint learning of multiple tasks are beneficial to achieve a more robust and accurate system.
2	  We expect our dataset and proposed relevant algorithms can support and motivate researchers for further development of multi-sensor fusion and multi-task learning in the field of computer vision.


### 112
##### 10.1109/TPAMI.2019.2926357
#### Simultaneous Fidelity and Regularization Learning for Image Restoration


0	  Most existing non-blind restoration methods are based on the assumption that a precise degradation model is known.
0	  As the degradation process can only partially known or inaccurately modeled, images may not be well restored.
0	  For rain streak removal, although an input image can be decomposed into a scene layer and a rain streak layer, there exists no explicit formulation for modeling rain streaks and the composition with scene layer.
0	  For blind deconvolution, as estimation error of blur kernel is usually introduced, the subsequent non-blind deconvolution process does not restore the latent image well.
1	  We propose a principled algorithm within the maximum a posterior framework to tackle image restoration with a partially known or inaccurate degradation model.
1	  The residual caused by a partially known or inaccurate degradation model is spatially dependent and complexly distributed.
1	  With a training set of degraded and ground-truth image pairs, we parameterize and learn the fidelity term for a degradation model in a task-driven manner.
1	  The regularization term can also be learned along with the fidelity term, thereby forming a simultaneous fidelity and regularization learning model.
2	  Extensive experimental results demonstrate the effectiveness of the proposed model for image deconvolution with inaccurate blur kernels and rain streak removal.


### 113
##### 10.1109/TPAMI.2019.2926033
#### Community Detection Using Restrained Random-walk Similarity


1	  In this paper, we propose a restrained random-walk similarity method for detecting the community structures of graphs.
1	  The basic premise of our method is that the starting vertices of finite-length random walks are judged to be in the same community if the walkers pass similar sets of vertices.
1	  This idea is based on our consideration that a random walker tends to move in the community including the walker's starting vertex for some time after starting the walk.
1	  Therefore, the sets of vertices passed by random walkers starting from vertices in the same community must be similar.
1	  The idea is reinforced with two conditions.
1	  First, we exclude abnormal random walks.
1	  Random walks that depart from each vertex are executed many times, and vertices that are rarely passed by the walkers are excluded from the set of vertices that the walkers may pass.
1	  Second, we forcibly restrain random walks to an appropriate length.
1	  In our method, a random walk is terminated when the walker repeatedly visits vertices that they have already passed.
2	  Experiments on real-world networks demonstrate that our method outperforms previous techniques in terms of accuracy.


### 114
##### 10.1109/TPAMI.2019.2919824
#### Providing a Single Ground-truth for Illuminant Estimation for the ColorChecker Dataset


0	  The ColorChecker dataset is one of the most widely used image sets for evaluating and ranking illuminant estimation algorithms.
0	  However, this single set of images has at least 3 different sets of ground-truth (i.e.  correct answers) associated with it.
0	  In the literature it is often asserted that one algorithm is better than another when the algorithms in question have been tuned and tested with the different ground-truths.
1	  In this short correspondence we present some of the background as to why the 3 existing ground-truths are different and go on to make a new single and recommended set of correct answers.
2	  Experiments reinforce the importance of this work in that we show that the total ordering of a set of algorithms may be reversed depending on whether we use the new or legacy ground-truth data.


### 115
##### 10.1109/TPAMI.2019.2925793
#### A General Decoupled Learning Framework for Parameterized Image Operators


0	  Many different deep networks have been used to approximate, accelerate or improve traditional image operators.
0	  Among these traditional operators, many contain parameters which need to be tweaked to obtain the satisfactory results, which we refer to as "parameterized image operators".
0	  However, most existing deep networks trained for these operators are only designed for one specific parameter configuration, which does not meet the needs of real scenarios that usually require flexible parameters settings.
1	  To overcome this limitation, we propose a new decoupled learning algorithm to learn from the operator parameters to dynamically adjust the weights of a deep network for image operators, denoted as the base network.
1	  The learned algorithm is formed as another network, namely the weight learning network, which can be end-to-end jointly trained with the base network.
2	  Experiments demonstrate that the proposed framework can be successfully applied to many traditional parameterized image operators.
1	  To accelerate the parameter tuning for practical scenarios, the proposed framework can be further extended to dynamically change the weights of only one single layer of the base network while sharing most computation cost.
2	  We demonstrate that this cheap parameter-tuning extension of the proposed decoupled learning framework even outperforms the state-of-the-art alternative approaches.


### 116
##### 10.1109/TPAMI.2019.2924953
#### Border-Peeling Clustering


1	  In this paper, we present a novel non-parametric clustering technique.
1	  Our technique is based on the notion that each latent cluster is comprised of layers that surround its core, where the external layers, or border points, implicitly separate the clusters.
1	  Unlike previous techniques, such as DBSCAN, where the cores of the clusters are defined directly by their densities, here the latent cores are revealed by a progressive peeling of the border points.
1	  Analyzing the density of the local neighborhoods allows identifying the border points and associating them with points of inner layers.
2	  We show that the peeling process adapts to the local densities and characteristics to successfully separates adjacent clusters (of possibly different densities).
1	  We extensively tested our technique on large sets of labeled data, including high-dimensional datasets of deep features that were trained by a convolutional neural network.
2	  We show that our technique is competitive to other state-of-the-art non-parametric methods, using a fixed set of parameters throughout the experiments.


### 117
##### 10.1109/TPAMI.2019.2925347
#### Asymmetric Mapping Quantization for Nearest Neighbor Search


0	  Nearest neighbor search is a fundamental problem in computer vision and machine learning.
0	  The straightforward solution, linear scan, is both computationally and memory intensive in large scale high-dimensional cases, hence is not preferable in practice.
0	  Therefore, there have been a lot of interests in algorithms that perform approximate nearest neighbor (ANN) search.
1	  In this paper, we propose a novel addition-based vector quantization algorithm, Asymmetric Mapping Quantization (AMQ), to efficiently conduct ANN search.
1	  Unlike existing addition-based quantization methods that suffer from handling the problem caused by the norm of database vector, we map the query vector and database vector using different mapping functions to transform the computation of L-2 distance to inner product similarity, thus do not need to evaluate the norm of database vector.
1	  Moreover, we further propose Distributed Asymmetric Mapping Quantization (DAMQ) to enable AMQ to work on very large dataset by distributed learning.
2	  Extensive experiments on approximate nearest neighbor search and image retrieval validate the merits of the proposed AMQ and DAMQ.


### 118
##### 10.1109/TPAMI.2019.2924417
#### Revisiting Video Saliency Prediction in the Deep Learning Era


0	  Predicting where people look in static scenes, a.k.a visual saliency, has received significant research interests recently.
0	  However, relatively less effort has been spent in understanding visual attention over dynamic scenes.
0	  This work makes three contributions to video saliency research.
1	  First, we introduce a new benchmark, called DHF1K, for predicting fixations during dynamic scene free-viewing, which is a long-time need in this field.
1	  DHF1K consists of 1K high-quality, elaborately selected videos annotated by 17 observers using an eye tracker.
1	  The videos span a wide range of scenes, motions, object types and backgrounds.
1	  Second, we propose a novel video saliency model, called ACLNet, that augments the CNN-LSTM network with a supervised attention mechanism to enable fast end-to-end learning.
1	  The attention mechanism explicitly encodes static saliency information, thus allowing LSTM to focus on learning a more flexible temporal saliency representation.
1	  Such a design leverages existing large-scale static fixation datasets, avoids overfitting, and significantly improves training efficiency and testing performance.
1	  Third, we perform an extensive evaluation of state-of-the-art saliency models on three current datasets (i.e., DHF1K, Hollywood2, UCF sports).
2	  Experimental results over more than 1.2K testing videos containing 400K frames demonstrate that ACLNet outperforms other contenders and has a fast processing speed (40fps).


### 119
##### 10.1109/TPAMI.2019.2924428
#### A Framework of Composite Functional Gradient Methods for Generative Adversarial Models


0	  Generative adversarial networks (GAN) are trained through a minimax game between a generator and a discriminator to generate data that mimics observations.
0	  While being widely used, GAN training is known to be empirically unstable.
1	  This paper presents a new theory for generative adversarial methods that does not rely on the traditional minimax formulation.
1	  Our theory shows that with a strong discriminator, a good generator can be obtained by composite functional gradient learning, so that several distance measures (including the KL divergence and the JS divergence) between the probability distributions of real data and generated data are simultaneously improved after each functional gradient step until converging to zero.
2	  This new point of view leads to stable procedures for training generative models.
2	  It also gives a new theoretical insight into the original GAN.
2	  Empirical results on image generation show the effectiveness of our new method.


### 120
##### 10.1109/TPAMI.2019.2923998
#### Ranking-Preserving Cross-Source Learning for Image Retargeting Quality Assessment


0	  Image retargeting techniques adjust images into different sizes and have attracted much attention recently.
0	  Objective quality assessment (OQA) of image retargeting results is often desired to automatically select the best results.
0	  Existing OQA methods train a model using some benchmarks (e.g., RetargetMe), in which subjective scores evaluated by users are provided.
1	  Observing that it is challenging even for human subjects to give consistent scores for retargeting results of different source images (diff-source-results), in this paper we propose a learning-based OQA method that trains a General Regression Neural Network (GRNN) model based on relative scores --- which preserve the ranking --- of retargeting results of the same source image (same-source-results).
1	  In particular, we develop a novel training scheme with provable convergence that learns a common base scalar for same-source-results.
1	  With this source specific offset, our computed scores not only preserve the ranking of subjective scores for same-source-results, but also provide a reference to compare the diff-source-results.
1	  We train and evaluate our GRNN model using human preference data collected in RetargetMe.
1	  Moreover, we introduce a further subjective benchmark to evaluate the generalizability of different OQA methods.
2	  Experimental results demonstrate that our method outperforms ten representative OQA methods in ranking prediction.


### 121
##### 10.1109/TPAMI.2019.2923240
#### Bayesian Low-Tubal-Rank Robust Tensor Factorization with Multi-Rank Determination


0	  Robust tensor factorization is a fundamental problem in machine learning and computer vision, which aims at recovering tensors corrupted with outliers as a sum of the low-rank and sparse components.
0	  However, existing methods either suffer from limited modeling power in preserving low-rank structures, or have difficulties in determining the target tensor rank and the trade-off between the low-rank and sparse components.
1	  To address these problems, we propose a fully Bayesian treatment of robust tensor factorization along with a generalized sparsity-inducing prior.
1	  By adapting the recently proposed low-tubal-rank model in a generative manner, our method is effective in preserving low-rank structures.
1	  Moreover, benefiting from the proposed prior and the Bayesian framework, the proposed method can automatically determine the tensor rank while inferring the trade-off between the low-rank and sparse components.
1	  For model estimation, we develop a variational inference algorithm, and further improve its efficiency by reformulating the variational updates in the frequency domain.
2	  Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of the proposed method in multi-rank determination as well as its superiority in image denoising and background modeling over state-of-the-art approaches.


### 122
##### 10.1109/TPAMI.2019.2923513
#### Zig-Zag Network for Semantic Segmentation of RGB-D Images


0	  Semantic segmentation of images requires an understanding of appearances of objects and their spatial relationships in scenes.
0	  The fully convolutional network (FCN) has been successfully applied to recognize objects' appearances, which are represented with RGB channels.
0	  Images augmented with depth channels provide more understanding of the geometric information of the scene in an image.
1	  In this paper, we present a multiple-branch neural network to utilize depth information to assist in the semantic segmentation of images.
1	  Our approach splits the image into layers according to the "scene-scale".
1	  We introduce the context-aware receptive field (CARF), which provides better control of the relevant context information of learned features.
1	  Each branch of the network is equipped with CARF to adaptively aggregate the context information of image regions, leading to a more focused domain that is easier to learn.
1	  Furthermore, we propose a new zig-zag architecture to exchange information between the feature maps at different levels, augmented by the CARFs of the backbone network and decoder network.
1	  With the flexible information propagation allowed by our zig-zag network, we enrich the context information of feature maps for the segmentation.
2	  We show that the zig-zag network achieves state-of-the-art performances on several public datasets.


### 123
##### 10.1109/TPAMI.2019.2923621
#### Photometric Depth Super-Resolution


1	  This study explores the use of photometric techniques (shape-from-shading and uncalibrated photometric stereo) for upsampling the low-resolution depth map from an RGB-D sensor to the higher resolution of the companion RGB image.
1	  A single-shot variational approach is first put forward, which is effective as long as the target's reflectance is piecewise-constant.
1	  It is then shown that this dependency upon a specific reflectance model can be relaxed by focusing on a specific class of objects (e.g., faces), and delegate reflectance estimation to a deep neural network.
2	  A multi-shot strategy based on randomly varying lighting conditions is eventually discussed.
2	  It requires no training or prior on the reflectance, yet this comes at the price of a dedicated acquisition setup.
2	  Both quantitative and qualitative evaluations illustrate the effectiveness of the proposed methods on synthetic and real-world scenarios.


### 124
##### 10.1109/TPAMI.2019.2923201
#### Clouds of Oriented Gradients for 3D Detection of Objects, Surfaces, and Indoor Scene Layouts


0	  We develop new representations and algorithms for three-dimensional (3D) object detection and spatial layout prediction in cluttered indoor scenes.
1	  We first propose a clouds of oriented gradient (COG) descriptor that links the 2D appearance and 3D pose of object categories, and thus accurately models how perspective projection affects perceived image gradients.
1	  To better represent the 3D visual styles of large objects and provide contextual cues to improve the detection of small objects, we introduce latent support surfaces.
1	  We then propose a "Manhattan voxel" representation which better captures the 3D room layout geometry of common indoor environments.
1	  Effective classification rules are learned via a latent structured prediction framework.
2	  Contextual relationships among categories and layout are captured via a cascade of classifiers, leading to holistic scene hypotheses that exceed the state-of-the-art on the SUN RGB-D database.


### 125
##### 10.1109/TPAMI.2019.2922640
#### RotationNet for Joint Object Categorization and Unsupervised Pose Estimation from Multi-view Images


1	  We propose a Convolutional Neural Network (CNN)-based model "RotationNet," which takes multi-view images of an object as input and jointly estimates its pose and object category.
1	  Unlike previous approaches that use known viewpoint labels for training, our method treats the viewpoint labels as latent variables, which are learned in an unsupervised manner during the training using an unaligned object dataset.
1	  RotationNet uses only a partial set of multi-view images for inference, and this property makes it useful in practical scenarios where only partial views are available.
1	  Moreover, our pose alignment strategy enables one to obtain view-specific feature representations shared across classes, which is important to maintain high accuracy in both object categorization and pose estimation.
2	  Effectiveness of RotationNet is demonstrated by its superior performance to the state-of-the-art methods of 3D object classification on 10- and 40-class ModelNet datasets.
2	  We also show that RotationNet, even trained without known poses, achieves comparable performance to the state-of-the-art methods on an object pose estimation dataset.
2	  Furthermore, our object ranking method based on classification by RotationNet achieved the first prize in two tracks of the 3D Shape Retrieval Contest (SHREC) 2017.
2	  Finally, we demonstrate the performance of real-world applications of RotationNet trained with our newly created multi-view image dataset using a moving USB camera.


### 126
##### 10.1109/TPAMI.2019.2922959
#### One shot segmentation: unifying rigid detection and non-rigid segmentation using elastic regularization


0	  This paper proposes a novel approach for the non-rigid segmentation of deformable objects in image sequences, which is based on one-shot segmentation that unifies rigid detection and non-rigid segmentation using elastic regularization.
0	  The domain of application is the segmentation of a visual object that temporally undergoes a rigid transformation (e.g., affine transformation) and a non-rigid transformation (i.e., contour deformation).
0	  The majority of segmentation approaches to solve this problem are generally based on two steps that run in sequence: a rigid detection, followed by a non-rigid segmentation.
1	  In this paper, we propose a new approach, where both the rigid and non-rigid segmentation are performed in a single shot using a sparse low-dimensional manifold that represents the visual object deformations.
1	  Given the multi-modality of these deformations, the manifold partitions the training data into several patches, where each patch provides a segmentation proposal during the inference process.
1	  These multiple segmentation proposals are merged using the classification results produced by deep belief networks (DBN) that compute the confidence on each segmentation proposal.
1	  Thus, an ensemble of DBN classifiers is used for estimating the final segmentation.
2	  Compared to current methods proposed in the field, our proposed approach is advantageous in four aspects: 
2	  (i) it is a unified framework to produce rigid and non-rigid segmentations; 
2	  (ii) it uses an ensemble classification process, which can help the segmentation robustness; 
2	  (iii) it provides a significant reduction in terms of the number of dimensions of the rigid and non-rigid segmentations search spaces, compared to current approaches that divide these two problems; and 
2	  (iv) this lower dimensionality of the search space can also reduce the need for large annotated training sets to be used for estimating the DBN models.
2	  Experiments on the problem of left ventricle endocardial segmentation from ultrasound images, and lip segmentation from frontal facial images using the extended Cohn-Kanade (CK+) database, demonstrate the potential of the methodology through qualitative and quantitative evaluations, and the ability to reduce the search and training complexities without a significant impact on the segmentation accuracy.


### 127
##### 10.1109/TPAMI.2019.2922396
#### Towards Safe Weakly Supervised Learning


0	  In this paper, we study weakly supervised learning where a large amount of label information is not accessible.
0	  This includes incomplete supervision such as semi-supervised learning and domain adaptation; inexact supervision, such as multi-instance learning and inaccurate supervision, such as label noise learning.
0	  Unlike supervised learning, weakly supervised learning, however, may sometimes even degenerate performance.
0	  Such deficiency definitely hinders the deployment of weakly supervised learning to real applications.
0	  For this reason, it is desired to study safe weakly supervised learning.
1	  In this paper we present a generic ensemble learning scheme to derive the safe prediction.
1	  We consider optimizing the worst-case performance gain which leads to a maximin optimization.
2	  Our resultant formulation brings multiple advantages.
2	  Firstly, for many commonly used convex loss functions in classification and regression tasks, our formulation is guaranteed to derive a safe prediction under a mild condition.
2	  Secondly, prior knowledge related to the weight of the base weakly supervised learners can be flexibly embedded.
2	  Thirdly, our formulation can be globally and efficiently addressed.
2	  Finally, it is in an intuitive geometric interpretation.
2	  Extensive experiments on multiple weakly supervised learning tasks clearly demonstrate the effectiveness of our proposal algorithms.


### 128
##### 10.1109/TPAMI.2019.2922175
#### Vocabulary-informed Zero-shot and Open-set Learning


0	  Despite significant progress in object categorization, in recent years, a number of important challenges remain; mainly, ability to learn from limited labeled data and ability to recognize object classes within large, potentially open, set of labels.
0	  Zero-shot learning is one way of addressing these challenges, but it has only been shown to work with limited sized class vocabularies and typically requires separation between supervised and unsupervised classes, allowing former to inform the latter but not vice versa.
1	  We propose the notion of vocabulary-informed learning to alleviate the above mentioned challenges and address problems of supervised, zero-shot, generalized zero-shot and open set recognition using a unified framework.
1	  Specifically, we propose a weighted maximum margin framework for semantic manifold-based recognition that incorporates distance constraints from (both supervised and unsupervised) vocabulary atoms.
1	  Distance constraints ensure that labeled samples are projected closer to their correct prototypes, in the embedding space, than to others.
2	  We illustrate that resulting model shows improvements in supervised, zero-shot, generalized zero-shot, and large open set recognition, with up to 310K class vocabulary on AwA and ImageNet datasets.


### 129
##### 10.1109/TPAMI.2019.2922181
#### Object Detection from Scratch with Deep Supervision


0	  We propose Deeply Supervised Object Detectors (DSOD), an object detection framework that can be trained from scratch.
0	  Recent advances in object detection heavily depend on the off-the-shelf models pre-trained on large-scale classification datasets like ImageNet and OpenImage.
0	  However, one problem is that adopting pre-trained models from classification to detection task may incur learning bias due to the different objective function and diverse distributions of object categories.
0	  Techniques like fine-tuning on detection task could alleviate this issue to some extent but are still not fundamental.
0	  Furthermore, transferring these pre-trained models cross discrepant domains will be more difficult (e.g., from RGB to depth images).
0	  Thus, a better solution to handle these critical problems is to train object detectors from scratch, which motivates our proposed method.
1	  In DSOD, we contribute a set of design principles for learning object detectors from scratch.
1	  One of the key principles is the deep supervision, enabled by layer-wise dense connections in both backbone networks and prediction layers, plays a critical role in learning good detectors from scratch.
2	  We evaluate our method on PASCAL VOC 2007, 2012 and COCO datasets.
2	  DSOD achieves consistently better results than the state-of-the-art methods with much more compact models.


### 130
##### 10.1109/TPAMI.2019.2921960
#### Semantic Fisher Scores for Task Transfer: Using Objects to Classify Scenes


1	  The tranfer of a neural network (CNN) trained to recognize objects to the task of scene classification is considered.
1	  A Bag-of-Semantics (BoS) representation is first induced, by feeding scene image patches to the object CNN, and representing the scene image by the ensuing bag of posterior class probability vectors (semantic posteriors).
1	  The encoding of the BoS with a Fisher vector (FV) is then studied.
1	  A link is established between the FV of any probabilistic model and the Q-function of the expectation-maximization (EM) algorithm used to estimate its parameters by maximum likelihood.
1	  This enables 1) imediate derivation of FVs for any model for which an EM algorithm exists, and 2) leveraging efficient implementations from the EM literature for the computation of FVs.
2	  It is then shown that standard FVs, such as those derived from Gaussian or even Dirichelet mixtures, are unsuccessful for the transfer of semantic posteriors, due to the highly non-linear nature of the probability simplex.
2	  The analysis of these FVs shows that significant benefits can ensue by 1) designing FVs in the natural parameter space of the multinomial distribution, and 2) adopting sophisticated probabilistic models of semantic feature covariance.
2	  The combination of these two insights leads to the encoding of the BoS in the natural parameter space of the multinomial, using a vector of Fisher scores derived from a mixture of factor analyzers (MFA).
1	  A network implementation of the MFA Fisher Score (MFA-FS), denoted as the MFAFSNet, is finally proposed to enable end-to-end training.
2	  Experiments with various object CNNs and datasets show that the approach has state-of-the-art transfer performance.
2	  Somewhat surprisingly, the scene classification results are superior to those of a CNN explicitly trained for scene classification, using a large scene dataset (Places).
2	  This suggests that holistic analysis is insufficient for scene classification.
2	  The modeling of local object semantics appears to be at least equally important.
2	  The two approaches are also shown to be strongly complementary, leading to very large scene classification gains when combined, and outperforming all previous scene classification approaches by a sizeable margin.


### 131
##### 10.1109/TPAMI.2019.2921539
#### Two-Stream Region Convolutional 3D Network for Temporal Activity Detection


0	  We address the problem of temporal activity detection in continuous, untrimmed video streams.
0	  This is a difficult task that requires extracting meaningful spatio-temporal features to capture activities, accurately localizing the start and end times of each activity.
1	  We introduce a new model, Region Convolutional 3D Network (R-C3D), which encodes the video streams using a three-dimensional fully convolutional network, then generates candidate temporal regions containing activities and finally classifies selected regions into specific activities.
1	  Computation is saved due to the sharing of convolutional features between the proposal and the classification pipelines.
1	  We further improve the detection performance by efficiently integrating an optical flow based motion stream with the original RGB stream.
1	  The two-stream network is jointly optimized by fusing the flow and RGB feature maps at different levels.
1	  Additionally, the training stage incorporates an online hard example mining strategy to address the extreme foreground-background imbalance typically observed in any detection pipeline.
1	  Instead of heuristically sampling the candidate segments for the final activity classification stage, we rank them according to their performance and only select the worst performers to update the model.
1	  This improves the model without heavy hyper-parameter tuning.
2	  Extensive experiments on three benchmark datasets are carried out to show superior performance over existing temporal activity detection methods.
2	  Our model achieves state-of-the-art results on the THUMOS'14 and Charades datasets.
2	  We further demonstrate that our model is a general temporal activity detection framework that does not rely on assumptions about particular dataset properties by evaluating our approach on the ActivityNet dataset.


### 132
##### 10.1109/TPAMI.2019.2921548
#### Real-world Image Denoising with Deep Boosting


1	  We propose a Deep Boosting Framework (DBF) for real-world image denoising by integrating the deep learning technique into the boosting algorithm.
1	  The DBF replaces conventional handcrafted boosting units by elaborate convolutional neural networks, which brings notable advantages in terms of both performance and speed.
1	  We design a lightweight Dense Dilated Fusion Network (DDFN) as an embodiment of the boosting unit, which addresses the vanishing of gradients during training due to the cascading of networks while promoting the efficiency of limited parameters.
1	  The capabilities of the proposed method are first validated on several representative simulation tasks including non-blind and blind Gaussian denoising and JPEG image deblocking.
1	  We then focus on a practical scenario to tackle with the complex and challenging real-world noise.
1	  To facilitate leaning-based methods including ours, we build a new Real-world Image Denoising (RID) dataset, which contains 200 pairs of high-resolution images with diverse scene content under various shooting conditions.
1	  Moreover, we conduct comprehensive analysis on the domain shift issue for real-world denoising and propose an effective one-shot domain transfer scheme to address this issue.
2	  Comprehensive experiments on widely used benchmarks demonstrate that the proposed method significantly surpasses existing methods on the task of real-world image denoising.


### 133
##### 10.1109/TPAMI.2019.2921543
#### Guided Attention Inference Network


0	  With only coarse labels, weakly supervised learning typically uses top-down attention maps generated by back-propagating gradients as priors for tasks such as object localization and semantic segmentation.
0	  While these attention maps are intuitive and informative explanations of deep neural network, there is no effective mechanism to manipulate the network attention during learning process.
1	  In this paper, we address three shortcomings of previous approaches in modeling such attention maps in one common framework.
1	  First, we make attention maps a natural and explicit component in the training pipeline such that they are end-to-end trainable.
1	  Moreover, we provide self-guidance directly on these maps by exploring supervision from the network itself to improve them towards specific target tasks.
1	  Lastly, we proposed a design to seamlessly bridge the gap between using weak and extra supervision if available.
2	  Despite its simplicity, experiments on the semantic segmentation task demonstrate the effectiveness of our methods.
2	  Besides, the proposed framework provides a way not only explaining the focus of the learner but also feeding back with direct guidance towards specific tasks.
2	  Under mild assumptions our method can also be understood as a plug-in to existing convolutional neural networks to improve their generalization performance.


### 134
##### 10.1109/TPAMI.2019.2921574
#### CoRRN: Cooperative Reflection Removal Network


0	  Removing the undesired reflections from images taken through the glass is of broad application to various computer vision tasks.
0	  Non-learning based methods utilize different handcrafted priors such as the separable sparse gradients caused by different levels of blurs, which often fail due to their limited description capability to the properties of real-world reflections.
1	  In this paper, we propose a network with the feature-sharing strategy to tackle this problem in a cooperative and unified framework, by integrating image context information and the multi-scale gradient information.
1	  To remove the strong reflections existed in some local regions, we propose a statistic loss by considering the gradient level statistics between the background and reflections.
1	  Our network is trained on a new dataset with 3250 reflection images taken under diverse real-world scenes.
2	  Experiments on a public benchmark dataset show that the proposed method performs favorably against state-of-the-art methods.


### 135
##### 10.1109/TPAMI.2019.2921327
#### Joint Segmentation and Path Classification of Curvilinear Structures


0	  Detection of curvilinear structures in images has long been of interest.
0	  One of the most challenging aspects of this problem is inferring the graph representation of the curvilinear network.
0	  Most existing delineation approaches first perform binary segmentation of the image and then refine it using either a set of hand-designed heuristics or a separate classifier that assigns likelihood to paths extracted from the pixel-wise prediction.
1	  In our work, we bridge the gap between segmentation and path classification by training a deep network that performs those two tasks simultaneously.
2	  We show that this approach is beneficial because it enforces consistency across the whole processing pipeline.
1	  We apply our approach on roads and neurons datasets.


### 136
##### 10.1109/TPAMI.2019.2917908
#### Learning and Tracking the 3D Body Shape of Freely Moving Infants from RGB-D sequences


0	  Statistical models of the human body surface are generally learned from thousands of high-quality 3D scans in predefined poses to cover the wide variety of human body shapes and articulations.
0	  Acquisition of such data requires expensive equipment, calibration procedures, and is limited to cooperative subjects who can understand and follow instructions, such as adults.
1	  We present a method for learning a statistical 3D Skinned Multi-Infant Linear body model (SMIL) from incomplete, low-quality RGB-D sequences of freely moving infants.
1	  Quantitative experiments show that SMIL faithfully represents the RGB-D data and properly factorizes the shape and pose of the infants.
2	  To demonstrate the applicability of SMIL, we fit the model to RGB-D sequences of freely moving infants and show, with a case study, that our method captures enough motion detail for General Movements Assessment (GMA), a method used in clinical practice for early detection of neurodevelopmental disorders in infants.
2	  SMIL provides a new tool for analyzing infant shape and movement and is a step towards an automated system for GMA.


### 137
##### 10.1109/TPAMI.2019.2921031
#### Trace Quotient with Sparsity Priors for Learning Low Dimensional Image Representations


0	  This work studies the problem of learning appropriate low dimensional image representations.
1	  We propose a generic algorithmic framework, which leverages two classic representation learning paradigms, i.e., sparse representation and the trace quotient criterion, to disentangle underlying factors of variation in high dimensional images.
1	  Specifically, we aim to learn simple representations of low dimensional, discriminant factors by applying the trace quotient criterion to well-engineered sparse representations.
1	  We construct a unified cost function, coined as the SPARse LOW dimensional representation (SparLow) function, for jointly learning both a sparsifying dictionary and a dimensionality reduction transformation.
0	  The SparLow function is widely applicable for developing various algorithms in three classic machine learning scenarios, namely, unsupervised, supervised, and semi-supervised learning.
1	  In order to develop efficient joint learning algorithms for maximizing the SparLow function, we deploy a framework of sparse coding with appropriate convex priors to ensure the sparse representations to be locally differentiable.
1	  Moreover, we develop an efficient geometric conjugate gradient algorithm to maximize the SparLow function on its underlying Riemannian manifold.
2	  Performance of the proposed SparLow algorithmic framework is investigated on several image processing tasks, such as 3D data visualization, face/digit recognition, and object/scene categorization.


### 138
##### 10.1109/TPAMI.2019.2920899
#### Reconstruct and Represent Video Contents for Captioning via Reinforcement Learning


0	  In this paper, the problem of describing visual contents of a video sequence with natural language is addressed.
1	  Unlike previous video captioning work mainly exploiting the cues of video contents to make a description, we propose a reconstruction network (RecNet) in a novel encoder-decoder-reconstructor architecture, which leverages both forward (video to sentence) and backward (sentence to video) flows for video captioning.
1	  Specifically, the encoder-decoder component makes use of the forward flow to produce a sentence description based on the encoded video semantic features.
1	  Two types of reconstructors are subsequently proposed to employ backward flow and reproduce the video features from local and global perspectives, respectively, capitalizing on the hidden state sequence generated by the decoder.
1	  Moreover, in order to make a comprehensive reconstruction of the video features, we propose to fuse the two types of reconstructors together.
1	  The generation loss yielded by the encoder-decoder component and the reconstruction loss introduced by the reconstructor are jointly cast into training the proposed RecNet in an end-to-end fashion.
1	  Additionally, the RecNet is finetuned by CIDEr optimization via reinforcement learning, which significantly boosts the captioning performance.
2	  Experimental results on benchmark datasets demonstrate that the proposed reconstructor can boost the performance of video captioning consistently.


### 139
##### 10.1109/TPAMI.2019.2920821
#### Local Deformable 3D Reconstruction with Cartan's Connections


0	  3D reconstruction of deformable objects using inter-image visual motion from monocular images has been studied under Shape-from- Template (SfT) and Non-Rigid Structure-from-Motion (NRSfM).
0	  Most methods have been developed for simple deformation models, primarily isometry.
0	  They may treat a surface as a discrete set of points and draw constraints from the points only or they may use a non- parametric representation and use both points and differentials to express constraints.
1	  We propose a differential framework based on Cartan's theory of connections and moving frames.
1	  It is applicable to SfT and NRSfM, and to deformation models other than isometry.
1	  It utilises infinitesimal-level assumptions on the surface's geometry and mappings.
1	  It has the following properties.
1	  1) It allows one to derive existing solutions in a simpler way.
1	  2) It models SfT and NRSfM in a unified way.
1	  3) It allows us to introduce a new skewless deformation model and solve SfT and NRSfM for it.
1	  4) It facilitates a generic solution to SfT which does not require deformation modeling.
1	  Our framework is complete: it solves deformable 3D reconstruction for a whole class of algebraic deformation models including isometry.
2	  We compared our solutions with the state-of-the-art methods and show that ours outperform in terms of both accuracy and computation time.


### 140
##### 10.1109/TPAMI.2019.2920636
#### Gravitational Laws of Focus of Attention


0	  The understanding of the mechanisms behind focus of attention in a visual scene is a problem of great interest in visual perception and computer vision.
1	  In this paper, we describe a model of scanpath as a dynamic process which can be interpreted as a variational law somehow related to mechanics, where the focus of attention is subject to a gravitational field.
1	  The distributed virtual mass that drives eye movements is associated with the presence of details and motion in the video.
1	  Unlike most current models, the proposed approach does not estimate directly the saliency map, but the prediction of eye movements allows us to integrate over time the positions of interest.
1	  The process of inhibition-of-return is also supported in the same dynamic model with the purpose of simulating fixations and saccades.
1	  The differential equations of motion of the proposed model are numerically integrated to simulate scanpaths on both images and videos.
2	  Experimental results for the tasks of saliency and scanpath prediction on a wide collection of datasets are presented to support the theory.
2	  Top level performances are achieved especially in the prediction of scanpaths, which is the primary purpose of the proposed model.


### 141
##### 10.1109/TPAMI.2019.2920591
#### On the Convergence of Learning-based Iterative Methods for Nonconvex Inverse Problems


0	  Numerous tasks at the core of statistics, learning and vision areas are specific cases of ill-posed inverse problems.
0	  Recently, learning-based (e.g., deep) iterative methods have been empirically shown to be useful for these problems.
0	  Nevertheless, integrating learnable structures into iterations is still a laborious process, which can only be guided by intuitions or empirical insights.
0	  Moreover, there is a lack of rigorous analysis about the convergence behaviors of these reimplemented iterations, and thus the significance of such methods is a little bit vague.
1	  This paper moves beyond these limits and proposes Flexible Iterative Modularization Algorithm (FIMA), a generic and provable paradigm for nonconvex inverse problems.
2	  Our theoretical analysis reveals that FIMA allows us to generate globally convergent trajectories for learning-based iterative methods.
2	  Meanwhile, the devised scheduling policies on flexible modules should also be beneficial for classical numerical methods in the nonconvex scenario.
2	  Extensive experiments on real applications verify the superiority of FIMA.


### 142
##### 10.1109/TPAMI.2019.2919707
#### On the Robustness of Semantic Segmentation Models to Adversarial Attacks


0	  Deep Neural Networks (DNNs) have demonstrated exceptional performance on most recognition tasks such as image classification and segmentation.
0	  However, they have also been shown to be vulnerable to adversarial examples.
0	  This phenomenon has recently attracted a lot of attention but it has not been extensively studied on multiple, large-scale datasets and structured prediction tasks such as semantic segmentation which often require more specialised networks with additional components such as CRFs, dilated convolutions, skip-connections and multiscale processing.
1	  In this paper, we present what to our knowledge is the first rigorous evaluation of adversarial attacks on modern semantic segmentation models, using two large-scale datasets.
1	  We analyse the effect of different network architectures, model capacity and multiscale processing, and show that many observations made on the task of classification do not always transfer to this more complex task.
2	  Furthermore, we show how mean-field inference in deep structured models, multiscale processing (and more generally, input transformations) naturally implement recently proposed adversarial defenses.
2	  Our observations will aid future efforts in understanding and defending against adversarial examples.
2	  Moreover, in the shorter term, we show how to effectively benchmark robustness and show which segmentation models should currently be preferred in safety-critical applications due to their inherent robustness.


### 143
##### 10.1109/TPAMI.2019.2919597
#### MOSES: A Streaming Algorithm for Linear Dimensionality Reduction


1	  This paper introduces Memory-limited Online Sub- space Estimation Scheme (MOSES) for both estimating the principal components of streaming data and reducing its dimension.
1	  More specifically, in various applications such as sensor net- works, the data vectors are presented sequentially to a user who has limited storage and processing time available.
1	  Applied to such problems, MOSES can provide a running estimate of leading principal components of the data that has arrived so far and also reduce its dimension.
1	  MOSES generalises the popular incremental Singular Vale Decomposition (iSVD) to handle thin blocks of data, rather than just vectors.
1	  This minor generalisation in part allows us to complement MOSES with a comprehensive statistical analysis, thus providing the first theoretically-sound variant of iSVD, which has been lacking despite the empirical success of this method.
1	  This generalisation also enables us to concretely interpret MOSES as an approximate solver for the underlying non-convex optimisation program.
2	  We find that MOSES consistently surpasses the state of the art in our numerical experiments with both synthetic and real-world datasets, while being computationally inexpensive.


### 144
##### 10.1109/TPAMI.2019.2919616
#### Direction-aware Spatial Context Features for Shadow Detection and Removal


0	  Shadow detection and shadow removal are fundamental and challenging tasks, requiring an understanding of the global image semantics.
1	  This paper presents a novel deep neural network design for shadow detection and removal by analyzing the spatial image context in a direction-aware manner.
1	  To achieve this, we first formulate the direction-aware attention mechanism in a spatial recurrent neural network (RNN) by introducing attention weights when aggregating spatial context features in the RNN.
2	  By learning these weights through training, we can recover direction-aware spatial context (DSC) for detecting and removing shadows.
1	  This design is developed into the DSC module and embedded in a convolutional neural network to learn the DSC features at different levels.
1	  Moreover, we design a weighted cross entropy loss to make effective the training for shadow detection and further adopt the network for shadow removal by using a Euclidean loss function and formulating a color transfer function to address the color and luminosity inconsistencies in the training pairs.
1	  We employed two shadow detection benchmark datasets and two shadow removal benchmark datasets, and performed various experiments to evaluate our method.
2	  Experimental results show that our method performs favorably against the state-of-the-art methods for both shadow detection and shadow removal.


### 145
##### 10.1109/TPAMI.2019.2919301
#### DART: Distribution Aware Retinal Transform for Event-based Cameras


1	  We introduce a generic visual descriptor, termed as distribution aware retinal transform (DART), that encodes the structural context using log-polar grids for event cameras.
1	  The DART descriptor is applied to four different problems, namely object classification, tracking, detection and feature matching: 
1	  (1) The DART features are directly employed as local descriptors in a bag-of-words classification framework and testing is carried out on four standard event-based object datasets (N-MNIST, MNIST-DVS, CIFAR10-DVS, NCaltech-101); 
1	  (2) Extending the classification system, tracking is demonstrated using two key novelties: 
1	  (i) Statistical bootstrapping is leveraged with online learning for overcoming the low-sample problem during the one-shot learning of the tracker, 
1	  (ii) Cyclical shifts are induced in the log-polar domain of the DART descriptor to achieve robustness to object scale and rotation variations; 
1	  (3) To solve the long-term object tracking problem, an object detector is designed using the principle of cluster majority voting.
2	  The detection scheme is then combined with the tracker to result in a high intersection-over-union score with augmented ground truth annotations on the publicly available event camera dataset; (4) Finally, the event context encoded by DART greatly simplifies the feature correspondence problem, especially for spatio-temporal slices far apart in time, which has not been explicitly tackled in the event-based vision domain.


### 146
##### 10.1109/TPAMI.2019.2919303
#### Learning Low-Dimensional Temporal Representations with Latent Alignments


0	  Low-dimensional discriminative representations enhance machine learning methods in both performance and complexity.
0	  This has motivated supervised dimensionality reduction (DR), which transforms high-dimensional data into a discriminative subspace.
0	  Most DR methods require data to be i.i.d.
0	  However, in some domains, data naturally appear in sequences, where the observations are temporally correlated.
1	  We propose a DR method, namely, latent temporal linear discriminant analysis (LT-LDA), to learn low-dimensional temporal representations.
1	  We construct the separability among sequence classes by lifting the holistic temporal structures, which are established based on temporal alignments and may change in different subspaces.
1	  We jointly learn the subspace and the associated latent alignments by optimizing an objective that favors easily separable temporal structures.
1	  We show that this objective is connected to the inference of alignments and thus allows for an iterative solution.
2	  We provide both theoretical insight and empirical evaluations on several real-world sequence datasets to show the applicability of our method.


### 147
##### 10.1109/TPAMI.2019.2919308
#### A Functional Representation for Graph Matching


0	  Graph matching is an important and persistent problem in computer vision and pattern recognition for finding node-to-node correspondence between graphs.
0	  However, graph matching that incorporates pairwise constraints can be formulated as a quadratic assignment problem (QAP), which is NP-complete and results in intrinsic computational difficulties.
1	  This paper presents a functional representation for graph matching (FRGM) that aims to provide more geometric insights on the problem and reduce the space and time complexities.
1	  To achieve these goals, we represent each graph by a linear function space equipped with a functional such as inner product or metric, that has an explicit geometric meaning.
1	  Consequently, the correspondence matrix between graphs can be represented as a linear representation map.
1	  Furthermore, this map can be reformulated as a new parameterization for matching graphs in Euclidean space such that it is consistent with graphs under rigid or nonrigid deformations.
1	  This allows us to estimate the correspondence matrix and geometric deformations simultaneously.
2	  We use the representation of edge-attributes rather than the affinity matrix to reduce the space complexity and propose an efficient optimization strategy to reduce the time complexity.
2	  The experimental results on both synthetic and real-world datasets show that the FRGM can achieve state-of-the-art performance.


### 148
##### 10.1109/TPAMI.2019.2919284
#### Robust RGB-D Face Recognition Using Attribute-Aware Loss


0	  Existing convolutional neural network (CNN) based face recognition algorithms typically learn a discriminative feature mapping, using a loss function that enforces separation of features from different classes and/or aggregation of features within the same class.
0	  However, they may suffer from bias in the training data such as uneven sampling density, because they optimize the adjacency relationship of the learned features without considering the proximity of the underlying faces.
0	  Moreover, since they only use facial images for training, the learned feature mapping may not correctly indicate the relationship of other attributes such as gender and ethnicity, which can be important for some face recognition applications.
1	  In this paper, we propose a new CNN-based face recognition approach that incorporates such attributes into the training process.
2	  Using an attribute-aware loss function that regularizes the feature mapping using attribute proximity, our approach learns more discriminative features that are correlated with the attributes.
1	  We train our face recognition model on a large-scale RGB-D data set with over 100K identities captured under real application conditions.
2	  By comparing our approach with other methods on a variety of experiments, we demonstrate that depth channel and attribute-aware loss greatly improve the accuracy and robustness of face recognition.


### 149
##### 10.1109/TPAMI.2019.2918284
#### Convolutional Networks with Dense Connectivity


0	  Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output.
1	  In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion.
1	  Whereas traditional convolutional networks with L layers have L connections -- one between each layer and its subsequent layer -- our network has $\frac{L(L+1)}{2}$ direct connections.
1	  For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers.
0	  DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially improve parameter efficiency.
2	  We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet).
2	  DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less parameters and computation to achieve high performance.


### 150
##### 10.1109/TPAMI.2019.2918208
#### Learning Visual Instance Retrieval from Failure: Efficient Online Local Metric Adaptation from Negative Samples


0	  Existing visual instance retrieval (VIR) approaches attempt to learn a faithful global matching metric or discriminative feature embedding offline to cover enormous visual appearance variations, so as to directly use it online on various unseen probes for retrieval.
0	  However, their requirement for a huge set of positive training pairs is very demanding in practice and the performance is largely constrained for the unseen testing samples due to the severe data shifting issue.
1	  In contrast, this paper advocates a different paradigm: part of the learning can be performed online but with nominal costs, so as to achieve online metric adaptation for different query probes.
1	  By exploiting easily-available negative samples, we propose a novel solution to achieve the optimal local metric adaptation effectively and efficiently.
2	  The insight of our method is the local hard negative samples can actually provide tight constraints to fine tune the metric locally.
2	  Our local metric adaptation method is generally applicable to be used on top of any offline-learned baselines.
2	  In addition, this paper gives in-depth theoretical analyses of the proposed method to guarantee the reduction of the classification error both asymptotically and practically.
2	  Extensive experiments on various VIR tasks have confirmed our effectiveness and superiority.
